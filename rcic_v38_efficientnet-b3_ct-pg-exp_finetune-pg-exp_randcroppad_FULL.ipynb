{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:40.240474Z",
     "start_time": "2019-09-03T16:31:40.083108Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:40.871360Z",
     "start_time": "2019-09-03T16:31:40.241664Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from fastai.vision import *\n",
    "from fastai.vision.models.xresnet import *\n",
    "\n",
    "# for datablock API\n",
    "from fastai.vision.image import _resolve_tfms, _get_crop_target, _round_multiple, _get_resize_target, _affine_grid, _grid_sample, _affine_mult\n",
    "\n",
    "# for XResNet\n",
    "#from fastai.vision.models.xresnet import act_fn, init_cnn, conv, noop, conv_layer, ResBlock, filt_sz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:40.882809Z",
     "start_time": "2019-09-03T16:31:40.872733Z"
    }
   },
   "outputs": [],
   "source": [
    "from fastai.callbacks import CSVLogger, ReduceLROnPlateauCallback, SaveModelCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:40.895270Z",
     "start_time": "2019-09-03T16:31:40.883929Z"
    }
   },
   "outputs": [],
   "source": [
    "from efficientnet_pytorch import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:40.906718Z",
     "start_time": "2019-09-03T16:31:40.896292Z"
    }
   },
   "outputs": [],
   "source": [
    "from nb_new_data_augmentation_adacos_celltype_plategroup_exp import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:40.917291Z",
     "start_time": "2019-09-03T16:31:40.907730Z"
    }
   },
   "outputs": [],
   "source": [
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:40.929303Z",
     "start_time": "2019-09-03T16:31:40.918387Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.55'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6D image with celltype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:40.943523Z",
     "start_time": "2019-09-03T16:31:40.930824Z"
    }
   },
   "outputs": [],
   "source": [
    "class Image6Dct(Image):\n",
    "    \"Support applying transforms to image data in `px`.\"\n",
    "    def __init__(self, px:Tensor, ctint, pgint, expint): # ct\n",
    "        self._px = px\n",
    "        self._logit_px=None\n",
    "        #self.ct = ct\n",
    "        self.ctint = ctint\n",
    "        self.pgint = pgint\n",
    "        self.expint = expint\n",
    "        self._flow=None\n",
    "        self._affine_mat=None\n",
    "        self.sample_kwargs = {}\n",
    "    \n",
    "    def _repr_image_format(self, format_str):\n",
    "        with BytesIO() as str_buffer:\n",
    "            #plt.imsave(str_buffer, image2np(self.px[:3]), format=format_str)\n",
    "            plt.imsave(str_buffer, \n",
    "                       np.concatenate((image2np(self.px[:3]), \n",
    "                                       image2np(self.px[3:])), axis=1),\n",
    "                       format=format_str)\n",
    "            return str_buffer.getvalue()\n",
    "        \n",
    "    def clone(self):\n",
    "        \"Mimic the behavior of torch.clone for `Image` objects.\"\n",
    "        return self.__class__(self.px.clone(), self.ctint.clone(), self.pgint.clone(), self.expint.clone()) # self.ct.clone(), \n",
    "\n",
    "    @property\n",
    "    def data(self)->TensorImage:\n",
    "        \"Return this images pixels as a tensor.\"\n",
    "        return self.px, self.ctint, self.pgint, self.expint\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:40.957232Z",
     "start_time": "2019-09-03T16:31:40.944672Z"
    }
   },
   "outputs": [],
   "source": [
    "def open_image_6Dct(fn:PathOrStr, div:bool=True, convert_mode:str='L', cls:type=Image6Dct,\n",
    "        after_open:Callable=None)->Image:\n",
    "    \"Return `Image` object created from image in file `fn`.\"\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", UserWarning) # EXIF warning from TiffPlugin\n",
    "        \n",
    "        x = []\n",
    "        for i in range(6):\n",
    "            c = PIL.Image.open(fn+'_w'+str(i+1)+'.png').convert(convert_mode)\n",
    "            if after_open: c = after_open(c)\n",
    "            c = np.asarray(c)\n",
    "            c = torch.from_numpy(c.astype(np.float32, copy=False))\n",
    "            x.append(c)\n",
    "    ct = fn.split('/')[1].split('-')[0] # get cell type\n",
    "    ctint = torch.tensor(ct2int[ct])\n",
    "    pgint = torch.tensor(fn2pgint[fn])\n",
    "    exp = fn.split('/')[1] # get experiment\n",
    "    expint = torch.tensor(exp2int[exp])\n",
    "    x = torch.stack(x)\n",
    "    if div: x.div_(255)\n",
    "    return cls(x, ctint, pgint, expint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:40.970412Z",
     "start_time": "2019-09-03T16:31:40.958305Z"
    }
   },
   "outputs": [],
   "source": [
    "# number experiments so that cell types do not overlap\n",
    "# and the valid and test dataset do have a embedding they can use!\n",
    "exp2int = {'HEPG2-01': 0,\n",
    "           'HEPG2-02': 1,\n",
    "           'HEPG2-03': 2,\n",
    "           'HEPG2-04': 3,\n",
    "           'HEPG2-05': 4,\n",
    "           # valid\n",
    "           'HEPG2-06': 0,\n",
    "           'HEPG2-07': 1,\n",
    "           # test\n",
    "           'HEPG2-08': 0,\n",
    "           'HEPG2-09': 1,\n",
    "           'HEPG2-10': 2,\n",
    "           'HEPG2-11': 3,           \n",
    "             \n",
    "           # train\n",
    "           'HUVEC-01': 5,\n",
    "           'HUVEC-02': 6,\n",
    "           'HUVEC-03': 7,\n",
    "           'HUVEC-04': 8,\n",
    "           'HUVEC-05': 9,\n",
    "           'HUVEC-06': 10,\n",
    "           'HUVEC-07': 11, \n",
    "           'HUVEC-08': 12,\n",
    "           'HUVEC-09': 13,\n",
    "           'HUVEC-10': 14,\n",
    "           'HUVEC-11': 15,\n",
    "           'HUVEC-12': 16,\n",
    "           'HUVEC-13': 17,\n",
    "           'HUVEC-14': 18, \n",
    "           # valid\n",
    "           'HUVEC-15': 5,\n",
    "           'HUVEC-16': 6, \n",
    "           # test\n",
    "           'HUVEC-17': 5,\n",
    "           'HUVEC-18': 6,\n",
    "           'HUVEC-19': 7,\n",
    "           'HUVEC-20': 8,\n",
    "           'HUVEC-21': 9,\n",
    "           'HUVEC-22': 10,\n",
    "           'HUVEC-23': 11,\n",
    "           'HUVEC-24': 12,\n",
    "             \n",
    "           # train\n",
    "           'RPE-01': 19,\n",
    "           'RPE-02': 20,\n",
    "           'RPE-03': 21,\n",
    "           'RPE-04': 22,\n",
    "           'RPE-05': 23,\n",
    "           # valid\n",
    "           'RPE-06': 19,\n",
    "           'RPE-07': 20,\n",
    "           # test\n",
    "           'RPE-08': 19,\n",
    "           'RPE-09': 20,\n",
    "           'RPE-10': 21,\n",
    "           'RPE-11': 22,\n",
    "             \n",
    "           # train\n",
    "           'U2OS-01': 24,\n",
    "           'U2OS-02': 25,\n",
    "           # valid\n",
    "           'U2OS-03': 24,\n",
    "           # test\n",
    "           'U2OS-04': 24,\n",
    "           'U2OS-05': 25\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:40.983233Z",
     "start_time": "2019-09-03T16:31:40.971471Z"
    }
   },
   "outputs": [],
   "source": [
    "#exp2int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:41.056016Z",
     "start_time": "2019-09-03T16:31:40.984202Z"
    }
   },
   "outputs": [],
   "source": [
    "df_full_plate_pattern = pd.read_csv('full_dataset_v2_path_plate_groups_only_20190812.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:41.071721Z",
     "start_time": "2019-09-03T16:31:41.057003Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>plate_pattern</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train/HEPG2-01/Plate1/B03_s1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train/HEPG2-01/Plate1/B04_s1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train/HEPG2-01/Plate1/B05_s1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train/HEPG2-01/Plate1/B06_s1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train/HEPG2-01/Plate1/B07_s1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           path  plate_pattern\n",
       "0  train/HEPG2-01/Plate1/B03_s1              0\n",
       "1  train/HEPG2-01/Plate1/B04_s1              0\n",
       "2  train/HEPG2-01/Plate1/B05_s1              0\n",
       "3  train/HEPG2-01/Plate1/B06_s1              0\n",
       "4  train/HEPG2-01/Plate1/B07_s1              0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full_plate_pattern.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:41.097705Z",
     "start_time": "2019-09-03T16:31:41.072598Z"
    }
   },
   "outputs": [],
   "source": [
    "fn2pgint = dict(zip(df_full_plate_pattern.path.values, \n",
    "                              df_full_plate_pattern.plate_pattern.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:41.109243Z",
     "start_time": "2019-09-03T16:31:41.098718Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn2pgint['train/HEPG2-01/Plate1/B03_s1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:41.120523Z",
     "start_time": "2019-09-03T16:31:41.110098Z"
    }
   },
   "outputs": [],
   "source": [
    "# cell types from rcic_v10_inspect_image_data.ipynb \"pixel stats\"\n",
    "cts = ['HEPG2', 'HUVEC', 'RPE', 'U2OS']\n",
    "int2ct = {i: ct for i, ct in enumerate(cts)}\n",
    "ct2int = {ct: i for i, ct in int2ct.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:41.131427Z",
     "start_time": "2019-09-03T16:31:41.121557Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'HEPG2', 1: 'HUVEC', 2: 'RPE', 3: 'U2OS'}\n",
      "{'HEPG2': 0, 'HUVEC': 1, 'RPE': 2, 'U2OS': 3}\n"
     ]
    }
   ],
   "source": [
    "print(int2ct)\n",
    "print(ct2int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:41.143206Z",
     "start_time": "2019-09-03T16:31:41.132453Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HEPG2'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct = 'train/HEPG2-01/Plate1/B03_s1'.split('/')[1].split('-')[0]; ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:41.154605Z",
     "start_time": "2019-09-03T16:31:41.144224Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct2int[ct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:41.165033Z",
     "start_time": "2019-09-03T16:31:41.155626Z"
    }
   },
   "outputs": [],
   "source": [
    "PATH_trunc = 'train/HEPG2-01/Plate1/B03_s1' # path is missing suffix \"_w1.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:41.200077Z",
     "start_time": "2019-09-03T16:31:41.166063Z"
    }
   },
   "outputs": [],
   "source": [
    "img = open_image_6Dct(PATH_trunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:41.211343Z",
     "start_time": "2019-09-03T16:31:41.201039Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 512, 512])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.px.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:41.224102Z",
     "start_time": "2019-09-03T16:31:41.213493Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(0), tensor(0))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.ctint, img.pgint, img.expint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:41.235909Z",
     "start_time": "2019-09-03T16:31:41.225439Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Tensor, torch.Tensor, torch.Tensor)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(img.ctint), type(img.pgint), type(img.expint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:41.249862Z",
     "start_time": "2019-09-03T16:31:41.236931Z"
    }
   },
   "outputs": [],
   "source": [
    "class ImageList6Dct(ImageList): #ImageList\n",
    "    def __init__(self, *args, convert_mode='L', after_open:Callable=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.convert_mode,self.after_open = convert_mode,after_open\n",
    "        self.copy_new.append('convert_mode')\n",
    "        self.c,self.sizes = 6,{}\n",
    "        \n",
    "    def open(self, fn):\n",
    "        \"Open image in `fn`, subclass and overwrite for custom behavior.\"\n",
    "        return open_image_6Dct(fn, convert_mode=self.convert_mode, after_open=self.after_open)\n",
    "\n",
    "#    def show(self, img):\n",
    "#        #return torch.cat((img[i][:3], img[i][3:]), dim=1)\n",
    "#        show_image(img)\n",
    "    \n",
    "    # https://docs.fast.ai/tutorial.itemlist.html#Advanced-show-methods\n",
    "    def show_xys(self, xs, ys, figsize:Tuple[int,int]=(15,10), **kwargs):\n",
    "        \"Show the `xs` and `ys` on a figure of `figsize`. `kwargs` are passed to the show method.\"\n",
    "        rows = int(math.sqrt(len(xs)))\n",
    "        fig, axs = plt.subplots(rows,rows,figsize=figsize)\n",
    "        for i, ax in enumerate(axs.flatten() if rows > 1 else [axs]):\n",
    "            #xs[i].show(ax=ax, y=ys[i], **kwargs)\n",
    "            img = Image6D(torch.cat((xs[i].data[:3], xs[i].data[3:]), dim=2)) # works but not elegant?\n",
    "            #img = Image6D(xs[i]) # does not work?\n",
    "            img.show(ax=ax, y=ys[i], **kwargs)\n",
    "        plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:41.260560Z",
     "start_time": "2019-09-03T16:31:41.250912Z"
    }
   },
   "outputs": [],
   "source": [
    "#def show_image(img:Image, ax:plt.Axes=None, figsize:tuple=(3,3), hide_axis:bool=True, cmap:str='binary',\n",
    "#                alpha:float=None, **kwargs)->plt.Axes:\n",
    "#    \"Display `Image` in notebook.\"\n",
    "#    if ax is None: fig,ax = plt.subplots(figsize=figsize)\n",
    "#    pdb.set_trace()\n",
    "#    #ax.imshow(image2np(img.data), cmap=cmap, alpha=alpha, **kwargs)\n",
    "#    ax.imshow(np.concatenate((image2np(self.px[:3]),\n",
    "#                              image2np(self.px[3:])), axis=1),\n",
    "#              cmap=cmap, alpha=alpha, **kwargs)\n",
    "#    if hide_axis: ax.axis('off')\n",
    "#    return ax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset raw files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:41.364637Z",
     "start_time": "2019-09-03T16:31:41.261574Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('full_train_dataset_valid-split-ex_v2_ct_20190824.csv', index_col=0)\n",
    "df_test = pd.read_csv('full_test_dataset_v2_ct_20190824.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:41.376087Z",
     "start_time": "2019-09-03T16:31:41.365702Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73030, 6)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:41.390754Z",
     "start_time": "2019-09-03T16:31:41.376973Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>experiment</th>\n",
       "      <th>sirna</th>\n",
       "      <th>multi</th>\n",
       "      <th>valid</th>\n",
       "      <th>celltype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36510</th>\n",
       "      <td>U2OS-03/Plate4/O19_s2</td>\n",
       "      <td>U2OS-03</td>\n",
       "      <td>103</td>\n",
       "      <td>U2OS-03 103</td>\n",
       "      <td>1</td>\n",
       "      <td>U2OS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36511</th>\n",
       "      <td>U2OS-03/Plate4/O20_s2</td>\n",
       "      <td>U2OS-03</td>\n",
       "      <td>202</td>\n",
       "      <td>U2OS-03 202</td>\n",
       "      <td>1</td>\n",
       "      <td>U2OS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36512</th>\n",
       "      <td>U2OS-03/Plate4/O21_s2</td>\n",
       "      <td>U2OS-03</td>\n",
       "      <td>824</td>\n",
       "      <td>U2OS-03 824</td>\n",
       "      <td>1</td>\n",
       "      <td>U2OS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36513</th>\n",
       "      <td>U2OS-03/Plate4/O22_s2</td>\n",
       "      <td>U2OS-03</td>\n",
       "      <td>328</td>\n",
       "      <td>U2OS-03 328</td>\n",
       "      <td>1</td>\n",
       "      <td>U2OS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36514</th>\n",
       "      <td>U2OS-03/Plate4/O23_s2</td>\n",
       "      <td>U2OS-03</td>\n",
       "      <td>509</td>\n",
       "      <td>U2OS-03 509</td>\n",
       "      <td>1</td>\n",
       "      <td>U2OS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        path experiment  sirna        multi  valid celltype\n",
       "36510  U2OS-03/Plate4/O19_s2    U2OS-03    103  U2OS-03 103      1     U2OS\n",
       "36511  U2OS-03/Plate4/O20_s2    U2OS-03    202  U2OS-03 202      1     U2OS\n",
       "36512  U2OS-03/Plate4/O21_s2    U2OS-03    824  U2OS-03 824      1     U2OS\n",
       "36513  U2OS-03/Plate4/O22_s2    U2OS-03    328  U2OS-03 328      1     U2OS\n",
       "36514  U2OS-03/Plate4/O23_s2    U2OS-03    509  U2OS-03 509      1     U2OS"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:41.404761Z",
     "start_time": "2019-09-03T16:31:41.391658Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>experiment</th>\n",
       "      <th>celltype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19892</th>\n",
       "      <td>U2OS-05/Plate4/O19_s2</td>\n",
       "      <td>U2OS-05</td>\n",
       "      <td>U2OS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19893</th>\n",
       "      <td>U2OS-05/Plate4/O20_s2</td>\n",
       "      <td>U2OS-05</td>\n",
       "      <td>U2OS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19894</th>\n",
       "      <td>U2OS-05/Plate4/O21_s2</td>\n",
       "      <td>U2OS-05</td>\n",
       "      <td>U2OS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19895</th>\n",
       "      <td>U2OS-05/Plate4/O22_s2</td>\n",
       "      <td>U2OS-05</td>\n",
       "      <td>U2OS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19896</th>\n",
       "      <td>U2OS-05/Plate4/O23_s2</td>\n",
       "      <td>U2OS-05</td>\n",
       "      <td>U2OS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        path experiment celltype\n",
       "19892  U2OS-05/Plate4/O19_s2    U2OS-05     U2OS\n",
       "19893  U2OS-05/Plate4/O20_s2    U2OS-05     U2OS\n",
       "19894  U2OS-05/Plate4/O21_s2    U2OS-05     U2OS\n",
       "19895  U2OS-05/Plate4/O22_s2    U2OS-05     U2OS\n",
       "19896  U2OS-05/Plate4/O23_s2    U2OS-05     U2OS"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:41.415556Z",
     "start_time": "2019-09-03T16:31:41.405797Z"
    }
   },
   "outputs": [],
   "source": [
    "cts = ['HEPG2', 'HUVEC', 'RPE', 'U2OS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:41.425961Z",
     "start_time": "2019-09-03T16:31:41.416552Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pick the celltype for the celltype-specific training\n",
    "#ct = cts[3]; ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:41.436276Z",
     "start_time": "2019-09-03T16:31:41.427031Z"
    }
   },
   "outputs": [],
   "source": [
    "#df_train[df_train['celltype'] == ct].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:41.446510Z",
     "start_time": "2019-09-03T16:31:41.437302Z"
    }
   },
   "outputs": [],
   "source": [
    "#df_train[df_train['celltype'] == ct].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:41.456843Z",
     "start_time": "2019-09-03T16:31:41.447556Z"
    }
   },
   "outputs": [],
   "source": [
    "#df_test[df_test['celltype'] == ct].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:41.488615Z",
     "start_time": "2019-09-03T16:31:41.457710Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train['pg'] = df_train['path'].apply(lambda x: fn2pgint['train/'+x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:41.513041Z",
     "start_time": "2019-09-03T16:31:41.489587Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test['pg'] = df_test['path'].apply(lambda x: fn2pgint['test/'+x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:41.523878Z",
     "start_time": "2019-09-03T16:31:41.514059Z"
    }
   },
   "outputs": [],
   "source": [
    "pg = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:41.538719Z",
     "start_time": "2019-09-03T16:31:41.524816Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18252, 7), (9946, 4))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train['pg'] == pg].shape, df_test[df_test['pg'] == pg].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:41.555083Z",
     "start_time": "2019-09-03T16:31:41.539665Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>experiment</th>\n",
       "      <th>sirna</th>\n",
       "      <th>multi</th>\n",
       "      <th>valid</th>\n",
       "      <th>celltype</th>\n",
       "      <th>pg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36510</th>\n",
       "      <td>U2OS-03/Plate4/O19_s2</td>\n",
       "      <td>U2OS-03</td>\n",
       "      <td>103</td>\n",
       "      <td>U2OS-03 103</td>\n",
       "      <td>1</td>\n",
       "      <td>U2OS</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36511</th>\n",
       "      <td>U2OS-03/Plate4/O20_s2</td>\n",
       "      <td>U2OS-03</td>\n",
       "      <td>202</td>\n",
       "      <td>U2OS-03 202</td>\n",
       "      <td>1</td>\n",
       "      <td>U2OS</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36512</th>\n",
       "      <td>U2OS-03/Plate4/O21_s2</td>\n",
       "      <td>U2OS-03</td>\n",
       "      <td>824</td>\n",
       "      <td>U2OS-03 824</td>\n",
       "      <td>1</td>\n",
       "      <td>U2OS</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36513</th>\n",
       "      <td>U2OS-03/Plate4/O22_s2</td>\n",
       "      <td>U2OS-03</td>\n",
       "      <td>328</td>\n",
       "      <td>U2OS-03 328</td>\n",
       "      <td>1</td>\n",
       "      <td>U2OS</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36514</th>\n",
       "      <td>U2OS-03/Plate4/O23_s2</td>\n",
       "      <td>U2OS-03</td>\n",
       "      <td>509</td>\n",
       "      <td>U2OS-03 509</td>\n",
       "      <td>1</td>\n",
       "      <td>U2OS</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        path experiment  sirna        multi  valid celltype  \\\n",
       "36510  U2OS-03/Plate4/O19_s2    U2OS-03    103  U2OS-03 103      1     U2OS   \n",
       "36511  U2OS-03/Plate4/O20_s2    U2OS-03    202  U2OS-03 202      1     U2OS   \n",
       "36512  U2OS-03/Plate4/O21_s2    U2OS-03    824  U2OS-03 824      1     U2OS   \n",
       "36513  U2OS-03/Plate4/O22_s2    U2OS-03    328  U2OS-03 328      1     U2OS   \n",
       "36514  U2OS-03/Plate4/O23_s2    U2OS-03    509  U2OS-03 509      1     U2OS   \n",
       "\n",
       "       pg  \n",
       "36510   3  \n",
       "36511   3  \n",
       "36512   3  \n",
       "36513   3  \n",
       "36514   3  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train['pg'] == pg].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:41.570412Z",
     "start_time": "2019-09-03T16:31:41.556052Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>experiment</th>\n",
       "      <th>celltype</th>\n",
       "      <th>pg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19069</th>\n",
       "      <td>U2OS-05/Plate1/O19_s2</td>\n",
       "      <td>U2OS-05</td>\n",
       "      <td>U2OS</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19070</th>\n",
       "      <td>U2OS-05/Plate1/O20_s2</td>\n",
       "      <td>U2OS-05</td>\n",
       "      <td>U2OS</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19071</th>\n",
       "      <td>U2OS-05/Plate1/O21_s2</td>\n",
       "      <td>U2OS-05</td>\n",
       "      <td>U2OS</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19072</th>\n",
       "      <td>U2OS-05/Plate1/O22_s2</td>\n",
       "      <td>U2OS-05</td>\n",
       "      <td>U2OS</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19073</th>\n",
       "      <td>U2OS-05/Plate1/O23_s2</td>\n",
       "      <td>U2OS-05</td>\n",
       "      <td>U2OS</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        path experiment celltype  pg\n",
       "19069  U2OS-05/Plate1/O19_s2    U2OS-05     U2OS   3\n",
       "19070  U2OS-05/Plate1/O20_s2    U2OS-05     U2OS   3\n",
       "19071  U2OS-05/Plate1/O21_s2    U2OS-05     U2OS   3\n",
       "19072  U2OS-05/Plate1/O22_s2    U2OS-05     U2OS   3\n",
       "19073  U2OS-05/Plate1/O23_s2    U2OS-05     U2OS   3"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[df_test['pg'] == pg].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color augmentation transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Color Augmentation: Color variability can be increased by applying random color transformations to original training samples. We perform color augmentation by transforming every color channels Ic ← ac · Ic + bc, where ac and bc are drawn from uniform distributions ac ∼ U [0.9, 1.1] and bc ∼ U [−10, +10].\" from Domain-adversarial neural networks to address the appearance variability of histopathology images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:41.581061Z",
     "start_time": "2019-09-03T16:31:41.571450Z"
    }
   },
   "outputs": [],
   "source": [
    "# from https://github.com/fastai/fastai/blob/master/fastai/vision/transform.py#L137\n",
    "#def _rgb_randomize(x, channel:int=None, thresh:float=0.3):\n",
    "#    \"Randomize one of the channels of the input image\"\n",
    "#    if channel is None: channel = np.random.randint(0, x.shape[0] - 1)\n",
    "#    x[channel] = torch.rand(x.shape[1:]) * np.random.uniform(0, thresh)\n",
    "#    return x\n",
    "#\n",
    "#rgb_randomize = TfmPixel(_rgb_randomize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:41.591530Z",
     "start_time": "2019-09-03T16:31:41.582029Z"
    }
   },
   "outputs": [],
   "source": [
    "# Scaling factor comes from byte tensor?\n",
    "#10/255 = 0.0392156862745098"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:41.603728Z",
     "start_time": "2019-09-03T16:31:41.592586Z"
    }
   },
   "outputs": [],
   "source": [
    "def _color_augmentation(x):\n",
    "    \"Randomize all channels of the input image\"\n",
    "    channel_count = x.shape[0] - 1\n",
    "    \n",
    "    # by transforming every color channels Ic ← ac · Ic + bc, \n",
    "    # where ac and bc are drawn from uniform distributions \n",
    "    # ac ∼ U [0.9, 1.1] and \n",
    "    # bc ∼ U [−10, +10].\n",
    "    \n",
    "    # x [0,1]\n",
    "    \n",
    "    for c in range(channel_count):\n",
    "        #pdb.set_trace()\n",
    "        #print(x.min(), x.max())\n",
    "        ac = np.random.uniform(0.9, 1.1) #np.random.uniform(0.9, 1.1)\n",
    "        bc = np.random.uniform(-0.1,0.1) #np.random.uniform(-10, 10)\n",
    "        x[c] = x[c] * ac + bc\n",
    "        \n",
    "        # clipping to min 0 and max 1\n",
    "        x[c] = torch.clamp(x[c], 0., 1.)\n",
    "    \n",
    "    return x\n",
    "\n",
    "color_augmentation = TfmPixel(_color_augmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforms setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:41.614377Z",
     "start_time": "2019-09-03T16:31:41.604686Z"
    }
   },
   "outputs": [],
   "source": [
    "## EfficientNet-B3\n",
    "#sz, bs = 300, 8 # 4167MiB /  7952MiB\n",
    "sz, bs = 300, 8*2 # 7942MiB /  7952MiB // FP16: 4397MiB /  7952MiB\n",
    "#sz, bs = 300, 8*4 # FP16: 7805MiB /  7952MiB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:41.625660Z",
     "start_time": "2019-09-03T16:31:41.615407Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 16)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sz, bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:41.636070Z",
     "start_time": "2019-09-03T16:31:41.626513Z"
    }
   },
   "outputs": [],
   "source": [
    "# cutout params\n",
    "#int(sz*0.1), int(sz*0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:41.646283Z",
     "start_time": "2019-09-03T16:31:41.637026Z"
    }
   },
   "outputs": [],
   "source": [
    "# normal tfms\n",
    "#tfms = get_transforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:41.657427Z",
     "start_time": "2019-09-03T16:31:41.647156Z"
    }
   },
   "outputs": [],
   "source": [
    "# extended tfms\n",
    "tfms = get_transforms(do_flip=True, flip_vert=True, \n",
    "                      max_rotate=90.0, max_zoom=1.1, \n",
    "                      max_lighting=0.2, max_warp=0.2, \n",
    "                      p_affine=0.75, p_lighting=0.75, \n",
    "                      xtra_tfms=[color_augmentation()])\n",
    "\n",
    "# crop_pad: https://forums.fast.ai/t/misc-issues/35386/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:41.668043Z",
     "start_time": "2019-09-03T16:31:41.658485Z"
    }
   },
   "outputs": [],
   "source": [
    "# extended tfms\n",
    "#tfms = get_transforms(do_flip=True, flip_vert=True, \n",
    "#                      max_rotate=90.0, max_zoom=1.1, \n",
    "#                      max_lighting=0.2, max_warp=0.2, \n",
    "#                      p_affine=0.75, p_lighting=0.75, \n",
    "#                      xtra_tfms=[color_augmentation(), \n",
    "#                                 cutout(n_holes=(1,4), length=(int(sz*0.1), int(sz*0.5)), p=.5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:41.679306Z",
     "start_time": "2019-09-03T16:31:41.669035Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([RandTransform(tfm=TfmCrop (crop_pad), kwargs={'row_pct': (0, 1), 'col_pct': (0, 1), 'padding_mode': 'reflection'}, p=1.0, resolved={}, do_run=True, is_random=True, use_on_y=True),\n",
       "  RandTransform(tfm=TfmAffine (dihedral_affine), kwargs={}, p=1.0, resolved={}, do_run=True, is_random=True, use_on_y=True),\n",
       "  RandTransform(tfm=TfmCoord (symmetric_warp), kwargs={'magnitude': (-0.2, 0.2)}, p=0.75, resolved={}, do_run=True, is_random=True, use_on_y=True),\n",
       "  RandTransform(tfm=TfmAffine (rotate), kwargs={'degrees': (-90.0, 90.0)}, p=0.75, resolved={}, do_run=True, is_random=True, use_on_y=True),\n",
       "  RandTransform(tfm=TfmAffine (zoom), kwargs={'scale': (1.0, 1.1), 'row_pct': (0, 1), 'col_pct': (0, 1)}, p=0.75, resolved={}, do_run=True, is_random=True, use_on_y=True),\n",
       "  RandTransform(tfm=TfmLighting (brightness), kwargs={'change': (0.4, 0.6)}, p=0.75, resolved={}, do_run=True, is_random=True, use_on_y=True),\n",
       "  RandTransform(tfm=TfmLighting (contrast), kwargs={'scale': (0.8, 1.25)}, p=0.75, resolved={}, do_run=True, is_random=True, use_on_y=True),\n",
       "  RandTransform(tfm=TfmPixel (color_augmentation), kwargs={}, p=1.0, resolved={}, do_run=True, is_random=True, use_on_y=True)],\n",
       " [RandTransform(tfm=TfmCrop (crop_pad), kwargs={}, p=1.0, resolved={}, do_run=True, is_random=True, use_on_y=True)])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:41.690506Z",
     "start_time": "2019-09-03T16:31:41.680165Z"
    }
   },
   "outputs": [],
   "source": [
    "# \"crop_pad\" to sz\n",
    "tfms[0][0] = crop_pad(size=sz, row_pct=[0.,1.], col_pct=[0.,1.])\n",
    "tfms[1][0] = crop_pad(size=sz, row_pct=[0.,1.], col_pct=[0.,1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:41.701773Z",
     "start_time": "2019-09-03T16:31:41.691480Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([RandTransform(tfm=TfmCrop (crop_pad), kwargs={'size': 300, 'row_pct': [0.0, 1.0], 'col_pct': [0.0, 1.0]}, p=1.0, resolved={}, do_run=True, is_random=True, use_on_y=True),\n",
       "  RandTransform(tfm=TfmAffine (dihedral_affine), kwargs={}, p=1.0, resolved={}, do_run=True, is_random=True, use_on_y=True),\n",
       "  RandTransform(tfm=TfmCoord (symmetric_warp), kwargs={'magnitude': (-0.2, 0.2)}, p=0.75, resolved={}, do_run=True, is_random=True, use_on_y=True),\n",
       "  RandTransform(tfm=TfmAffine (rotate), kwargs={'degrees': (-90.0, 90.0)}, p=0.75, resolved={}, do_run=True, is_random=True, use_on_y=True),\n",
       "  RandTransform(tfm=TfmAffine (zoom), kwargs={'scale': (1.0, 1.1), 'row_pct': (0, 1), 'col_pct': (0, 1)}, p=0.75, resolved={}, do_run=True, is_random=True, use_on_y=True),\n",
       "  RandTransform(tfm=TfmLighting (brightness), kwargs={'change': (0.4, 0.6)}, p=0.75, resolved={}, do_run=True, is_random=True, use_on_y=True),\n",
       "  RandTransform(tfm=TfmLighting (contrast), kwargs={'scale': (0.8, 1.25)}, p=0.75, resolved={}, do_run=True, is_random=True, use_on_y=True),\n",
       "  RandTransform(tfm=TfmPixel (color_augmentation), kwargs={}, p=1.0, resolved={}, do_run=True, is_random=True, use_on_y=True)],\n",
       " [RandTransform(tfm=TfmCrop (crop_pad), kwargs={'size': 300, 'row_pct': [0.0, 1.0], 'col_pct': [0.0, 1.0]}, p=1.0, resolved={}, do_run=True, is_random=True, use_on_y=True)])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:41.712218Z",
     "start_time": "2019-09-03T16:31:41.702627Z"
    }
   },
   "outputs": [],
   "source": [
    "### CHANGED LINE 65 to:\n",
    "# nano ~/anaconda3/envs/fastai/lib/python3.6/site-packages/fastai/vision/data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T10:36:41.864055Z",
     "start_time": "2019-08-10T10:36:41.846780Z"
    }
   },
   "source": [
    "```\n",
    "~/anaconda3/envs/fastai/lib/python3.6/site-packages/fastai/vision/data.py in _normalize_batch(b, mean, std, do_x, do_y)\n",
    "     64     \"`b` = `x`,`y` - normalize `x` array of imgs and `do_y` optionally `y`.\"\n",
    "     65     x,y = b\n",
    "---> 66     mean,std = mean.to(x.device),std.to(x.device)\n",
    "     67     if do_x: x = normalize(x,mean,std)\n",
    "     68     if do_y and len(y.shape) == 4: y = normalize(y,mean,std)\n",
    "\n",
    "AttributeError: 'list' object has no attribute 'device'\n",
    "```\n",
    "CHANGED TO:\n",
    "```\n",
    "def _normalize_batch(b:Tuple[Tensor,Tensor], mean:FloatTensor, std:FloatTensor, do_x:bool$\n",
    "    \"`b` = `x`,`y` - normalize `x` array of imgs and `do_y` optionally `y`.\"\n",
    "    (x,cint,pgint,expint),y = b\n",
    "    mean,std = mean.to(x.device),std.to(x.device)\n",
    "    if do_x: x = normalize(x,mean,std)\n",
    "    if do_y and len(y.shape) == 4: y = normalize(y,mean,std)\n",
    "    return (x,cint,pgint,expint),y\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:41.722575Z",
     "start_time": "2019-09-03T16:31:41.713153Z"
    }
   },
   "outputs": [],
   "source": [
    "#data.batch_stats() # DOES NOT WORK?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:41.734222Z",
     "start_time": "2019-09-03T16:31:41.723533Z"
    }
   },
   "outputs": [],
   "source": [
    "# From https://github.com/recursionpharma/rxrx1-utils/blob/master/rxrx/main.py\n",
    "# The mean and stds for each of the channels\n",
    "GLOBAL_PIXEL_STATS = (np.array([6.74696984, 14.74640167, 10.51260864,\n",
    "                                10.45369445,  5.49959796, 9.81545561]),\n",
    "                       np.array([7.95876312, 12.17305868, 5.86172946,\n",
    "                                 7.83451711, 4.701167, 5.43130431]))\n",
    "\n",
    "stats_mean = torch.tensor(GLOBAL_PIXEL_STATS[0]/255).float()\n",
    "stats_var = torch.tensor(GLOBAL_PIXEL_STATS[1]/255).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:41.744631Z",
     "start_time": "2019-09-03T16:31:41.735172Z"
    }
   },
   "outputs": [],
   "source": [
    "#stats_mean, stats_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:41.755022Z",
     "start_time": "2019-09-03T16:31:41.745647Z"
    }
   },
   "outputs": [],
   "source": [
    "# 3d to 6d from old/rcic_multicat_v9_resnet50-pretrained_colaug.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:41.765735Z",
     "start_time": "2019-09-03T16:31:41.755981Z"
    }
   },
   "outputs": [],
   "source": [
    "from efficientnet_pytorch.utils import get_same_padding_conv2d, round_filters, round_repeats, relu_fn\n",
    "from efficientnet_pytorch.model import MBConvBlock, load_pretrained_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:41.785146Z",
     "start_time": "2019-09-03T16:31:41.766797Z"
    }
   },
   "outputs": [],
   "source": [
    "# put feature extractor into forward method\n",
    "class EfficientNet(nn.Module):\n",
    "    \"\"\"\n",
    "    An EfficientNet model. Most easily loaded with the .from_name or .from_pretrained methods\n",
    "    Args:\n",
    "        blocks_args (list): A list of BlockArgs to construct blocks\n",
    "        global_params (namedtuple): A set of GlobalParams shared between blocks\n",
    "    Example:\n",
    "        model = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, blocks_args=None, global_params=None):\n",
    "        super().__init__()\n",
    "        assert isinstance(blocks_args, list), 'blocks_args should be a list'\n",
    "        assert len(blocks_args) > 0, 'block args must be greater than 0'\n",
    "        self._global_params = global_params\n",
    "        self._blocks_args = blocks_args\n",
    "\n",
    "        # Get static or dynamic convolution depending on image size\n",
    "        Conv2d = get_same_padding_conv2d(image_size=global_params.image_size)\n",
    "\n",
    "        # Batch norm parameters\n",
    "        bn_mom = 1 - self._global_params.batch_norm_momentum\n",
    "        bn_eps = self._global_params.batch_norm_epsilon\n",
    "\n",
    "        # Stem\n",
    "        in_channels = 3  # rgb\n",
    "        out_channels = round_filters(32, self._global_params)  # number of output channels\n",
    "        self._conv_stem = Conv2d(in_channels, out_channels, kernel_size=3, stride=2, bias=False)\n",
    "        self._bn0 = nn.BatchNorm2d(num_features=out_channels, momentum=bn_mom, eps=bn_eps)\n",
    "\n",
    "        # Build blocks\n",
    "        self._blocks = nn.ModuleList([])\n",
    "        for block_args in self._blocks_args:\n",
    "\n",
    "            # Update block input and output filters based on depth multiplier.\n",
    "            block_args = block_args._replace(\n",
    "                input_filters=round_filters(block_args.input_filters, self._global_params),\n",
    "                output_filters=round_filters(block_args.output_filters, self._global_params),\n",
    "                num_repeat=round_repeats(block_args.num_repeat, self._global_params)\n",
    "            )\n",
    "\n",
    "            # The first block needs to take care of stride and filter size increase.\n",
    "            self._blocks.append(MBConvBlock(block_args, self._global_params))\n",
    "            if block_args.num_repeat > 1:\n",
    "                block_args = block_args._replace(input_filters=block_args.output_filters, stride=1)\n",
    "            for _ in range(block_args.num_repeat - 1):\n",
    "                self._blocks.append(MBConvBlock(block_args, self._global_params))\n",
    "\n",
    "        # Head\n",
    "        in_channels = block_args.output_filters  # output of final block\n",
    "        out_channels = round_filters(1280, self._global_params)\n",
    "        self._conv_head = Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self._bn1 = nn.BatchNorm2d(num_features=out_channels, momentum=bn_mom, eps=bn_eps)\n",
    "\n",
    "        # Final linear layer\n",
    "        #self._dropout = self._global_params.dropout_rate\n",
    "        #self._fc = nn.Linear(out_channels, self._global_params.num_classes)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\" Returns output of the final convolution layer \"\"\"\n",
    "\n",
    "        # Stem\n",
    "        x = relu_fn(self._bn0(self._conv_stem(inputs)))\n",
    "\n",
    "        # Blocks\n",
    "        for idx, block in enumerate(self._blocks):\n",
    "            drop_connect_rate = self._global_params.drop_connect_rate\n",
    "            if drop_connect_rate:\n",
    "                drop_connect_rate *= float(idx) / len(self._blocks)\n",
    "            x = block(x, drop_connect_rate=drop_connect_rate)\n",
    "\n",
    "        # Head\n",
    "        x = relu_fn(self._bn1(self._conv_head(x)))\n",
    "\n",
    "        return x\n",
    "\n",
    "    #def forward(self, inputs):\n",
    "    #    \"\"\" Calls extract_features to extract features, applies final linear layer, and returns logits. \"\"\"\n",
    "    #\n",
    "    #    # Convolution layers\n",
    "    #    x = self.extract_features(inputs)\n",
    "    #\n",
    "    #    # Pooling and final linear layer\n",
    "    #    x = F.adaptive_avg_pool2d(x, 1).squeeze(-1).squeeze(-1)\n",
    "    #    if self._dropout:\n",
    "    #        x = F.dropout(x, p=self._dropout, training=self.training)\n",
    "    #    x = self._fc(x)\n",
    "    #    return x\n",
    "\n",
    "    @classmethod\n",
    "    def from_name(cls, model_name, override_params=None):\n",
    "        cls._check_model_name_is_valid(model_name)\n",
    "        blocks_args, global_params = get_model_params(model_name, override_params)\n",
    "        return EfficientNet(blocks_args, global_params)\n",
    "\n",
    "    @classmethod\n",
    "    def from_pretrained(cls, model_name, num_classes=1000):\n",
    "        model = EfficientNet.from_name(model_name, override_params={'num_classes': num_classes})\n",
    "        load_pretrained_weights(model, model_name, load_fc=(num_classes == 1000))\n",
    "        return model\n",
    "\n",
    "    @classmethod\n",
    "    def get_image_size(cls, model_name):\n",
    "        cls._check_model_name_is_valid(model_name)\n",
    "        _, _, res, _ = efficientnet_params(model_name)\n",
    "        return res\n",
    "\n",
    "    @classmethod\n",
    "    def _check_model_name_is_valid(cls, model_name, also_need_pretrained_weights=False):\n",
    "        \"\"\" Validates model name. None that pretrained weights are only available for\n",
    "        the first four models (efficientnet-b{i} for i in 0,1,2,3) at the moment. \"\"\"\n",
    "        num_models = 4 if also_need_pretrained_weights else 8\n",
    "        valid_models = ['efficientnet_b'+str(i) for i in range(num_models)]\n",
    "        if model_name.replace('-','_') not in valid_models:\n",
    "            raise ValueError('model_name should be one of: ' + ', '.join(valid_models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:41.795882Z",
     "start_time": "2019-09-03T16:31:41.786130Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils import model_zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:41.806736Z",
     "start_time": "2019-09-03T16:31:41.796835Z"
    }
   },
   "outputs": [],
   "source": [
    "url_map = {\n",
    "    'efficientnet-b0': 'http://storage.googleapis.com/public-models/efficientnet/efficientnet-b0-355c32eb.pth',\n",
    "    'efficientnet-b1': 'http://storage.googleapis.com/public-models/efficientnet/efficientnet-b1-f1951068.pth',\n",
    "    'efficientnet-b2': 'http://storage.googleapis.com/public-models/efficientnet/efficientnet-b2-8bb594d6.pth',\n",
    "    'efficientnet-b3': 'http://storage.googleapis.com/public-models/efficientnet/efficientnet-b3-5fb5a3c3.pth',\n",
    "    'efficientnet-b4': 'http://storage.googleapis.com/public-models/efficientnet/efficientnet-b4-6ed6700e.pth',\n",
    "    'efficientnet-b5': 'http://storage.googleapis.com/public-models/efficientnet/efficientnet-b5-b6417697.pth',\n",
    "    'efficientnet-b6': 'http://storage.googleapis.com/public-models/efficientnet/efficientnet-b6-c76e70fd.pth',\n",
    "    'efficientnet-b7': 'http://storage.googleapis.com/public-models/efficientnet/efficientnet-b7-dcc49843.pth',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:41.818025Z",
     "start_time": "2019-09-03T16:31:41.807700Z"
    }
   },
   "outputs": [],
   "source": [
    "# adapt load function to only load weights for feature extractor stage\n",
    "def load_pretrained_weights(model, model_name, load_fc=True):\n",
    "    \"\"\" Loads pretrained weights, and downloads if loading for the first time. \"\"\"\n",
    "    state_dict = model_zoo.load_url(url_map[model_name])\n",
    "    #if load_fc:\n",
    "    #    model.load_state_dict(state_dict)\n",
    "    #else:\n",
    "    state_dict.pop('_fc.weight')\n",
    "    state_dict.pop('_fc.bias')\n",
    "    res = model.load_state_dict(state_dict, strict=False)\n",
    "        #assert str(res.missing_keys) == str(['_fc.weight', '_fc.bias']), 'issue loading pretrained weights'\n",
    "    print('Loaded pretrained weights for {}'.format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:41.953080Z",
     "start_time": "2019-09-03T16:31:41.818999Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b3\n"
     ]
    }
   ],
   "source": [
    "# b3: input size = 300\n",
    "#efficientnet_b3 = EfficientNet.from_name('efficientnet-b3')\n",
    "efficientnet_f = EfficientNet.from_pretrained('efficientnet-b3')\n",
    "#efficientnet_b4f = EfficientNet.from_pretrained('efficientnet-b4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:41.963668Z",
     "start_time": "2019-09-03T16:31:41.953998Z"
    }
   },
   "outputs": [],
   "source": [
    "#efficientnet_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:41.975072Z",
     "start_time": "2019-09-03T16:31:41.964615Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Conv2dStaticSamePadding(\n",
       "   3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "   (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       " ), efficientnet_pytorch.utils.Conv2dStaticSamePadding)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficientnet_f._conv_stem, type(efficientnet_f._conv_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:41.986942Z",
     "start_time": "2019-09-03T16:31:41.976034Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2dStaticSamePadding(\n",
       "  6, 40, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "  (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       ")"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.Conv2dStaticSamePadding(6, 40, kernel_size=(3, 3), stride=(2, 2), bias=False, image_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:42.004587Z",
     "start_time": "2019-09-03T16:31:41.994075Z"
    }
   },
   "outputs": [],
   "source": [
    "p_dict = {pn: p for pn, p in efficientnet_f._conv_stem.named_parameters()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:42.020104Z",
     "start_time": "2019-09-03T16:31:42.008617Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['weight'])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:42.034284Z",
     "start_time": "2019-09-03T16:31:42.022780Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([40, 3, 3, 3]), True)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_dict['weight'].shape, p_dict['weight'].requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:42.047308Z",
     "start_time": "2019-09-03T16:31:42.036946Z"
    }
   },
   "outputs": [],
   "source": [
    "old_weight = p_dict['weight'].detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:42.061652Z",
     "start_time": "2019-09-03T16:31:42.050038Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([40, 3, 3, 3]), False)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_weight.shape, old_weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:42.074750Z",
     "start_time": "2019-09-03T16:31:42.064433Z"
    }
   },
   "outputs": [],
   "source": [
    "new_weight = torch.cat((old_weight, old_weight), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:42.089076Z",
     "start_time": "2019-09-03T16:31:42.077492Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([40, 6, 3, 3]), False)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_weight.shape, new_weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:42.103779Z",
     "start_time": "2019-09-03T16:31:42.091861Z"
    }
   },
   "outputs": [],
   "source": [
    "def show_input_stage_weights(weight=None, nrows=2, ncols=3):\n",
    "    fig, ax = plt.subplots(nrows=nrows, ncols=ncols)\n",
    "    k = 0\n",
    "    for i in range(nrows):\n",
    "        for j in range(ncols):\n",
    "            if nrows > 1:\n",
    "                ax[i,j].set_title(k)\n",
    "                ax[i,j].imshow(weight[0][k])\n",
    "                ax[i,j].axis(\"off\")\n",
    "            else:\n",
    "                ax[j].set_title(k)\n",
    "                ax[j].imshow(weight[0][k])\n",
    "                ax[j].axis(\"off\")\n",
    "            k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:42.116654Z",
     "start_time": "2019-09-03T16:31:42.106493Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot old_weight\n",
    "#show_input_stage_weights(old_weight, nrows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:42.129371Z",
     "start_time": "2019-09-03T16:31:42.119390Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot new_weight\n",
    "#show_input_stage_weights(new_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:42.142957Z",
     "start_time": "2019-09-03T16:31:42.132146Z"
    }
   },
   "outputs": [],
   "source": [
    "# replace first conv layer with a 6-channel version\n",
    "efficientnet_f._conv_stem = utils.Conv2dStaticSamePadding(6, 40, kernel_size=(3, 3),\n",
    "                                                          stride=(2, 2), bias=False, image_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:42.156825Z",
     "start_time": "2019-09-03T16:31:42.145660Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2dStaticSamePadding(\n",
       "  6, 40, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "  (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       ")"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficientnet_f._conv_stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:42.168267Z",
     "start_time": "2019-09-03T16:31:42.157847Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 6, 3, 3])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficientnet_f._conv_stem.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:42.178723Z",
     "start_time": "2019-09-03T16:31:42.169221Z"
    }
   },
   "outputs": [],
   "source": [
    "# set new_weights to nn.Parameter and overwrite it in the conv layer\n",
    "efficientnet_f._conv_stem.weight = nn.Parameter(new_weight) # hand over requires_grad False?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:42.189395Z",
     "start_time": "2019-09-03T16:31:42.179759Z"
    }
   },
   "outputs": [],
   "source": [
    "# check if weight was loaded properly\n",
    "assert torch.allclose(new_weight, efficientnet_f._conv_stem.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:42.200814Z",
     "start_time": "2019-09-03T16:31:42.190420Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([40, 6, 3, 3]), True)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficientnet_f._conv_stem.weight.shape, efficientnet_f._conv_stem.weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:42.211036Z",
     "start_time": "2019-09-03T16:31:42.201852Z"
    }
   },
   "outputs": [],
   "source": [
    "# network is in full train mode!\n",
    "#[p.requires_grad for p in efficientnet_b3f.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:42.222047Z",
     "start_time": "2019-09-03T16:31:42.212139Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_rg(model=efficientnet_f, option=False):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:42.233234Z",
     "start_time": "2019-09-03T16:31:42.223036Z"
    }
   },
   "outputs": [],
   "source": [
    "# set requires grad for the efficientnet to false (to later only set it true for the input)\n",
    "# WE WILL NOT DO THIS, because it should be not necessary!\n",
    "set_rg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:42.243660Z",
     "start_time": "2019-09-03T16:31:42.234235Z"
    }
   },
   "outputs": [],
   "source": [
    "# network is frozen\n",
    "#[p.requires_grad for p in efficientnet_b4f.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:42.254653Z",
     "start_time": "2019-09-03T16:31:42.244676Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficientnet_f._conv_stem.weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:42.265117Z",
     "start_time": "2019-09-03T16:31:42.255634Z"
    }
   },
   "outputs": [],
   "source": [
    "# set input stage to trainable\n",
    "#efficientnet_f._conv_stem.weight.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:42.275273Z",
     "start_time": "2019-09-03T16:31:42.266044Z"
    }
   },
   "outputs": [],
   "source": [
    "#efficientnet_f._conv_stem.weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:42.408056Z",
     "start_time": "2019-09-03T16:31:42.276239Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1536, 9, 9])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficientnet_f(torch.randn(1,6,sz,sz)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EfficientNet Pre-Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:42.420291Z",
     "start_time": "2019-09-03T16:31:42.409954Z"
    }
   },
   "outputs": [],
   "source": [
    "def resnet_pre_head(concat_pool:bool=True):\n",
    "    pool = AdaptiveConcatPool2d() if concat_pool else nn.AdaptiveAvgPool2d(1)\n",
    "    layers = [pool, Flatten()]\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:42.431027Z",
     "start_time": "2019-09-03T16:31:42.421234Z"
    }
   },
   "outputs": [],
   "source": [
    "efficientnet_f_prehead = resnet_pre_head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:42.442072Z",
     "start_time": "2019-09-03T16:31:42.431954Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): AdaptiveConcatPool2d(\n",
       "    (ap): AdaptiveAvgPool2d(output_size=1)\n",
       "    (mp): AdaptiveMaxPool2d(output_size=1)\n",
       "  )\n",
       "  (1): Flatten()\n",
       ")"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficientnet_f_prehead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:42.455137Z",
     "start_time": "2019-09-03T16:31:42.442994Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3072])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficientnet_f_prehead(torch.randn(2, 1536, 9, 9)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:42.465851Z",
     "start_time": "2019-09-03T16:31:42.456172Z"
    }
   },
   "outputs": [],
   "source": [
    "efficientnet_fph = nn.Sequential(efficientnet_f, efficientnet_f_prehead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:42.598371Z",
     "start_time": "2019-09-03T16:31:42.466792Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3072])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficientnet_fph(torch.randn(1,6,sz,sz)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CellType & Plate Group Feature Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:42.609938Z",
     "start_time": "2019-09-03T16:31:42.599391Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exps = len(set([exp2int[i] for i in exp2int])); exps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:42.624673Z",
     "start_time": "2019-09-03T16:31:42.610885Z"
    }
   },
   "outputs": [],
   "source": [
    "class CellTypePlateGroupFeatures(nn.Module):\n",
    "    '''CellType Feature Extractor.'''\n",
    "    def __init__(self, cell_types=4, plate_groups=4, exps=exps, emb_sz=128):\n",
    "        super(CellTypePlateGroupFeatures, self).__init__()\n",
    "        self.emb_ctint = nn.Embedding(cell_types, emb_sz)\n",
    "        self.emb_pgint = nn.Embedding(plate_groups, emb_sz)\n",
    "        self.emb_expint = nn.Embedding(exps, emb_sz)\n",
    "        \n",
    "    def forward(self, xb_ctint, xb_pgint, xb_expint, yb=None): # yb=None for training in non-AdaCos mode!\n",
    "        \n",
    "        ### CTINT\n",
    "        # check if we are in CutMix mode:\n",
    "        if isinstance(xb_ctint, tuple):\n",
    "            x1, x2, λ = xb_ctint\n",
    "            out1 = self.emb_ctint(x1)\n",
    "            out2 = self.emb_ctint(x2)\n",
    "            out_ctint = out1 * λ + out2 * (1-λ)\n",
    "        else: # if not CutMix, then normal mode\n",
    "            out_ctint = self.emb_ctint(xb_ctint)\n",
    "        \n",
    "        ## PGINT\n",
    "        # check if we are in CutMix mode:\n",
    "        if isinstance(xb_pgint, tuple):\n",
    "            x1, x2, λ = xb_pgint\n",
    "            out1 = self.emb_pgint(x1)\n",
    "            out2 = self.emb_pgint(x2)\n",
    "            out_pgint = out1 * λ + out2 * (1-λ)\n",
    "        else: # if not CutMix, then normal mode\n",
    "            out_pgint = self.emb_pgint(xb_pgint)\n",
    "            \n",
    "        ## EXPINT\n",
    "        # check if we are in CutMix mode:\n",
    "        if isinstance(xb_expint, tuple):\n",
    "            x1, x2, λ = xb_expint\n",
    "            out1 = self.emb_expint(x1)\n",
    "            out2 = self.emb_expint(x2)\n",
    "            out_expint = out1 * λ + out2 * (1-λ)\n",
    "        else: # if not CutMix, then normal mode\n",
    "            out_expint = self.emb_expint(xb_expint)\n",
    "        \n",
    "        out = torch.cat((out_ctint, out_pgint,  out_expint), dim=-1)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:42.635522Z",
     "start_time": "2019-09-03T16:31:42.625606Z"
    }
   },
   "outputs": [],
   "source": [
    "ctf = CellTypePlateGroupFeatures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:42.646579Z",
     "start_time": "2019-09-03T16:31:42.636445Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CellTypePlateGroupFeatures(\n",
       "  (emb_ctint): Embedding(4, 128)\n",
       "  (emb_pgint): Embedding(4, 128)\n",
       "  (emb_expint): Embedding(26, 128)\n",
       ")"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:42.657500Z",
     "start_time": "2019-09-03T16:31:42.647491Z"
    }
   },
   "outputs": [],
   "source": [
    "xb = (torch.tensor(ct2int['HEPG2']),\n",
    "      torch.tensor(fn2pgint['train/HEPG2-01/Plate1/B03_s1']),\n",
    "      torch.tensor(exp2int['train/HEPG2-01/Plate1/B03_s1'.split('/')[1]])\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:42.668741Z",
     "start_time": "2019-09-03T16:31:42.658414Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(0), tensor(0))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:42.681558Z",
     "start_time": "2019-09-03T16:31:42.669700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([384])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctf(xb[0], xb[1], xb[2]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:42.692771Z",
     "start_time": "2019-09-03T16:31:42.682889Z"
    }
   },
   "outputs": [],
   "source": [
    "xb = (torch.tensor((1,3)), torch.tensor((1,3)), torch.tensor((1,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:42.704027Z",
     "start_time": "2019-09-03T16:31:42.693714Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 3]), tensor([1, 3]), tensor([1, 3]))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:42.715498Z",
     "start_time": "2019-09-03T16:31:42.704975Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 384])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctf(xb[0], xb[1], xb[2]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:42.726688Z",
     "start_time": "2019-09-03T16:31:42.716452Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 2)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct2int['HEPG2'], ct2int['RPE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:42.737858Z",
     "start_time": "2019-09-03T16:31:42.727637Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn2pgint['train/HEPG2-01/Plate1/B03_s1'], fn2pgint['train/RPE-01/Plate1/B03_s1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:42.749068Z",
     "start_time": "2019-09-03T16:31:42.738847Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 19)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp2int['HEPG2-01'], exp2int['RPE-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:42.760383Z",
     "start_time": "2019-09-03T16:31:42.750039Z"
    }
   },
   "outputs": [],
   "source": [
    "xb = ((torch.tensor(ct2int['HEPG2']), torch.tensor(ct2int['RPE']), 0.9),\n",
    "      (torch.tensor(fn2pgint['train/HEPG2-01/Plate1/B03_s1']),\n",
    "       torch.tensor(fn2pgint['train/RPE-01/Plate1/B03_s1']), 0.9),\n",
    "      (torch.tensor(exp2int['HEPG2-01']),\n",
    "       torch.tensor(exp2int['RPE-01']), 0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:42.771987Z",
     "start_time": "2019-09-03T16:31:42.761363Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([384])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctf(xb[0], xb[1], xb[2]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:42.782520Z",
     "start_time": "2019-09-03T16:31:42.772963Z"
    }
   },
   "outputs": [],
   "source": [
    "#class CellTypeFeatures(nn.Module):\n",
    "#    '''CellType Feature Extractor.'''\n",
    "#    def __init__(self, cell_types=4, emb_sz=128, lin_ftrs:Optional[Collection[int]]=None, nc=128):\n",
    "#        super(AdaCosNet, self).__init__()\n",
    "#        self.emb = nn.Embedding(cell_types, emb_sz)\n",
    "#        \n",
    "#        self.lin_ftrs = [emb_sz, 512, 512] if lin_ftrs is None else [emb_sz] + lin_ftrs + [nc]\n",
    "#\n",
    "#        \n",
    "#    def forward(self, xb, yb=None): # yb=None for training in non-AdaCos mode!\n",
    "#\n",
    "#        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaCos-Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:42.795647Z",
     "start_time": "2019-09-03T16:31:42.783521Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_adacos_head(nf:int, lin_ftrs:Optional[Collection[int]]=None, ps:Floats=0.5,\n",
    "                bn_final:bool=False): # concat_pool:bool=True, nc:int,\n",
    "    \"Model head that takes `nf` features, runs through `lin_ftrs`, and about `nc` classes.\"\n",
    "    \n",
    "    # ADDED TWO MORE 512 LAYERS !!!\n",
    "    lin_ftrs = [nf, 512, 512, 512, 512] if lin_ftrs is None else [nf] + lin_ftrs + [nc]\n",
    "    # remove last 512 fc layer to reduce MODEL SIZE ??? ???\n",
    "    \n",
    "    ps = listify(ps)\n",
    "    if len(ps) == 1: ps = [ps[0]/2] * (len(lin_ftrs)-2) + ps\n",
    "    actns = [nn.ReLU(inplace=True)] * (len(lin_ftrs)-2) + [None]\n",
    "    #pool = AdaptiveConcatPool2d() if concat_pool else nn.AdaptiveAvgPool2d(1)\n",
    "    #layers = [pool, Flatten()]\n",
    "    layers = []\n",
    "    for ni,no,p,actn in zip(lin_ftrs[:-1], lin_ftrs[1:], ps, actns):\n",
    "        layers += bn_drop_lin(ni, no, True, p, actn)\n",
    "    if bn_final: layers.append(nn.BatchNorm1d(lin_ftrs[-1], momentum=0.01))\n",
    "    #layers.append(AdaCos(lin_ftrs[-1], nc))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:42.819189Z",
     "start_time": "2019-09-03T16:31:42.796624Z"
    }
   },
   "outputs": [],
   "source": [
    "#adacos_head = create_adacos_head(nf=2048+1) \n",
    "adacos_head = create_adacos_head(nf=1536*2+128*3)\n",
    "# se_xresnet50f: 2048*2=4096, ctf: 128*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:42.830221Z",
     "start_time": "2019-09-03T16:31:42.820243Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): BatchNorm1d(3456, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (1): Dropout(p=0.25)\n",
       "  (2): Linear(in_features=3456, out_features=512, bias=True)\n",
       "  (3): ReLU(inplace)\n",
       "  (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (5): Dropout(p=0.25)\n",
       "  (6): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (7): ReLU(inplace)\n",
       "  (8): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (9): Dropout(p=0.25)\n",
       "  (10): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (11): ReLU(inplace)\n",
       "  (12): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (13): Dropout(p=0.5)\n",
       "  (14): Linear(in_features=512, out_features=512, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adacos_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:42.840427Z",
     "start_time": "2019-09-03T16:31:42.831194Z"
    }
   },
   "outputs": [],
   "source": [
    "#adacos_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:42.854443Z",
     "start_time": "2019-09-03T16:31:42.841423Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 512])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adacos_head(torch.randn(2, 1536*2+128*3)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:42.872719Z",
     "start_time": "2019-09-03T16:31:42.855374Z"
    }
   },
   "outputs": [],
   "source": [
    "# from https://github.com/4uiiurz1/pytorch-adacos/blob/master/metrics.py\n",
    "class AdaCos(nn.Module):\n",
    "    def __init__(self, num_features, num_classes, m=0.50):\n",
    "        super(AdaCos, self).__init__()\n",
    "        self.num_features = num_features\n",
    "        self.n_classes = num_classes\n",
    "        self.s = math.sqrt(2) * math.log(num_classes - 1)\n",
    "        self.m = m\n",
    "        self.We = nn.Parameter(torch.FloatTensor(num_classes, num_features))\n",
    "        nn.init.xavier_uniform_(self.We)\n",
    "\n",
    "    def forward(self, xb, yb):\n",
    "        \n",
    "        #print(yb.shape)\n",
    "        #pdb.set_trace()\n",
    "        \n",
    "        # normalize features\n",
    "        x = F.normalize(xb)\n",
    "        # normalize weights\n",
    "        W = F.normalize(self.We)\n",
    "        # dot product\n",
    "        logits = F.linear(x, W)\n",
    "        \n",
    "        # for training in non-AdaCos mode (= no yb date in the forward pass):\n",
    "        if yb is None:\n",
    "            print('yb = None')\n",
    "            return logits\n",
    "        \n",
    "        # feature re-scale\n",
    "        theta = torch.acos(torch.clamp(logits, -1.0 + 1e-7, 1.0 - 1e-7))\n",
    "        one_hot = torch.zeros_like(logits)\n",
    "        \n",
    "        # ORIGINAL\n",
    "        #one_hot.scatter_(1, yb.view(-1, 1).long(), 1)\n",
    "        #with torch.no_grad():\n",
    "        #    B_avg = torch.where(one_hot < 1, torch.exp(self.s * logits), torch.zeros_like(logits))\n",
    "        #    B_avg = torch.sum(B_avg) / xb.size(0)\n",
    "        #    #print(B_avg)\n",
    "        #    theta_med = torch.median(theta[one_hot == 1])\n",
    "        #    self.s = torch.log(B_avg) / torch.cos(torch.min(math.pi/4 * torch.ones_like(theta_med), theta_med))\n",
    "        #    #print(self.s)\n",
    "            \n",
    "        # ADAPTED FOR CUTMIX TO GET MIXED SCALE PARAMETER\n",
    "        with torch.no_grad():\n",
    "            # FROM nb_new_data_augmentation_adacos2.py LINE 888\n",
    "            # AND https://github.com/fastai/fastai/blob/master/fastai/callbacks/mixup.py#L40\n",
    "            if yb.ndim == 2:# and target.shape[-1] >1:\n",
    "                n_mod_patches = (yb.shape[-1] - 1) // 2\n",
    "                #c_ = yb[:, 1:n_mod_patches + 1]\n",
    "                c_ = yb[:, 0:n_mod_patches + 1]\n",
    "                W_ = yb[:, n_mod_patches + 1:]\n",
    "                self.s_scaled = []\n",
    "                \n",
    "                # this loop is only realdy needed when we have different probabilities inside a batch\n",
    "                # which we do not have (right now)! So this could be cleaned up, but we leave until\n",
    "                # we know we will not need the case with different probabilities in a batch.\n",
    "                for k in range(n_mod_patches+1):\n",
    "                    yb_new = c_[:, k].long()\n",
    "                    #pdb.set_trace()\n",
    "                    \n",
    "                    one_hot.scatter_(1, yb_new.view(-1,1).long(), 1)\n",
    "                    \n",
    "                    B_avg = torch.where(one_hot < 1, torch.exp(self.s * logits), torch.zeros_like(logits))\n",
    "                    B_avg = torch.sum(B_avg) / xb.size(0)\n",
    "                    theta_med = torch.median(theta[one_hot == 1])\n",
    "                    self.s = torch.log(B_avg) / torch.cos(torch.min(math.pi/4 * torch.ones_like(theta_med), theta_med))\n",
    "                    \n",
    "                    if k+1 == len(range(n_mod_patches+1)):\n",
    "                        #self.s_scaled.append((1-W_[:, k-1]) * self.s)\n",
    "                        self.s_scaled.append((1-W_[0, k-1]) * self.s)\n",
    "                        # For more than two the sum of W_[:, :k] has to be used!!!\n",
    "                    else:\n",
    "                        #self.s_scaled.append(W_[:, k] * self.s)\n",
    "                        self.s_scaled.append(W_[0, k] * self.s)\n",
    "                    # Mixed B_avg & self.s and single are not really far off, but now we have it coded\n",
    "                    # se we keep it (until it breaks something later).\n",
    "                self.s = torch.add(*self.s_scaled)\n",
    "                # Clean up, self.s_scaled is just a vector with the same entry multiple times\n",
    "                # when it is not indexed above with W_[0,... !\n",
    "            else:\n",
    "                one_hot.scatter_(1, yb.view(-1,1).long(), 1)\n",
    "                B_avg = torch.where(one_hot < 1, torch.exp(self.s * logits), torch.zeros_like(logits))\n",
    "                B_avg = torch.sum(B_avg) / xb.size(0)\n",
    "                theta_med = torch.median(theta[one_hot == 1])\n",
    "                self.s = torch.log(B_avg) / torch.cos(torch.min(math.pi/4 * torch.ones_like(theta_med), theta_med))\n",
    "        \n",
    "        output = self.s * logits\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:42.885071Z",
     "start_time": "2019-09-03T16:31:42.873593Z"
    }
   },
   "outputs": [],
   "source": [
    "class AdaCosNet(nn.Module):\n",
    "    '''Simple AdaCosNet connecter to run xb through the feature extractor head\n",
    "    and then feed xb and yb into the AdaCos layer.'''\n",
    "    def __init__(self, body1, body2, head):\n",
    "        super(AdaCosNet, self).__init__()\n",
    "        self.body1 = body1\n",
    "        self.body2 = body2\n",
    "        self.head = head\n",
    "        self.adacos = AdaCos(512, 277) # was 1108 !!!\n",
    "        \n",
    "    def forward(self, xb, yb=None): # yb=None for training in non-AdaCos mode!\n",
    "        xb_img, xb_ctint, xb_pgint, xb_expint = xb\n",
    "        resnet_features = self.body1(xb_img)\n",
    "        int_features = self.body2(xb_ctint, xb_pgint, xb_expint)\n",
    "        features = torch.cat((resnet_features, int_features), dim=-1)\n",
    "        out = self.head(features)\n",
    "        #print('xb.shape: ', xb.shape,', yb.shape: ', yb.shape)\n",
    "        out = self.adacos(out, yb)\n",
    "        #print('out: ',out.shape)\n",
    "        #pdb.set_trace()\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:42.896625Z",
     "start_time": "2019-09-03T16:31:42.886006Z"
    }
   },
   "outputs": [],
   "source": [
    "adacos_efficientnet = AdaCosNet(efficientnet_fph, ctf, adacos_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:42.913746Z",
     "start_time": "2019-09-03T16:31:42.897584Z"
    }
   },
   "outputs": [],
   "source": [
    "xb = (torch.randn(2,6,sz,sz),\n",
    "      #(torch.randint(4, (2,1)),  torch.randint(4, (2,1)))\n",
    "      torch.tensor((1,3)), torch.tensor((1,3)), torch.tensor((1,3))\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.127566Z",
     "start_time": "2019-09-03T16:31:42.914715Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yb = None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 277])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adacos_efficientnet(xb).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.344023Z",
     "start_time": "2019-09-03T16:31:43.128554Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 277])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adacos_efficientnet(xb, torch.tensor([276, 1])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.355217Z",
     "start_time": "2019-09-03T16:31:43.344994Z"
    }
   },
   "outputs": [],
   "source": [
    "test_target = torch.tensor(\n",
    "    [[2.4700e+02, 2.3900e+02, 7.8362e-01],\n",
    "     [2.3300e+02, 1.7400e+02, 7.8362e-01],\n",
    "     [1.7400e+02, 1.3400e+02, 7.8362e-01],\n",
    "     [1.9800e+02, 1.4700e+02, 7.8362e-01]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.762766Z",
     "start_time": "2019-09-03T16:31:43.356147Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 277])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adacos_efficientnet((torch.randn(4,6,sz,sz), \n",
    "                     torch.tensor((1,3,0,2)), torch.tensor((1,3,0,2)), torch.tensor((1,3,0,2))),\n",
    "                    test_target).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.776700Z",
     "start_time": "2019-09-03T16:31:43.765403Z"
    }
   },
   "outputs": [],
   "source": [
    "# Based on https://forums.fast.ai/t/teacher-forcing/29415/4\n",
    "# https://forums.fast.ai/t/on-batch-begin-callback/35201/3\n",
    "@dataclass\n",
    "class AppendBatchTargs(Callback):\n",
    "    learn:Learner\n",
    "    def __init__(self, learn):\n",
    "        super().__init__()\n",
    "    def on_batch_begin(self, last_input, last_target, **kwargs):\n",
    "        return {'last_input':(last_input, last_target), 'last_target':last_target}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.790091Z",
     "start_time": "2019-09-03T16:31:43.779324Z"
    }
   },
   "outputs": [],
   "source": [
    "#def check_rg(model=learn.model):\n",
    "#    layer_rg = [(n, p.requires_grad) for n,p in model.named_parameters()]\n",
    "#    for i in range(len(layer_rg)):\n",
    "#        print(f'{layer_rg[i][0]}\\t{layer_rg[i][1]}'.expandtabs(45))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.889712Z",
     "start_time": "2019-09-03T16:31:43.792796Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xxx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-129-38170c08cb45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxxx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'xxx' is not defined"
     ]
    }
   ],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:33:16.979499Z",
     "start_time": "2019-09-03T16:33:16.962811Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HEPG2', 'HUVEC', 'RPE', 'U2OS']"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.895495Z",
     "start_time": "2019-09-03T16:31:40.894Z"
    }
   },
   "outputs": [],
   "source": [
    "# pg0 for 'HEPG2', 'HUVEC', 'RPE ==> OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-03T16:37:00.614Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ===  0  ===  HEPG2  === \n",
      " ===  0  ===  HUVEC  === \n",
      " ===  0  ===  RPE  === \n",
      " ===  0  ===  U2OS  === \n",
      " ===  1  ===  HEPG2  === \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.575806</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.134414</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.537444</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.114348</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.875533</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.675548</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.594656</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.516391</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.405310</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.354261</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.379980</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.378733</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.290502</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.238196</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.263579</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.214921</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.252473</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.191961</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.192394</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.196700</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.182801</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.212266</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.179190</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1.157790</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.166117</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ===  1  ===  HUVEC  === \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.179153</td>\n",
       "      <td>#na#</td>\n",
       "      <td>02:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.105570</td>\n",
       "      <td>#na#</td>\n",
       "      <td>02:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.078648</td>\n",
       "      <td>#na#</td>\n",
       "      <td>02:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.079309</td>\n",
       "      <td>#na#</td>\n",
       "      <td>02:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.082279</td>\n",
       "      <td>#na#</td>\n",
       "      <td>02:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.036964</td>\n",
       "      <td>#na#</td>\n",
       "      <td>02:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.990002</td>\n",
       "      <td>#na#</td>\n",
       "      <td>02:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.994666</td>\n",
       "      <td>#na#</td>\n",
       "      <td>02:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.016169</td>\n",
       "      <td>#na#</td>\n",
       "      <td>02:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.974039</td>\n",
       "      <td>#na#</td>\n",
       "      <td>02:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.981480</td>\n",
       "      <td>#na#</td>\n",
       "      <td>02:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.975387</td>\n",
       "      <td>#na#</td>\n",
       "      <td>02:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.985926</td>\n",
       "      <td>#na#</td>\n",
       "      <td>02:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.971428</td>\n",
       "      <td>#na#</td>\n",
       "      <td>02:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.961500</td>\n",
       "      <td>#na#</td>\n",
       "      <td>02:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.928487</td>\n",
       "      <td>#na#</td>\n",
       "      <td>02:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.924839</td>\n",
       "      <td>#na#</td>\n",
       "      <td>02:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.919415</td>\n",
       "      <td>#na#</td>\n",
       "      <td>02:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.897592</td>\n",
       "      <td>#na#</td>\n",
       "      <td>02:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.921779</td>\n",
       "      <td>#na#</td>\n",
       "      <td>02:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.893193</td>\n",
       "      <td>#na#</td>\n",
       "      <td>02:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.911747</td>\n",
       "      <td>#na#</td>\n",
       "      <td>02:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.882440</td>\n",
       "      <td>#na#</td>\n",
       "      <td>02:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.896514</td>\n",
       "      <td>#na#</td>\n",
       "      <td>02:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.905977</td>\n",
       "      <td>#na#</td>\n",
       "      <td>02:24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ===  1  ===  RPE  === \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.129741</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.644353</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.095847</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.777104</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.560135</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.436079</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.402987</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.332352</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.328611</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.317580</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.266112</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.217516</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.174860</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.191827</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.161024</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.138825</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.164224</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.136319</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.113510</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.142025</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.128149</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.062881</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.101132</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1.070505</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.070975</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ===  1  ===  U2OS  === \n",
      " ===  2  ===  HEPG2  === \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='25', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      4.00% [1/25 01:03<25:28]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.854236</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='36' class='' max='242', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      14.88% [36/242 00:10<00:58 3.8682]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for pg in range(4):\n",
    "    for ct in cts:\n",
    "        print(' === ', pg ,' === ', ct , ' === ')\n",
    "        if pg == 0 or ct == 'U2OS': continue\n",
    "\n",
    "        # VALID SPLIT (incl. tfms)\n",
    "        data = (ImageList6Dct.from_df(df_train[(df_train['pg'] == pg) & (df_train['celltype'] == ct)], path='train')\n",
    "        .split_none() # !!!\n",
    "        .label_from_df(cols=-5)\n",
    "        #.add_test(ImageList6Dct.from_df(df_test[(df_test['pg'] == pg) & (df_test['celltype'] == ct)], path='test'))\n",
    "        .transform(tfms, size=sz)\n",
    "        .databunch(bs=bs))\n",
    "        \n",
    "        data.normalize([stats_mean, stats_var]);\n",
    "        \n",
    "        learn = Learner(data, adacos_efficientnet, metrics=[accuracy], callback_fns=[CSVLogger, AppendBatchTargs])\n",
    "        learn.load('effnet/adacos_efficientnet_b3_ct_pg_exp_Pre060e050pg'+str(pg)+'e100_190901');\n",
    "        learn.unfreeze()\n",
    "        learn.fit_one_cycle(25, max_lr=1e-4)\n",
    "        learn.save('effnet/adacos_efficientnet_b3_ct_pg_exp_Pre060e050pg'+str(pg)+'e100'+ct+'_FULL_025_190903');\n",
    "        \n",
    "        print('')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.899891Z",
     "start_time": "2019-09-03T16:31:40.910Z"
    }
   },
   "outputs": [],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# U2OS fully with all pg! (Because overflow, see below.)\n",
    "ct = 'U2OS'\n",
    "\n",
    "# VALID SPLIT (incl. tfms)\n",
    "data = (ImageList6Dct.from_df(df_train[df_train['celltype'] == ct], path='train')\n",
    ".split_none() # !!!\n",
    ".label_from_df(cols=-5)\n",
    "#.add_test(ImageList6Dct.from_df(df_test[(df_test['pg'] == pg) & (df_test['celltype'] == ct)], path='test'))\n",
    ".transform(tfms, size=sz)\n",
    ".databunch(bs=bs))\n",
    "\n",
    "data.normalize([stats_mean, stats_var]);\n",
    "\n",
    "learn = Learner(data, adacos_efficientnet, metrics=[accuracy], callback_fns=[CSVLogger, AppendBatchTargs])\n",
    "learn.load('effnet/adacos_efficientnet_b3_ct_pg_exp_Pre060e050_190823');\n",
    "learn.unfreeze()\n",
    "\n",
    "learn.fit_one_cycle(25, max_lr=1e-4)\n",
    "learn.save('effnet/adacos_efficientnet_b3_ct_pg_exp_Pre060e050pgALL'+ct+'_FULL_025_190903');\n",
    "\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.902086Z",
     "start_time": "2019-09-03T16:31:40.917Z"
    }
   },
   "outputs": [],
   "source": [
    "# U2OS seems to generate overflow with pg0 all the time!!!\n",
    "pg = 0\n",
    "ct = 'U2OS'\n",
    "\n",
    "# VALID SPLIT (incl. tfms)\n",
    "data = (ImageList6Dct.from_df(df_train[(df_train['pg'] == pg) & (df_train['celltype'] == ct)], path='train')\n",
    ".split_none() # !!!\n",
    ".label_from_df(cols=-5)\n",
    "#.add_test(ImageList6Dct.from_df(df_test[(df_test['pg'] == pg) & (df_test['celltype'] == ct)], path='test'))\n",
    "#.transform(tfms, size=sz)\n",
    ".transform(size=sz)\n",
    ".databunch(bs=bs))\n",
    "\n",
    "data.normalize([stats_mean, stats_var]);\n",
    "\n",
    "learn = Learner(data, adacos_efficientnet, metrics=[accuracy], callback_fns=[CSVLogger, AppendBatchTargs])\n",
    "learn.load('effnet/adacos_efficientnet_b3_ct_pg_exp_Pre060e050pg'+str(pg)+'e100_190901');\n",
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.904280Z",
     "start_time": "2019-09-03T16:31:40.925Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot(suggestion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.906467Z",
     "start_time": "2019-09-03T16:31:40.934Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.fit(25, lr=1e-7)\n",
    "learn.save('effnet/adacos_efficientnet_b3_ct_pg_exp_Pre060e050pg'+str(pg)+'e100'+ct+'_FULL_025_190903');\n",
    "\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lr train ( no 1cycle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.908666Z",
     "start_time": "2019-09-03T16:31:40.943Z"
    }
   },
   "outputs": [],
   "source": [
    "lrs = [1e-5, 1e-5, 1e-5, 1e-5, 1e-3, 1e-4, 1e-4, 1e-3, 1e-3, 1e-6, 1e-4, 1e-4, 1e-4, 1e-6, 1e-4, 1e-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.910862Z",
     "start_time": "2019-09-03T16:31:40.951Z"
    }
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for pg in range(4):\n",
    "    for ct in cts:\n",
    "        \n",
    "        print(' === ', pg ,' === ', ct , ' === ')\n",
    "\n",
    "        # VALID SPLIT (incl. tfms)\n",
    "        data = (ImageList6Dct.from_df(df_train[(df_train['pg'] == pg) & (df_train['celltype'] == ct)], path='train')\n",
    "        #.split_from_df(col=-3)  \n",
    "        .split_none() # FULL !!!\n",
    "        .label_from_df(cols=-5)\n",
    "        #.add_test(ImageList6Dct.from_df(df_test[(df_test['pg'] == pg) & (df_test['celltype'] == ct)], path='test'))\n",
    "        .transform(tfms, size=sz)\n",
    "        .databunch(bs=bs))\n",
    "        \n",
    "        data.normalize([stats_mean, stats_var]);\n",
    "        \n",
    "        learn = Learner(data, adacos_efficientnet, metrics=[accuracy], callback_fns=[CSVLogger, AppendBatchTargs])\n",
    "        learn.load('effnet/adacos_efficientnet_b3_ct_pg_exp_Pre060e050pg'+str(pg)+'e100_190901');\n",
    "        learn.unfreeze()\n",
    "        learn.fit(25, lr=lrs[i])\n",
    "        learn.save('effnet/adacos_efficientnet_b3_ct_pg_exp_Pre060e050pg'+str(pg)+'e100'+ct+'_FULL_025_190903');\n",
    "        i += 1\n",
    "        print('')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.913046Z",
     "start_time": "2019-09-03T16:31:40.958Z"
    }
   },
   "outputs": [],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.915235Z",
     "start_time": "2019-09-03T16:31:40.973Z"
    }
   },
   "outputs": [],
   "source": [
    "for pg in range(4):\n",
    "    for ct in cts:\n",
    "        print(' === ', pg ,' === ', ct , ' === ')\n",
    "        print('train: ', df_train[(df_train['pg'] == pg) & (df_train['celltype'] == ct)].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lrs pg & ct #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.917435Z",
     "start_time": "2019-09-03T16:31:40.983Z"
    }
   },
   "outputs": [],
   "source": [
    "for pg in range(4):\n",
    "    for ct in cts:\n",
    "        print(' === ', pg ,' === ', ct , ' === ')\n",
    "\n",
    "        # VALID SPLIT (incl. tfms)\n",
    "        data = (ImageList6Dct.from_df(df_train[(df_train['pg'] == pg) & (df_train['celltype'] == ct)], path='train')\n",
    "        .split_from_df(col=-3) # FULL: .split_none() # !!!\n",
    "        .label_from_df(cols=-5)\n",
    "        #.add_test(ImageList6Dct.from_df(df_test[(df_test['pg'] == pg) & (df_test['celltype'] == ct)], path='test'))\n",
    "        .transform(tfms, size=sz)\n",
    "        .databunch(bs=bs))\n",
    "        \n",
    "        data.normalize([stats_mean, stats_var]);\n",
    "        \n",
    "        learn = Learner(data, adacos_efficientnet, metrics=[accuracy], callback_fns=[CSVLogger, AppendBatchTargs])\n",
    "        learn.load('effnet/adacos_efficientnet_b3_ct_pg_exp_Pre060e050pg'+str(pg)+'e100_190901');\n",
    "        learn.unfreeze()\n",
    "        \n",
    "        #learn.fit_one_cycle(25, max_lr=1e-4)\n",
    "        #learn.save('effnet/adacos_efficientnet_b3_ct_pg_exp_Pre060e050pg'+str(pg)+'e100'+ct+'025_190902');\n",
    "        \n",
    "        learn.lr_find()\n",
    "        learn.recorder.plot(suggestion=True)\n",
    "        \n",
    "        print('')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.919620Z",
     "start_time": "2019-09-03T16:31:40.990Z"
    }
   },
   "outputs": [],
   "source": [
    "lrs = [1e-5, 1e-5, 1e-5, 1e-5, 1e-3, 1e-4, 1e-4, 1e-3, 1e-3, 1e-6, 1e-4, 1e-4, 1e-4, 1e-6, 1e-4, 1e-4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train pg & ct #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.921809Z",
     "start_time": "2019-09-03T16:31:41.000Z"
    }
   },
   "outputs": [],
   "source": [
    "for pg in range(4):\n",
    "    for ct in cts:\n",
    "        print(' === ', pg ,' === ', ct , ' === ')\n",
    "\n",
    "        # VALID SPLIT (incl. tfms)\n",
    "        data = (ImageList6Dct.from_df(df_train[(df_train['pg'] == pg) & (df_train['celltype'] == ct)], path='train')\n",
    "        .split_from_df(col=-3) # FULL: .split_none() # !!!\n",
    "        .label_from_df(cols=-5)\n",
    "        #.add_test(ImageList6Dct.from_df(df_test[(df_test['pg'] == pg) & (df_test['celltype'] == ct)], path='test'))\n",
    "        .transform(tfms, size=sz)\n",
    "        .databunch(bs=bs))\n",
    "        \n",
    "        data.normalize([stats_mean, stats_var]);\n",
    "        \n",
    "        learn = Learner(data, adacos_efficientnet, metrics=[accuracy], callback_fns=[CSVLogger, AppendBatchTargs])\n",
    "        learn.load('effnet/adacos_efficientnet_b3_ct_pg_exp_Pre060e050pg'+str(pg)+'e100_190901');\n",
    "        learn.unfreeze()\n",
    "        learn.fit_one_cycle(25, max_lr=1e-4)\n",
    "        learn.save('effnet/adacos_efficientnet_b3_ct_pg_exp_Pre060e050pg'+str(pg)+'e100'+ct+'025_190903');\n",
    "        \n",
    "        print('')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.923998Z",
     "start_time": "2019-09-03T16:31:41.008Z"
    }
   },
   "outputs": [],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.926182Z",
     "start_time": "2019-09-03T16:31:41.016Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train[(df_train['pg'] == 0) & (df_train['celltype'] == 'HEPG2')].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Classifcation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.928364Z",
     "start_time": "2019-09-03T16:31:41.027Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.load('resnet50/adacos_se_xresnet50c_val-split-v2_128e040-256e106CMe110_20190729');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.930553Z",
     "start_time": "2019-09-03T16:31:41.034Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get prediction of test dataset\n",
    "preds, _ = learn.get_preds(ds_type=DatasetType.Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.932910Z",
     "start_time": "2019-09-03T16:31:41.042Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# check length\n",
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.935136Z",
     "start_time": "2019-09-03T16:31:41.049Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get the categories\n",
    "preds_cat = preds.argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.937324Z",
     "start_time": "2019-09-03T16:31:41.058Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get the names\n",
    "preds_names = learn.data.test_ds.x.items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.939517Z",
     "start_time": "2019-09-03T16:31:41.065Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# without site\n",
    "#preds_names = [x.split('/')[1]+'_'+x.split('/')[2][-1]+'_'+x.split('/')[3][:3] for x in preds_names]\n",
    "\n",
    "# with site\n",
    "preds_names = [x.split('/')[1]+'_'+x.split('/')[2][-1]+'_'+x.split('/')[3] for x in preds_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.941705Z",
     "start_time": "2019-09-03T16:31:41.073Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_preds = pd.DataFrame({'id_code_site': preds_names, 'sirna': preds_cat})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.943896Z",
     "start_time": "2019-09-03T16:31:41.080Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get id_code without site\n",
    "df_preds['id_code'] = df_preds['id_code_site'].apply(lambda x: x[:-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.946088Z",
     "start_time": "2019-09-03T16:31:41.088Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get row indices with the same/not the same the prediction for both sites\n",
    "idx = [] # indices with the same prediction\n",
    "idx_notsame = [] # indices with not the same prediction\n",
    "for i, r in enumerate(df_preds.sort_values('id_code').iterrows()):\n",
    "    if i % 2:\n",
    "        # distance from row 2 is \n",
    "        if pred == r[1]['sirna']:\n",
    "            idx.append(r[0])\n",
    "        else:\n",
    "            #idx.append(r[0]) # always append idx until we come up with something better\n",
    "            idx.append(idx_row_before)\n",
    "            idx_notsame.append(idx_row_before) # get the first rows of the pairs that are not the same\n",
    "    else:\n",
    "        # save dist from row 1 for comparison in next iteration\n",
    "        pred = r[1]['sirna']\n",
    "        idx_row_before = r[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.948275Z",
     "start_time": "2019-09-03T16:31:41.095Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(idx), len(idx_notsame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.950461Z",
     "start_time": "2019-09-03T16:31:41.102Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "idx[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.952647Z",
     "start_time": "2019-09-03T16:31:41.110Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_preds.sort_values('id_code').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.954835Z",
     "start_time": "2019-09-03T16:31:41.119Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#df_preds.loc[idx,['id_code','sirna']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.957020Z",
     "start_time": "2019-09-03T16:31:41.130Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 'effnet/adacos_efficientnet_b3_e080CM112_190805'\n",
    "model = 'metriclearn_efficientnet_b3_e080CM112_190805'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.959214Z",
     "start_time": "2019-09-03T16:31:41.137Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_preds.loc[idx,['id_code','sirna']].to_csv('sub/'+model+'.csv.gz', index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.961393Z",
     "start_time": "2019-09-03T16:31:41.145Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c recursion-cellular-image-classification -f sub/{model}.csv.gz -m \"{model}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosinus similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full single features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.962100Z",
     "start_time": "2019-09-03T16:31:41.157Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://github.com/ducha-aiki/whale-identification-2018/blob/master/reproduce_problems.ipynb\n",
    "# And for test-time augmentation I used following random solution: switch train and val transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.962959Z",
     "start_time": "2019-09-03T16:31:41.165Z"
    }
   },
   "outputs": [],
   "source": [
    "# extended tfms\n",
    "tfms = get_transforms(do_flip=True, flip_vert=True, \n",
    "                      max_rotate=90.0, max_zoom=1.1, \n",
    "                      max_lighting=0.2, max_warp=0.2, \n",
    "                      p_affine=0.75, p_lighting=0.75, \n",
    "                      xtra_tfms=[color_augmentation()])\n",
    "\n",
    "# crop_pad: https://forums.fast.ai/t/misc-issues/35386/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.963664Z",
     "start_time": "2019-09-03T16:31:41.173Z"
    }
   },
   "outputs": [],
   "source": [
    "# extended tfms w/o color_augmentation !!!\n",
    "#tfms = get_transforms(do_flip=True, flip_vert=True, \n",
    "#                      max_rotate=90.0, max_zoom=1.1, \n",
    "#                      max_lighting=0.2, max_warp=0.2, \n",
    "#                      p_affine=0.75, p_lighting=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.964294Z",
     "start_time": "2019-09-03T16:31:41.180Z"
    }
   },
   "outputs": [],
   "source": [
    "# \"crop_pad\" to sz\n",
    "tfms[0][0] = crop_pad(size=sz, row_pct=[0.,1.], col_pct=[0.,1.])\n",
    "tfms[1][0] = crop_pad(size=sz, row_pct=[0.,1.], col_pct=[0.,1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.964965Z",
     "start_time": "2019-09-03T16:31:41.188Z"
    }
   },
   "outputs": [],
   "source": [
    "#sz, bs = 300, 8*2*2 # 3436MiB /  7952MiB\n",
    "#sz, bs = 300, 8*8 # 6884MiB /  7952MiB\n",
    "sz, bs = 300, 8*11 # 7938MiB /  7952MiB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.965664Z",
     "start_time": "2019-09-03T16:31:41.196Z"
    }
   },
   "outputs": [],
   "source": [
    "#pg = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.966324Z",
     "start_time": "2019-09-03T16:31:41.203Z"
    }
   },
   "outputs": [],
   "source": [
    "# VALID SPLIT (incl. tfms)\n",
    "data = (ImageList6Dct.from_df(df_train[df_train['pg'] == pg], path='train')\n",
    "        .split_from_df(col=-3) # FULL: .split_none() # !!!\n",
    "        .label_from_df(cols=-5)\n",
    "        .add_test(ImageList6Dct.from_df(df_test[df_test['pg'] == pg], path='test'))\n",
    "        .transform(tfms, size=sz)\n",
    "        .databunch(bs=bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.966970Z",
     "start_time": "2019-09-03T16:31:41.211Z"
    }
   },
   "outputs": [],
   "source": [
    "data.normalize([stats_mean, stats_var]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.967578Z",
     "start_time": "2019-09-03T16:31:41.218Z"
    }
   },
   "outputs": [],
   "source": [
    "#ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.968271Z",
     "start_time": "2019-09-03T16:31:41.226Z"
    }
   },
   "outputs": [],
   "source": [
    "pg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.969096Z",
     "start_time": "2019-09-03T16:31:41.234Z"
    }
   },
   "outputs": [],
   "source": [
    "#data.train_dl.dl.batch_sampler.sampler = torch.utils.data.SequentialSampler(data.train_ds)\n",
    "#data.train_dl.dl.batch_sampler.drop_last = False\n",
    "#\n",
    "#data.valid_dl.dl.batch_sampler.sampler = torch.utils.data.SequentialSampler(data.valid_ds)\n",
    "#data.valid_dl.dl.batch_sampler.drop_last = False\n",
    "#\n",
    "## DOES WORK TOO FOR TEST DL ??? ??? (Or do we need to set the test dataset to the valid dataset?)\n",
    "#data.test_dl.dl.batch_sampler.sampler = torch.utils.data.SequentialSampler(data.test_ds)\n",
    "#data.test_dl.dl.batch_sampler.drop_last = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.969825Z",
     "start_time": "2019-09-03T16:31:41.246Z"
    }
   },
   "outputs": [],
   "source": [
    "learn = Learner(data, adacos_efficientnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.970475Z",
     "start_time": "2019-09-03T16:31:41.253Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.load('effnet/adacos_efficientnet_b3_ct_pg_exp_Pre060e050pg'+str(pg)+'e100_190901');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.971203Z",
     "start_time": "2019-09-03T16:31:41.261Z"
    }
   },
   "outputs": [],
   "source": [
    "#def get_feats(model, dataloader, cycles=1):\n",
    "#    feats = []\n",
    "#    targs = []\n",
    "#    model.eval()\n",
    "#    with torch.no_grad():\n",
    "#        for i in range(cycles): # for TTA\n",
    "#            for xb, yb in dataloader:\n",
    "#                body_out = model.body(xb)\n",
    "#                head_out = model.head(body_out)\n",
    "#                feats.append(head_out.cpu())\n",
    "#                targs.append(yb.cpu())\n",
    "#    return feats, targs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.971843Z",
     "start_time": "2019-09-03T16:31:41.269Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_feats(model, dataloader, cycles=1):\n",
    "    feats = []\n",
    "    targs = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(cycles): # for TTA\n",
    "            for xb, yb in dataloader:\n",
    "                xb_img, xb_ctint, xb_pgint, xb_expint = xb\n",
    "                img_features = model.body1(xb_img)\n",
    "                int_features = model.body2(xb_ctint, xb_pgint, xb_expint)\n",
    "                features = torch.cat((img_features, int_features), dim=-1)\n",
    "                out = model.head(features)\n",
    "                feats.append(out.cpu())\n",
    "                targs.append(yb.cpu())\n",
    "    return feats, targs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.972473Z",
     "start_time": "2019-09-03T16:31:41.279Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_img_exp_feats(model, dataloader, cycles=1):\n",
    "    feats = []\n",
    "    targs = []\n",
    "    img_feats = []\n",
    "    exp_input = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(cycles): # for TTA\n",
    "            for xb, yb in dataloader:\n",
    "                xb_img, xb_ctint, xb_pgint, xb_expint = xb\n",
    "                img_features = model.body1(xb_img)\n",
    "                int_features = model.body2(xb_ctint, xb_pgint, xb_expint)\n",
    "                features = torch.cat((img_features, int_features), dim=-1)\n",
    "                out = model.head(features)\n",
    "                feats.append(out.cpu())\n",
    "                targs.append(yb.cpu())\n",
    "                img_feats.append(img_features)\n",
    "                exp_input.append(xb_expint.cpu())\n",
    "    return feats, targs, img_feats, exp_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.973209Z",
     "start_time": "2019-09-03T16:31:41.289Z"
    }
   },
   "outputs": [],
   "source": [
    "feats, targs = get_feats(learn.model, learn.data.train_dl, cycles=3)\n",
    "#feats, targs, img_feats, exp_input = get_img_exp_feats(learn.model, learn.data.train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.973954Z",
     "start_time": "2019-09-03T16:31:41.296Z"
    }
   },
   "outputs": [],
   "source": [
    "feats = torch.cat(feats, dim=0)\n",
    "targs = torch.cat(targs, dim=0)\n",
    "#img_feats = torch.cat(img_feats, dim=0)\n",
    "#exp_input = torch.cat(exp_input, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.974640Z",
     "start_time": "2019-09-03T16:31:41.304Z"
    }
   },
   "outputs": [],
   "source": [
    "# get class from data classes index\n",
    "targs_cl = torch.tensor([learn.data.classes[t] for t in targs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.975308Z",
     "start_time": "2019-09-03T16:31:41.311Z"
    }
   },
   "outputs": [],
   "source": [
    "feats.shape, targs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.976068Z",
     "start_time": "2019-09-03T16:31:41.319Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save('pred/feats_train_pg'+str(pg)+'.npy', feats)\n",
    "np.save('pred/targs_train_pg'+str(pg)+'.npy', targs)\n",
    "np.save('pred/targs_cl_train_pg'+str(pg)+'.npy', targs_cl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.976750Z",
     "start_time": "2019-09-03T16:31:41.328Z"
    }
   },
   "outputs": [],
   "source": [
    "feats, targs = get_feats(learn.model, learn.data.valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.977364Z",
     "start_time": "2019-09-03T16:31:41.336Z"
    }
   },
   "outputs": [],
   "source": [
    "feats = torch.cat(feats, dim=0)\n",
    "targs = torch.cat(targs, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.978267Z",
     "start_time": "2019-09-03T16:31:41.343Z"
    }
   },
   "outputs": [],
   "source": [
    "# get class from data classes index\n",
    "targs_cl = torch.tensor([learn.data.classes[t] for t in targs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.978910Z",
     "start_time": "2019-09-03T16:31:41.351Z"
    }
   },
   "outputs": [],
   "source": [
    "feats.shape, feats.shape, targs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.979701Z",
     "start_time": "2019-09-03T16:31:41.358Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save('pred/feats_valid_pg'+str(pg)+'.npy', feats)\n",
    "np.save('pred/targs_valid_pg'+str(pg)+'.npy', targs)\n",
    "np.save('pred/targs_cl_valid_pg'+str(pg)+'.npy', targs_cl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.980384Z",
     "start_time": "2019-09-03T16:31:41.367Z"
    }
   },
   "outputs": [],
   "source": [
    "feats, targs = get_feats(learn.model, learn.data.test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.981067Z",
     "start_time": "2019-09-03T16:31:41.375Z"
    }
   },
   "outputs": [],
   "source": [
    "del targs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.981708Z",
     "start_time": "2019-09-03T16:31:41.383Z"
    }
   },
   "outputs": [],
   "source": [
    "feats = torch.cat(feats, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.982480Z",
     "start_time": "2019-09-03T16:31:41.390Z"
    }
   },
   "outputs": [],
   "source": [
    "feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.983138Z",
     "start_time": "2019-09-03T16:31:41.398Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save('pred/feats_test_pg'+str(pg)+'.npy', feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.983876Z",
     "start_time": "2019-09-03T16:31:41.405Z"
    }
   },
   "outputs": [],
   "source": [
    "len(learn.data.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Multi-crop features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.984553Z",
     "start_time": "2019-09-03T16:31:41.414Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# https://github.com/ducha-aiki/whale-identification-2018/blob/master/reproduce_problems.ipynb\n",
    "# And for test-time augmentation I used following random solution: switch train and val transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.985368Z",
     "start_time": "2019-09-03T16:31:41.421Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_train['test'] = 0\n",
    "df_train['path'] = 'train/'+df_train['path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.986072Z",
     "start_time": "2019-09-03T16:31:41.429Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.986776Z",
     "start_time": "2019-09-03T16:31:41.437Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# add dummy columns for test dataset\n",
    "df_test['path'] = 'test/'+df_test['path']\n",
    "df_test['test'] = 1\n",
    "df_test['sirna'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.987500Z",
     "start_time": "2019-09-03T16:31:41.444Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.988176Z",
     "start_time": "2019-09-03T16:31:41.452Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_train_test = pd.concat((df_train, df_test), axis=0, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.988912Z",
     "start_time": "2019-09-03T16:31:41.459Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_train_test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.989529Z",
     "start_time": "2019-09-03T16:31:41.467Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# reload for train and valid ds\n",
    "df_train = pd.read_csv('full_train_dataset_valid-split-ex_v2_20190727.csv', index_col=0)\n",
    "df_test = pd.read_csv('full_test_dataset_v2_20190727.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T17:44:39.974069Z",
     "start_time": "2019-08-05T17:44:39.962352Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.990149Z",
     "start_time": "2019-09-03T16:31:41.479Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# test tfms switching for test ds\n",
    "#tfms_switched = (tfms[1], tfms[0])\n",
    "#\n",
    "#data = (ImageList6D.from_df(df_train_test, path='.')\n",
    "#                .split_from_df(col=-1)\n",
    "#                .label_from_df(cols=-4)\n",
    "#                .transform(tfms_switched)#, size=sz) # remove size so we get the crop size!\n",
    "#                .databunch(bs=bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.990795Z",
     "start_time": "2019-09-03T16:31:41.487Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#data.train_ds[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.991494Z",
     "start_time": "2019-09-03T16:31:41.494Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#data.valid_ds[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.992210Z",
     "start_time": "2019-09-03T16:31:41.506Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_dataset(row_pct, col_pct, is_test=False):\n",
    "    # extended tfms\n",
    "    tfms = get_transforms(do_flip=True, flip_vert=True, \n",
    "                          max_rotate=90.0, max_zoom=1.1, \n",
    "                          max_lighting=0.2, max_warp=0.2, \n",
    "                          p_affine=0.75, p_lighting=0.75, \n",
    "                          xtra_tfms=[color_augmentation()])\n",
    "    \n",
    "    # change \"crop_pad\" from get_transforms to \"crop\"\n",
    "    tfms[0][0] = crop(size=sz, row_pct=row_pct, col_pct=col_pct)\n",
    "    tfms[1][0] = crop(size=sz, row_pct=row_pct, col_pct=col_pct)\n",
    "    \n",
    "    # VALID SPLIT (incl. tfms)\n",
    "    if is_test:\n",
    "        #switch train with valid (= test) tfms!\n",
    "        tfms_switched = (tfms[1], tfms[0])\n",
    "        \n",
    "        data = (ImageList6D.from_df(df_train_test, path='.')\n",
    "                .split_from_df(col=-1)\n",
    "                .label_from_df(cols=-4)\n",
    "                .transform(tfms_switched)#, size=sz) # remove size so we get the crop size!\n",
    "                .databunch(bs=bs))\n",
    "    else:\n",
    "        data = (ImageList6D.from_df(df_train, path='train')\n",
    "                .split_from_df(col=-1) # split_by_rand_pct()\n",
    "                .label_from_df(cols=-3)\n",
    "                #.add_test(ImageList6D.from_df(df_test, path='test'))\n",
    "                .transform(tfms)#, size=sz) # remove size so we get the crop size!\n",
    "                .databunch(bs=bs))\n",
    "    \n",
    "    data.normalize([tensor([0.0456, 0.0702, 0.0447, 0.0468, 0.0407, 0.0399]),\n",
    "                    tensor([0.0644, 0.0733, 0.0536, 0.0633, 0.0555, 0.0392])]);\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.992905Z",
     "start_time": "2019-09-03T16:31:41.514Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_feats(model, dataloader, cycles=1):\n",
    "    feats = []\n",
    "    targs = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(cycles): # for TTA\n",
    "            for xb, yb in dataloader:\n",
    "                body_out = model.body(xb)\n",
    "                head_out = model.head(body_out)\n",
    "                feats.append(head_out.cpu())\n",
    "                targs.append(yb.cpu())\n",
    "                \n",
    "    feats = torch.cat(feats, dim=0)\n",
    "    targs = torch.cat(targs, dim=0)\n",
    "    \n",
    "    return feats, targs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.993519Z",
     "start_time": "2019-09-03T16:31:41.522Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def save_feats(feats, targs, crop, ds='train'):\n",
    "    np.save(f'pred/feats_{ds}_crop{crop}.npy', feats)\n",
    "    np.save(f'pred/targs_{ds}_crop{crop}.npy', targs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.994099Z",
     "start_time": "2019-09-03T16:31:41.529Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#https://docs.fast.ai/vision.transform.html#_crop\n",
    "crop_pos = [[0.,0.], [0.,1.],[0.5,0.5],[1.,0.], [1.,1.]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.994815Z",
     "start_time": "2019-09-03T16:31:41.536Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get random crop pos\n",
    "i = 2\n",
    "crop_pos = [[uniform(0,1), uniform(0,1)] for i in range(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.995410Z",
     "start_time": "2019-09-03T16:31:41.544Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "crop_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.996082Z",
     "start_time": "2019-09-03T16:31:41.551Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get the last three crop positions:\n",
    "crop_pos = [[0.5,0.5],[1.,0.], [1.,1.]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.996689Z",
     "start_time": "2019-09-03T16:31:41.559Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_crop_feats(model=learn.model, cycles=1, crop_pos=crop_pos):\n",
    "    \n",
    "    for i, (row_pct, col_pct) in enumerate(crop_pos):\n",
    "        \n",
    "        print('== crop#:', i,' of', len(crop_pos), '==')\n",
    "        print('row_pct:', row_pct,', col_pct:', col_pct)\n",
    "    \n",
    "        data = get_dataset(row_pct, col_pct)\n",
    "        \n",
    "        # train\n",
    "        print('= Start train dataset =')\n",
    "        feats, targs = get_feats(model, data.train_dl)\n",
    "        save_feats(feats, targs, i, ds='train')\n",
    "        print('feats:', feats.shape,' targs:', targs.shape)\n",
    "        print('- Finish train dataset -')\n",
    "        \n",
    "        # valid\n",
    "        print('= Start valid dataset =')\n",
    "        feats, targs = get_feats(model, data.valid_dl)\n",
    "        save_feats(feats, targs, i, ds='valid')\n",
    "        print('feats:', feats.shape,' targs:', targs.shape)\n",
    "        print('- Finish valid dataset -')\n",
    "        \n",
    "        # get test ds as valid ds for TTA\n",
    "        data = get_dataset(row_pct, col_pct, is_test=True)\n",
    "        \n",
    "        # test\n",
    "        print('= Start test dataset =')\n",
    "        feats, targs = get_feats(model, data.valid_dl)\n",
    "        save_feats(feats, targs, i, ds='test')\n",
    "        print('feats:', feats.shape,' targs:', targs.shape)\n",
    "        print('- Finish test dataset -')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.997200Z",
     "start_time": "2019-09-03T16:31:41.566Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn = Learner(data, adacos_efficientnet_b3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.998276Z",
     "start_time": "2019-09-03T16:31:41.574Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.load('effnet/adacos_efficientnet_b3_e080CM112_190805');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.998998Z",
     "start_time": "2019-09-03T16:31:41.582Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "get_crop_feats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:43.999686Z",
     "start_time": "2019-09-03T16:31:41.601Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#data = (ImageList6D.from_df(df_train_test, path='.')\n",
    "#        .split_from_df(col=-1)\n",
    "#        .label_from_df(cols=-4)\n",
    "#        .transform(tfms_switched)#, size=sz) # remove size so we get the crop size!\n",
    "#        .databunch(bs=bs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:44.000311Z",
     "start_time": "2019-09-03T16:31:41.610Z"
    }
   },
   "outputs": [],
   "source": [
    "# get the names\n",
    "preds_names = learn.data.test_ds.x.items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:44.000934Z",
     "start_time": "2019-09-03T16:31:41.618Z"
    }
   },
   "outputs": [],
   "source": [
    "# without site\n",
    "#preds_names = [x.split('/')[1]+'_'+x.split('/')[2][-1]+'_'+x.split('/')[3][:3] for x in preds_names]\n",
    "\n",
    "# with site\n",
    "preds_names = [x.split('/')[1]+'_'+x.split('/')[2][-1]+'_'+x.split('/')[3] for x in preds_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:44.001594Z",
     "start_time": "2019-09-03T16:31:41.625Z"
    }
   },
   "outputs": [],
   "source": [
    "preds_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:44.002215Z",
     "start_time": "2019-09-03T16:31:41.633Z"
    }
   },
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/27745500/how-to-save-a-list-to-a-file-and-read-it-as-a-list-type\n",
    "with open('pred/preds_test_pg'+str(pg)+'_names.txt', 'wb') as fp:   #Pickling\n",
    "    pickle.dump(preds_names, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:44.002872Z",
     "start_time": "2019-09-03T16:31:41.640Z"
    }
   },
   "outputs": [],
   "source": [
    "#with open('pred/preds_test_pg'+str(pg)+'_names.txt', 'rb') as fp:   # Unpickling\n",
    "#    b = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:44.003544Z",
     "start_time": "2019-09-03T16:31:41.647Z"
    }
   },
   "outputs": [],
   "source": [
    "preds_test = np.load('pred/preds_test_pg'+str(pg)+'.npy')\n",
    "dist_test = np.load('pred/dist_test_pg'+str(pg)+'.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:44.004275Z",
     "start_time": "2019-09-03T16:31:41.654Z"
    }
   },
   "outputs": [],
   "source": [
    "len(preds_names), len(preds_test), len(dist_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:44.004867Z",
     "start_time": "2019-09-03T16:31:41.661Z"
    }
   },
   "outputs": [],
   "source": [
    "#preds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:44.005607Z",
     "start_time": "2019-09-03T16:31:41.670Z"
    }
   },
   "outputs": [],
   "source": [
    "#dist_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:44.006314Z",
     "start_time": "2019-09-03T16:31:41.678Z"
    }
   },
   "outputs": [],
   "source": [
    "df_preds = pd.DataFrame({'id_code_site': preds_names, 'sirna': preds_test, 'cossim': dist_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:44.006997Z",
     "start_time": "2019-09-03T16:31:41.685Z"
    }
   },
   "outputs": [],
   "source": [
    "# get id_code without site\n",
    "df_preds['id_code'] = df_preds['id_code_site'].apply(lambda x: x[:-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:44.007582Z",
     "start_time": "2019-09-03T16:31:41.693Z"
    }
   },
   "outputs": [],
   "source": [
    "# get row indices with highest cosine similiarity\n",
    "idx = []\n",
    "for i, r in enumerate(df_preds.sort_values('id_code').iterrows()):\n",
    "    #print(r)\n",
    "    #print('i: ',i)\n",
    "    #print('idx: ',r[0])\n",
    "    #print(r[1]['cossim'])\n",
    "    if i % 2:\n",
    "        # distance from row 2 is \n",
    "        if dist < r[1]['cossim']:\n",
    "            idx.append(r[0])\n",
    "        else:\n",
    "            idx.append(idx_row_before)\n",
    "    else:\n",
    "        # save dist from row 1 for comparison in next iteration\n",
    "        dist = r[1]['cossim']\n",
    "        idx_row_before = r[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:44.008263Z",
     "start_time": "2019-09-03T16:31:41.701Z"
    }
   },
   "outputs": [],
   "source": [
    "idx[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:44.008831Z",
     "start_time": "2019-09-03T16:31:41.709Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_preds.sort_values('id_code').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:44.009496Z",
     "start_time": "2019-09-03T16:31:41.720Z"
    }
   },
   "outputs": [],
   "source": [
    "#df_preds.loc[idx,['id_code','sirna']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:44.010105Z",
     "start_time": "2019-09-03T16:31:41.731Z"
    }
   },
   "outputs": [],
   "source": [
    "# 'effnet/adacos_efficientnet_b3_ct_pg_exp_Pre060e050pg'+str(pg)+'e100_190901'\n",
    "model = 'adacos_efficientnet_b3_ct_pg_exp_Pre060e050pg'+str(pg)+'e100_190901_3xTTA-cossim'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:44.010761Z",
     "start_time": "2019-09-03T16:31:41.738Z"
    }
   },
   "outputs": [],
   "source": [
    "df_preds.loc[idx,['id_code','sirna']].to_csv('sub/'+model+'.csv.gz', index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:44.011420Z",
     "start_time": "2019-09-03T16:31:41.745Z"
    }
   },
   "outputs": [],
   "source": [
    "#!kaggle competitions submit -c recursion-cellular-image-classification -f sub/{model}.csv.gz -m \"{model}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:44.012030Z",
     "start_time": "2019-09-03T16:31:41.754Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('pred/preds_test_pg'+str(pg)+'_names.txt', 'rb') as fp:   # Unpickling\n",
    "    preds_names = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:44.012646Z",
     "start_time": "2019-09-03T16:31:41.762Z"
    }
   },
   "outputs": [],
   "source": [
    "preds_test_full = np.load('pred/preds_test_pg'+str(pg)+'_full.npy')\n",
    "dist_test_full = np.load('pred/dist_test_pg'+str(pg)+'_full.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:44.013245Z",
     "start_time": "2019-09-03T16:31:41.770Z"
    }
   },
   "outputs": [],
   "source": [
    "preds_test_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:44.013904Z",
     "start_time": "2019-09-03T16:31:41.777Z"
    }
   },
   "outputs": [],
   "source": [
    "dist_test_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:44.014619Z",
     "start_time": "2019-09-03T16:31:41.785Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    df_preds_full = pd.DataFrame({'id_code_site': preds_names,\n",
    "                                  'sirna': preds_test_full[:,i],\n",
    "                                  'cossim': dist_test_full[:,i]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:44.015229Z",
     "start_time": "2019-09-03T16:31:41.793Z"
    }
   },
   "outputs": [],
   "source": [
    "type(preds_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:44.015832Z",
     "start_time": "2019-09-03T16:31:41.804Z"
    }
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "df_preds_full = pd.DataFrame({'id_code_site': preds_names,\n",
    "                                  'sirna': preds_test_full[:,i],\n",
    "                                  'cossim': dist_test_full[:,i]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:44.016428Z",
     "start_time": "2019-09-03T16:31:41.812Z"
    }
   },
   "outputs": [],
   "source": [
    "df_preds_full.sort_values(by='cossim', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:44.017138Z",
     "start_time": "2019-09-03T16:31:41.819Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "for i, d in df_preds_full.sort_values(by='cossim', ascending=False).iterrows():\n",
    "    print(i)\n",
    "    print(d)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:44.017750Z",
     "start_time": "2019-09-03T16:31:41.828Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test.head()#.experiment.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:44.018357Z",
     "start_time": "2019-09-03T16:31:41.839Z"
    }
   },
   "outputs": [],
   "source": [
    "df_preds_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:44.019027Z",
     "start_time": "2019-09-03T16:31:41.848Z"
    }
   },
   "outputs": [],
   "source": [
    "df_preds_full.groupby('sirna')['id_code_site'].nunique()#.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T16:31:44.019627Z",
     "start_time": "2019-09-03T16:31:41.858Z"
    }
   },
   "outputs": [],
   "source": [
    "# ERROR ANALYSIS !!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "488px",
    "width": "305px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "206px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
