{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:46.481800Z",
     "start_time": "2019-09-02T17:57:46.474820Z"
    }
   },
   "outputs": [],
   "source": [
    "pg = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:46.703896Z",
     "start_time": "2019-09-02T17:57:46.493452Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:47.587104Z",
     "start_time": "2019-09-02T17:57:46.705115Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from fastai.vision import *\n",
    "from fastai.vision.models.xresnet import *\n",
    "\n",
    "# for datablock API\n",
    "from fastai.vision.image import _resolve_tfms, _get_crop_target, _round_multiple, _get_resize_target, _affine_grid, _grid_sample, _affine_mult\n",
    "\n",
    "# for XResNet\n",
    "#from fastai.vision.models.xresnet import act_fn, init_cnn, conv, noop, conv_layer, ResBlock, filt_sz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:47.598484Z",
     "start_time": "2019-09-02T17:57:47.588364Z"
    }
   },
   "outputs": [],
   "source": [
    "from fastai.callbacks import CSVLogger, ReduceLROnPlateauCallback, SaveModelCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:47.611996Z",
     "start_time": "2019-09-02T17:57:47.599693Z"
    }
   },
   "outputs": [],
   "source": [
    "from efficientnet_pytorch import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:47.624126Z",
     "start_time": "2019-09-02T17:57:47.613009Z"
    }
   },
   "outputs": [],
   "source": [
    "from nb_new_data_augmentation_adacos_celltype_plategroup_exp import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:47.635059Z",
     "start_time": "2019-09-02T17:57:47.625128Z"
    }
   },
   "outputs": [],
   "source": [
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:47.647396Z",
     "start_time": "2019-09-02T17:57:47.636102Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.55'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6D image with celltype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:47.661873Z",
     "start_time": "2019-09-02T17:57:47.648866Z"
    }
   },
   "outputs": [],
   "source": [
    "class Image6Dct(Image):\n",
    "    \"Support applying transforms to image data in `px`.\"\n",
    "    def __init__(self, px:Tensor, ctint, pgint, expint): # ct\n",
    "        self._px = px\n",
    "        self._logit_px=None\n",
    "        #self.ct = ct\n",
    "        self.ctint = ctint\n",
    "        self.pgint = pgint\n",
    "        self.expint = expint\n",
    "        self._flow=None\n",
    "        self._affine_mat=None\n",
    "        self.sample_kwargs = {}\n",
    "    \n",
    "    def _repr_image_format(self, format_str):\n",
    "        with BytesIO() as str_buffer:\n",
    "            #plt.imsave(str_buffer, image2np(self.px[:3]), format=format_str)\n",
    "            plt.imsave(str_buffer, \n",
    "                       np.concatenate((image2np(self.px[:3]), \n",
    "                                       image2np(self.px[3:])), axis=1),\n",
    "                       format=format_str)\n",
    "            return str_buffer.getvalue()\n",
    "        \n",
    "    def clone(self):\n",
    "        \"Mimic the behavior of torch.clone for `Image` objects.\"\n",
    "        return self.__class__(self.px.clone(), self.ctint.clone(), self.pgint.clone(), self.expint.clone()) # self.ct.clone(), \n",
    "\n",
    "    @property\n",
    "    def data(self)->TensorImage:\n",
    "        \"Return this images pixels as a tensor.\"\n",
    "        return self.px, self.ctint, self.pgint, self.expint\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:47.675886Z",
     "start_time": "2019-09-02T17:57:47.663152Z"
    }
   },
   "outputs": [],
   "source": [
    "def open_image_6Dct(fn:PathOrStr, div:bool=True, convert_mode:str='L', cls:type=Image6Dct,\n",
    "        after_open:Callable=None)->Image:\n",
    "    \"Return `Image` object created from image in file `fn`.\"\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", UserWarning) # EXIF warning from TiffPlugin\n",
    "        \n",
    "        x = []\n",
    "        for i in range(6):\n",
    "            c = PIL.Image.open(fn+'_w'+str(i+1)+'.png').convert(convert_mode)\n",
    "            if after_open: c = after_open(c)\n",
    "            c = np.asarray(c)\n",
    "            c = torch.from_numpy(c.astype(np.float32, copy=False))\n",
    "            x.append(c)\n",
    "    ct = fn.split('/')[1].split('-')[0] # get cell type\n",
    "    ctint = torch.tensor(ct2int[ct])\n",
    "    pgint = torch.tensor(fn2pgint[fn])\n",
    "    exp = fn.split('/')[1] # get experiment\n",
    "    expint = torch.tensor(exp2int[exp])\n",
    "    x = torch.stack(x)\n",
    "    if div: x.div_(255)\n",
    "    return cls(x, ctint, pgint, expint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:47.689355Z",
     "start_time": "2019-09-02T17:57:47.676935Z"
    }
   },
   "outputs": [],
   "source": [
    "# number experiments so that cell types do not overlap\n",
    "# and the valid and test dataset do have a embedding they can use!\n",
    "exp2int = {'HEPG2-01': 0,\n",
    "           'HEPG2-02': 1,\n",
    "           'HEPG2-03': 2,\n",
    "           'HEPG2-04': 3,\n",
    "           'HEPG2-05': 4,\n",
    "           # valid\n",
    "           'HEPG2-06': 0,\n",
    "           'HEPG2-07': 1,\n",
    "           # test\n",
    "           'HEPG2-08': 0,\n",
    "           'HEPG2-09': 1,\n",
    "           'HEPG2-10': 2,\n",
    "           'HEPG2-11': 3,           \n",
    "             \n",
    "           # train\n",
    "           'HUVEC-01': 5,\n",
    "           'HUVEC-02': 6,\n",
    "           'HUVEC-03': 7,\n",
    "           'HUVEC-04': 8,\n",
    "           'HUVEC-05': 9,\n",
    "           'HUVEC-06': 10,\n",
    "           'HUVEC-07': 11, \n",
    "           'HUVEC-08': 12,\n",
    "           'HUVEC-09': 13,\n",
    "           'HUVEC-10': 14,\n",
    "           'HUVEC-11': 15,\n",
    "           'HUVEC-12': 16,\n",
    "           'HUVEC-13': 17,\n",
    "           'HUVEC-14': 18, \n",
    "           # valid\n",
    "           'HUVEC-15': 5,\n",
    "           'HUVEC-16': 6, \n",
    "           # test\n",
    "           'HUVEC-17': 5,\n",
    "           'HUVEC-18': 6,\n",
    "           'HUVEC-19': 7,\n",
    "           'HUVEC-20': 8,\n",
    "           'HUVEC-21': 9,\n",
    "           'HUVEC-22': 10,\n",
    "           'HUVEC-23': 11,\n",
    "           'HUVEC-24': 12,\n",
    "             \n",
    "           # train\n",
    "           'RPE-01': 19,\n",
    "           'RPE-02': 20,\n",
    "           'RPE-03': 21,\n",
    "           'RPE-04': 22,\n",
    "           'RPE-05': 23,\n",
    "           # valid\n",
    "           'RPE-06': 19,\n",
    "           'RPE-07': 20,\n",
    "           # test\n",
    "           'RPE-08': 19,\n",
    "           'RPE-09': 20,\n",
    "           'RPE-10': 21,\n",
    "           'RPE-11': 22,\n",
    "             \n",
    "           # train\n",
    "           'U2OS-01': 24,\n",
    "           'U2OS-02': 25,\n",
    "           # valid\n",
    "           'U2OS-03': 24,\n",
    "           # test\n",
    "           'U2OS-04': 24,\n",
    "           'U2OS-05': 25\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:47.700254Z",
     "start_time": "2019-09-02T17:57:47.690435Z"
    }
   },
   "outputs": [],
   "source": [
    "#exp2int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:47.776567Z",
     "start_time": "2019-09-02T17:57:47.701226Z"
    }
   },
   "outputs": [],
   "source": [
    "df_full_plate_pattern = pd.read_csv('full_dataset_v2_path_plate_groups_only_20190812.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:47.792626Z",
     "start_time": "2019-09-02T17:57:47.777560Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>plate_pattern</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train/HEPG2-01/Plate1/B03_s1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train/HEPG2-01/Plate1/B04_s1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train/HEPG2-01/Plate1/B05_s1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train/HEPG2-01/Plate1/B06_s1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train/HEPG2-01/Plate1/B07_s1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           path  plate_pattern\n",
       "0  train/HEPG2-01/Plate1/B03_s1              0\n",
       "1  train/HEPG2-01/Plate1/B04_s1              0\n",
       "2  train/HEPG2-01/Plate1/B05_s1              0\n",
       "3  train/HEPG2-01/Plate1/B06_s1              0\n",
       "4  train/HEPG2-01/Plate1/B07_s1              0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full_plate_pattern.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:47.819173Z",
     "start_time": "2019-09-02T17:57:47.793633Z"
    }
   },
   "outputs": [],
   "source": [
    "fn2pgint = dict(zip(df_full_plate_pattern.path.values, \n",
    "                              df_full_plate_pattern.plate_pattern.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:47.831019Z",
     "start_time": "2019-09-02T17:57:47.820243Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn2pgint['train/HEPG2-01/Plate1/B03_s1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:47.842502Z",
     "start_time": "2019-09-02T17:57:47.832049Z"
    }
   },
   "outputs": [],
   "source": [
    "# cell types from rcic_v10_inspect_image_data.ipynb \"pixel stats\"\n",
    "cts = ['HEPG2', 'HUVEC', 'RPE', 'U2OS']\n",
    "int2ct = {i: ct for i, ct in enumerate(cts)}\n",
    "ct2int = {ct: i for i, ct in int2ct.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:47.853609Z",
     "start_time": "2019-09-02T17:57:47.843505Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'HEPG2', 1: 'HUVEC', 2: 'RPE', 3: 'U2OS'}\n",
      "{'HEPG2': 0, 'HUVEC': 1, 'RPE': 2, 'U2OS': 3}\n"
     ]
    }
   ],
   "source": [
    "print(int2ct)\n",
    "print(ct2int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:47.865894Z",
     "start_time": "2019-09-02T17:57:47.854668Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HEPG2'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct = 'train/HEPG2-01/Plate1/B03_s1'.split('/')[1].split('-')[0]; ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:47.877638Z",
     "start_time": "2019-09-02T17:57:47.866821Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct2int[ct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:47.888676Z",
     "start_time": "2019-09-02T17:57:47.878676Z"
    }
   },
   "outputs": [],
   "source": [
    "PATH_trunc = 'train/HEPG2-01/Plate1/B03_s1' # path is missing suffix \"_w1.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:47.940116Z",
     "start_time": "2019-09-02T17:57:47.889817Z"
    }
   },
   "outputs": [],
   "source": [
    "img = open_image_6Dct(PATH_trunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:47.952012Z",
     "start_time": "2019-09-02T17:57:47.941112Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 512, 512])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.px.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:47.965642Z",
     "start_time": "2019-09-02T17:57:47.954362Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(0), tensor(0))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.ctint, img.pgint, img.expint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:47.978164Z",
     "start_time": "2019-09-02T17:57:47.967143Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Tensor, torch.Tensor, torch.Tensor)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(img.ctint), type(img.pgint), type(img.expint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:47.993563Z",
     "start_time": "2019-09-02T17:57:47.979432Z"
    }
   },
   "outputs": [],
   "source": [
    "class ImageList6Dct(ImageList): #ImageList\n",
    "    def __init__(self, *args, convert_mode='L', after_open:Callable=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.convert_mode,self.after_open = convert_mode,after_open\n",
    "        self.copy_new.append('convert_mode')\n",
    "        self.c,self.sizes = 6,{}\n",
    "        \n",
    "    def open(self, fn):\n",
    "        \"Open image in `fn`, subclass and overwrite for custom behavior.\"\n",
    "        return open_image_6Dct(fn, convert_mode=self.convert_mode, after_open=self.after_open)\n",
    "\n",
    "#    def show(self, img):\n",
    "#        #return torch.cat((img[i][:3], img[i][3:]), dim=1)\n",
    "#        show_image(img)\n",
    "    \n",
    "    # https://docs.fast.ai/tutorial.itemlist.html#Advanced-show-methods\n",
    "    def show_xys(self, xs, ys, figsize:Tuple[int,int]=(15,10), **kwargs):\n",
    "        \"Show the `xs` and `ys` on a figure of `figsize`. `kwargs` are passed to the show method.\"\n",
    "        rows = int(math.sqrt(len(xs)))\n",
    "        fig, axs = plt.subplots(rows,rows,figsize=figsize)\n",
    "        for i, ax in enumerate(axs.flatten() if rows > 1 else [axs]):\n",
    "            #xs[i].show(ax=ax, y=ys[i], **kwargs)\n",
    "            img = Image6D(torch.cat((xs[i].data[:3], xs[i].data[3:]), dim=2)) # works but not elegant?\n",
    "            #img = Image6D(xs[i]) # does not work?\n",
    "            img.show(ax=ax, y=ys[i], **kwargs)\n",
    "        plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:48.004609Z",
     "start_time": "2019-09-02T17:57:47.994637Z"
    }
   },
   "outputs": [],
   "source": [
    "#def show_image(img:Image, ax:plt.Axes=None, figsize:tuple=(3,3), hide_axis:bool=True, cmap:str='binary',\n",
    "#                alpha:float=None, **kwargs)->plt.Axes:\n",
    "#    \"Display `Image` in notebook.\"\n",
    "#    if ax is None: fig,ax = plt.subplots(figsize=figsize)\n",
    "#    pdb.set_trace()\n",
    "#    #ax.imshow(image2np(img.data), cmap=cmap, alpha=alpha, **kwargs)\n",
    "#    ax.imshow(np.concatenate((image2np(self.px[:3]),\n",
    "#                              image2np(self.px[3:])), axis=1),\n",
    "#              cmap=cmap, alpha=alpha, **kwargs)\n",
    "#    if hide_axis: ax.axis('off')\n",
    "#    return ax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset raw files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:48.112378Z",
     "start_time": "2019-09-02T17:57:48.005641Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('full_train_dataset_valid-split-ex_v2_ct_20190824.csv', index_col=0)\n",
    "df_test = pd.read_csv('full_test_dataset_v2_ct_20190824.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:48.124113Z",
     "start_time": "2019-09-02T17:57:48.113405Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73030, 6)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:48.139791Z",
     "start_time": "2019-09-02T17:57:48.125046Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>experiment</th>\n",
       "      <th>sirna</th>\n",
       "      <th>multi</th>\n",
       "      <th>valid</th>\n",
       "      <th>celltype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36510</th>\n",
       "      <td>U2OS-03/Plate4/O19_s2</td>\n",
       "      <td>U2OS-03</td>\n",
       "      <td>103</td>\n",
       "      <td>U2OS-03 103</td>\n",
       "      <td>1</td>\n",
       "      <td>U2OS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36511</th>\n",
       "      <td>U2OS-03/Plate4/O20_s2</td>\n",
       "      <td>U2OS-03</td>\n",
       "      <td>202</td>\n",
       "      <td>U2OS-03 202</td>\n",
       "      <td>1</td>\n",
       "      <td>U2OS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36512</th>\n",
       "      <td>U2OS-03/Plate4/O21_s2</td>\n",
       "      <td>U2OS-03</td>\n",
       "      <td>824</td>\n",
       "      <td>U2OS-03 824</td>\n",
       "      <td>1</td>\n",
       "      <td>U2OS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36513</th>\n",
       "      <td>U2OS-03/Plate4/O22_s2</td>\n",
       "      <td>U2OS-03</td>\n",
       "      <td>328</td>\n",
       "      <td>U2OS-03 328</td>\n",
       "      <td>1</td>\n",
       "      <td>U2OS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36514</th>\n",
       "      <td>U2OS-03/Plate4/O23_s2</td>\n",
       "      <td>U2OS-03</td>\n",
       "      <td>509</td>\n",
       "      <td>U2OS-03 509</td>\n",
       "      <td>1</td>\n",
       "      <td>U2OS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        path experiment  sirna        multi  valid celltype\n",
       "36510  U2OS-03/Plate4/O19_s2    U2OS-03    103  U2OS-03 103      1     U2OS\n",
       "36511  U2OS-03/Plate4/O20_s2    U2OS-03    202  U2OS-03 202      1     U2OS\n",
       "36512  U2OS-03/Plate4/O21_s2    U2OS-03    824  U2OS-03 824      1     U2OS\n",
       "36513  U2OS-03/Plate4/O22_s2    U2OS-03    328  U2OS-03 328      1     U2OS\n",
       "36514  U2OS-03/Plate4/O23_s2    U2OS-03    509  U2OS-03 509      1     U2OS"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:48.153814Z",
     "start_time": "2019-09-02T17:57:48.140783Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>experiment</th>\n",
       "      <th>celltype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19892</th>\n",
       "      <td>U2OS-05/Plate4/O19_s2</td>\n",
       "      <td>U2OS-05</td>\n",
       "      <td>U2OS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19893</th>\n",
       "      <td>U2OS-05/Plate4/O20_s2</td>\n",
       "      <td>U2OS-05</td>\n",
       "      <td>U2OS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19894</th>\n",
       "      <td>U2OS-05/Plate4/O21_s2</td>\n",
       "      <td>U2OS-05</td>\n",
       "      <td>U2OS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19895</th>\n",
       "      <td>U2OS-05/Plate4/O22_s2</td>\n",
       "      <td>U2OS-05</td>\n",
       "      <td>U2OS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19896</th>\n",
       "      <td>U2OS-05/Plate4/O23_s2</td>\n",
       "      <td>U2OS-05</td>\n",
       "      <td>U2OS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        path experiment celltype\n",
       "19892  U2OS-05/Plate4/O19_s2    U2OS-05     U2OS\n",
       "19893  U2OS-05/Plate4/O20_s2    U2OS-05     U2OS\n",
       "19894  U2OS-05/Plate4/O21_s2    U2OS-05     U2OS\n",
       "19895  U2OS-05/Plate4/O22_s2    U2OS-05     U2OS\n",
       "19896  U2OS-05/Plate4/O23_s2    U2OS-05     U2OS"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:48.164494Z",
     "start_time": "2019-09-02T17:57:48.154835Z"
    }
   },
   "outputs": [],
   "source": [
    "#cts = ['HEPG2', 'HUVEC', 'RPE', 'U2OS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:48.174730Z",
     "start_time": "2019-09-02T17:57:48.165326Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pick the celltype for the celltype-specific training\n",
    "#ct = cts[3]; ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:48.185430Z",
     "start_time": "2019-09-02T17:57:48.175780Z"
    }
   },
   "outputs": [],
   "source": [
    "#df_train[df_train['celltype'] == ct].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:48.196238Z",
     "start_time": "2019-09-02T17:57:48.186513Z"
    }
   },
   "outputs": [],
   "source": [
    "#df_train[df_train['celltype'] == ct].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:48.206637Z",
     "start_time": "2019-09-02T17:57:48.197248Z"
    }
   },
   "outputs": [],
   "source": [
    "#df_test[df_test['celltype'] == ct].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:48.239333Z",
     "start_time": "2019-09-02T17:57:48.207634Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train['pg'] = df_train['path'].apply(lambda x: fn2pgint['train/'+x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:48.263769Z",
     "start_time": "2019-09-02T17:57:48.240321Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test['pg'] = df_test['path'].apply(lambda x: fn2pgint['test/'+x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:48.278476Z",
     "start_time": "2019-09-02T17:57:48.264677Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18258, 7), (9958, 4))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train['pg'] == pg].shape, df_test[df_test['pg'] == pg].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:48.295495Z",
     "start_time": "2019-09-02T17:57:48.279682Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>experiment</th>\n",
       "      <th>sirna</th>\n",
       "      <th>multi</th>\n",
       "      <th>valid</th>\n",
       "      <th>celltype</th>\n",
       "      <th>pg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35679</th>\n",
       "      <td>U2OS-03/Plate1/O19_s2</td>\n",
       "      <td>U2OS-03</td>\n",
       "      <td>764</td>\n",
       "      <td>U2OS-03 764</td>\n",
       "      <td>1</td>\n",
       "      <td>U2OS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35680</th>\n",
       "      <td>U2OS-03/Plate1/O20_s2</td>\n",
       "      <td>U2OS-03</td>\n",
       "      <td>1065</td>\n",
       "      <td>U2OS-03 1065</td>\n",
       "      <td>1</td>\n",
       "      <td>U2OS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35681</th>\n",
       "      <td>U2OS-03/Plate1/O21_s2</td>\n",
       "      <td>U2OS-03</td>\n",
       "      <td>301</td>\n",
       "      <td>U2OS-03 301</td>\n",
       "      <td>1</td>\n",
       "      <td>U2OS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35682</th>\n",
       "      <td>U2OS-03/Plate1/O22_s2</td>\n",
       "      <td>U2OS-03</td>\n",
       "      <td>757</td>\n",
       "      <td>U2OS-03 757</td>\n",
       "      <td>1</td>\n",
       "      <td>U2OS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35683</th>\n",
       "      <td>U2OS-03/Plate1/O23_s2</td>\n",
       "      <td>U2OS-03</td>\n",
       "      <td>831</td>\n",
       "      <td>U2OS-03 831</td>\n",
       "      <td>1</td>\n",
       "      <td>U2OS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        path experiment  sirna         multi  valid celltype  \\\n",
       "35679  U2OS-03/Plate1/O19_s2    U2OS-03    764   U2OS-03 764      1     U2OS   \n",
       "35680  U2OS-03/Plate1/O20_s2    U2OS-03   1065  U2OS-03 1065      1     U2OS   \n",
       "35681  U2OS-03/Plate1/O21_s2    U2OS-03    301   U2OS-03 301      1     U2OS   \n",
       "35682  U2OS-03/Plate1/O22_s2    U2OS-03    757   U2OS-03 757      1     U2OS   \n",
       "35683  U2OS-03/Plate1/O23_s2    U2OS-03    831   U2OS-03 831      1     U2OS   \n",
       "\n",
       "       pg  \n",
       "35679   0  \n",
       "35680   0  \n",
       "35681   0  \n",
       "35682   0  \n",
       "35683   0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train['pg'] == pg].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:48.311072Z",
     "start_time": "2019-09-02T17:57:48.296475Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>experiment</th>\n",
       "      <th>celltype</th>\n",
       "      <th>pg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19344</th>\n",
       "      <td>U2OS-05/Plate2/O19_s2</td>\n",
       "      <td>U2OS-05</td>\n",
       "      <td>U2OS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19345</th>\n",
       "      <td>U2OS-05/Plate2/O20_s2</td>\n",
       "      <td>U2OS-05</td>\n",
       "      <td>U2OS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19346</th>\n",
       "      <td>U2OS-05/Plate2/O21_s2</td>\n",
       "      <td>U2OS-05</td>\n",
       "      <td>U2OS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19347</th>\n",
       "      <td>U2OS-05/Plate2/O22_s2</td>\n",
       "      <td>U2OS-05</td>\n",
       "      <td>U2OS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19348</th>\n",
       "      <td>U2OS-05/Plate2/O23_s2</td>\n",
       "      <td>U2OS-05</td>\n",
       "      <td>U2OS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        path experiment celltype  pg\n",
       "19344  U2OS-05/Plate2/O19_s2    U2OS-05     U2OS   0\n",
       "19345  U2OS-05/Plate2/O20_s2    U2OS-05     U2OS   0\n",
       "19346  U2OS-05/Plate2/O21_s2    U2OS-05     U2OS   0\n",
       "19347  U2OS-05/Plate2/O22_s2    U2OS-05     U2OS   0\n",
       "19348  U2OS-05/Plate2/O23_s2    U2OS-05     U2OS   0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[df_test['pg'] == pg].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color augmentation transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Color Augmentation: Color variability can be increased by applying random color transformations to original training samples. We perform color augmentation by transforming every color channels Ic ← ac · Ic + bc, where ac and bc are drawn from uniform distributions ac ∼ U [0.9, 1.1] and bc ∼ U [−10, +10].\" from Domain-adversarial neural networks to address the appearance variability of histopathology images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:48.322055Z",
     "start_time": "2019-09-02T17:57:48.312103Z"
    }
   },
   "outputs": [],
   "source": [
    "# from https://github.com/fastai/fastai/blob/master/fastai/vision/transform.py#L137\n",
    "#def _rgb_randomize(x, channel:int=None, thresh:float=0.3):\n",
    "#    \"Randomize one of the channels of the input image\"\n",
    "#    if channel is None: channel = np.random.randint(0, x.shape[0] - 1)\n",
    "#    x[channel] = torch.rand(x.shape[1:]) * np.random.uniform(0, thresh)\n",
    "#    return x\n",
    "#\n",
    "#rgb_randomize = TfmPixel(_rgb_randomize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:48.332856Z",
     "start_time": "2019-09-02T17:57:48.323035Z"
    }
   },
   "outputs": [],
   "source": [
    "# Scaling factor comes from byte tensor?\n",
    "#10/255 = 0.0392156862745098"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:48.345118Z",
     "start_time": "2019-09-02T17:57:48.333858Z"
    }
   },
   "outputs": [],
   "source": [
    "def _color_augmentation(x):\n",
    "    \"Randomize all channels of the input image\"\n",
    "    channel_count = x.shape[0] - 1\n",
    "    \n",
    "    # by transforming every color channels Ic ← ac · Ic + bc, \n",
    "    # where ac and bc are drawn from uniform distributions \n",
    "    # ac ∼ U [0.9, 1.1] and \n",
    "    # bc ∼ U [−10, +10].\n",
    "    \n",
    "    # x [0,1]\n",
    "    \n",
    "    for c in range(channel_count):\n",
    "        #pdb.set_trace()\n",
    "        #print(x.min(), x.max())\n",
    "        ac = np.random.uniform(0.9, 1.1) #np.random.uniform(0.9, 1.1)\n",
    "        bc = np.random.uniform(-0.1,0.1) #np.random.uniform(-10, 10)\n",
    "        x[c] = x[c] * ac + bc\n",
    "        \n",
    "        # clipping to min 0 and max 1\n",
    "        x[c] = torch.clamp(x[c], 0., 1.)\n",
    "    \n",
    "    return x\n",
    "\n",
    "color_augmentation = TfmPixel(_color_augmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforms setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:48.355799Z",
     "start_time": "2019-09-02T17:57:48.346040Z"
    }
   },
   "outputs": [],
   "source": [
    "## EfficientNet-B3\n",
    "#sz, bs = 300, 8 # 4167MiB /  7952MiB\n",
    "sz, bs = 300, 8*2 # 7942MiB /  7952MiB // FP16: 4397MiB /  7952MiB\n",
    "#sz, bs = 300, 8*4 # FP16: 7805MiB /  7952MiB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:48.366976Z",
     "start_time": "2019-09-02T17:57:48.356635Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 16)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sz, bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:48.377611Z",
     "start_time": "2019-09-02T17:57:48.367905Z"
    }
   },
   "outputs": [],
   "source": [
    "# cutout params\n",
    "#int(sz*0.1), int(sz*0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:48.388109Z",
     "start_time": "2019-09-02T17:57:48.378493Z"
    }
   },
   "outputs": [],
   "source": [
    "# normal tfms\n",
    "#tfms = get_transforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:48.399299Z",
     "start_time": "2019-09-02T17:57:48.388948Z"
    }
   },
   "outputs": [],
   "source": [
    "# extended tfms\n",
    "tfms = get_transforms(do_flip=True, flip_vert=True, \n",
    "                      max_rotate=90.0, max_zoom=1.1, \n",
    "                      max_lighting=0.2, max_warp=0.2, \n",
    "                      p_affine=0.75, p_lighting=0.75, \n",
    "                      xtra_tfms=[color_augmentation()])\n",
    "\n",
    "# crop_pad: https://forums.fast.ai/t/misc-issues/35386/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:48.409839Z",
     "start_time": "2019-09-02T17:57:48.400343Z"
    }
   },
   "outputs": [],
   "source": [
    "# extended tfms\n",
    "#tfms = get_transforms(do_flip=True, flip_vert=True, \n",
    "#                      max_rotate=90.0, max_zoom=1.1, \n",
    "#                      max_lighting=0.2, max_warp=0.2, \n",
    "#                      p_affine=0.75, p_lighting=0.75, \n",
    "#                      xtra_tfms=[color_augmentation(), \n",
    "#                                 cutout(n_holes=(1,4), length=(int(sz*0.1), int(sz*0.5)), p=.5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:48.421248Z",
     "start_time": "2019-09-02T17:57:48.410680Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([RandTransform(tfm=TfmCrop (crop_pad), kwargs={'row_pct': (0, 1), 'col_pct': (0, 1), 'padding_mode': 'reflection'}, p=1.0, resolved={}, do_run=True, is_random=True, use_on_y=True),\n",
       "  RandTransform(tfm=TfmAffine (dihedral_affine), kwargs={}, p=1.0, resolved={}, do_run=True, is_random=True, use_on_y=True),\n",
       "  RandTransform(tfm=TfmCoord (symmetric_warp), kwargs={'magnitude': (-0.2, 0.2)}, p=0.75, resolved={}, do_run=True, is_random=True, use_on_y=True),\n",
       "  RandTransform(tfm=TfmAffine (rotate), kwargs={'degrees': (-90.0, 90.0)}, p=0.75, resolved={}, do_run=True, is_random=True, use_on_y=True),\n",
       "  RandTransform(tfm=TfmAffine (zoom), kwargs={'scale': (1.0, 1.1), 'row_pct': (0, 1), 'col_pct': (0, 1)}, p=0.75, resolved={}, do_run=True, is_random=True, use_on_y=True),\n",
       "  RandTransform(tfm=TfmLighting (brightness), kwargs={'change': (0.4, 0.6)}, p=0.75, resolved={}, do_run=True, is_random=True, use_on_y=True),\n",
       "  RandTransform(tfm=TfmLighting (contrast), kwargs={'scale': (0.8, 1.25)}, p=0.75, resolved={}, do_run=True, is_random=True, use_on_y=True),\n",
       "  RandTransform(tfm=TfmPixel (color_augmentation), kwargs={}, p=1.0, resolved={}, do_run=True, is_random=True, use_on_y=True)],\n",
       " [RandTransform(tfm=TfmCrop (crop_pad), kwargs={}, p=1.0, resolved={}, do_run=True, is_random=True, use_on_y=True)])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:48.432857Z",
     "start_time": "2019-09-02T17:57:48.422194Z"
    }
   },
   "outputs": [],
   "source": [
    "# \"crop_pad\" to sz\n",
    "tfms[0][0] = crop_pad(size=sz, row_pct=[0.,1.], col_pct=[0.,1.])\n",
    "tfms[1][0] = crop_pad(size=sz, row_pct=[0.,1.], col_pct=[0.,1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:48.444355Z",
     "start_time": "2019-09-02T17:57:48.433825Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([RandTransform(tfm=TfmCrop (crop_pad), kwargs={'size': 300, 'row_pct': [0.0, 1.0], 'col_pct': [0.0, 1.0]}, p=1.0, resolved={}, do_run=True, is_random=True, use_on_y=True),\n",
       "  RandTransform(tfm=TfmAffine (dihedral_affine), kwargs={}, p=1.0, resolved={}, do_run=True, is_random=True, use_on_y=True),\n",
       "  RandTransform(tfm=TfmCoord (symmetric_warp), kwargs={'magnitude': (-0.2, 0.2)}, p=0.75, resolved={}, do_run=True, is_random=True, use_on_y=True),\n",
       "  RandTransform(tfm=TfmAffine (rotate), kwargs={'degrees': (-90.0, 90.0)}, p=0.75, resolved={}, do_run=True, is_random=True, use_on_y=True),\n",
       "  RandTransform(tfm=TfmAffine (zoom), kwargs={'scale': (1.0, 1.1), 'row_pct': (0, 1), 'col_pct': (0, 1)}, p=0.75, resolved={}, do_run=True, is_random=True, use_on_y=True),\n",
       "  RandTransform(tfm=TfmLighting (brightness), kwargs={'change': (0.4, 0.6)}, p=0.75, resolved={}, do_run=True, is_random=True, use_on_y=True),\n",
       "  RandTransform(tfm=TfmLighting (contrast), kwargs={'scale': (0.8, 1.25)}, p=0.75, resolved={}, do_run=True, is_random=True, use_on_y=True),\n",
       "  RandTransform(tfm=TfmPixel (color_augmentation), kwargs={}, p=1.0, resolved={}, do_run=True, is_random=True, use_on_y=True)],\n",
       " [RandTransform(tfm=TfmCrop (crop_pad), kwargs={'size': 300, 'row_pct': [0.0, 1.0], 'col_pct': [0.0, 1.0]}, p=1.0, resolved={}, do_run=True, is_random=True, use_on_y=True)])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:48.455029Z",
     "start_time": "2019-09-02T17:57:48.445182Z"
    }
   },
   "outputs": [],
   "source": [
    "# VALID SPLIT (incl. tfms)\n",
    "#data = (ImageList6Dct.from_df(df_train[df_train['pg'] == pg], path='train')\n",
    "#        .split_from_df(col=-3) # FULL: .split_none() # !!!\n",
    "#        .label_from_df(cols=-5)\n",
    "#        .add_test(ImageList6Dct.from_df(df_test[df_test['pg'] == pg], path='test'))\n",
    "#        .transform(tfms, size=sz)\n",
    "#        .databunch(bs=bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:48.465739Z",
     "start_time": "2019-09-02T17:57:48.455927Z"
    }
   },
   "outputs": [],
   "source": [
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:48.476331Z",
     "start_time": "2019-09-02T17:57:48.466762Z"
    }
   },
   "outputs": [],
   "source": [
    "### CHANGED LINE 65 to:\n",
    "# nano ~/anaconda3/envs/fastai/lib/python3.6/site-packages/fastai/vision/data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T10:36:41.864055Z",
     "start_time": "2019-08-10T10:36:41.846780Z"
    }
   },
   "source": [
    "```\n",
    "~/anaconda3/envs/fastai/lib/python3.6/site-packages/fastai/vision/data.py in _normalize_batch(b, mean, std, do_x, do_y)\n",
    "     64     \"`b` = `x`,`y` - normalize `x` array of imgs and `do_y` optionally `y`.\"\n",
    "     65     x,y = b\n",
    "---> 66     mean,std = mean.to(x.device),std.to(x.device)\n",
    "     67     if do_x: x = normalize(x,mean,std)\n",
    "     68     if do_y and len(y.shape) == 4: y = normalize(y,mean,std)\n",
    "\n",
    "AttributeError: 'list' object has no attribute 'device'\n",
    "```\n",
    "CHANGED TO:\n",
    "```\n",
    "def _normalize_batch(b:Tuple[Tensor,Tensor], mean:FloatTensor, std:FloatTensor, do_x:bool$\n",
    "    \"`b` = `x`,`y` - normalize `x` array of imgs and `do_y` optionally `y`.\"\n",
    "    (x,cint,pgint,expint),y = b\n",
    "    mean,std = mean.to(x.device),std.to(x.device)\n",
    "    if do_x: x = normalize(x,mean,std)\n",
    "    if do_y and len(y.shape) == 4: y = normalize(y,mean,std)\n",
    "    return (x,cint,pgint,expint),y\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:48.486804Z",
     "start_time": "2019-09-02T17:57:48.477152Z"
    }
   },
   "outputs": [],
   "source": [
    "#data.batch_stats() # DOES NOT WORK?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:48.498605Z",
     "start_time": "2019-09-02T17:57:48.487698Z"
    }
   },
   "outputs": [],
   "source": [
    "# From https://github.com/recursionpharma/rxrx1-utils/blob/master/rxrx/main.py\n",
    "# The mean and stds for each of the channels\n",
    "GLOBAL_PIXEL_STATS = (np.array([6.74696984, 14.74640167, 10.51260864,\n",
    "                                10.45369445,  5.49959796, 9.81545561]),\n",
    "                       np.array([7.95876312, 12.17305868, 5.86172946,\n",
    "                                 7.83451711, 4.701167, 5.43130431]))\n",
    "\n",
    "stats_mean = torch.tensor(GLOBAL_PIXEL_STATS[0]/255).float()\n",
    "stats_var = torch.tensor(GLOBAL_PIXEL_STATS[1]/255).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:48.509231Z",
     "start_time": "2019-09-02T17:57:48.499579Z"
    }
   },
   "outputs": [],
   "source": [
    "#stats_mean, stats_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:48.520154Z",
     "start_time": "2019-09-02T17:57:48.510273Z"
    }
   },
   "outputs": [],
   "source": [
    "# 3d to 6d from old/rcic_multicat_v9_resnet50-pretrained_colaug.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:48.531140Z",
     "start_time": "2019-09-02T17:57:48.521157Z"
    }
   },
   "outputs": [],
   "source": [
    "from efficientnet_pytorch.utils import get_same_padding_conv2d, round_filters, round_repeats, relu_fn\n",
    "from efficientnet_pytorch.model import MBConvBlock, load_pretrained_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:48.550779Z",
     "start_time": "2019-09-02T17:57:48.532173Z"
    }
   },
   "outputs": [],
   "source": [
    "# put feature extractor into forward method\n",
    "class EfficientNet(nn.Module):\n",
    "    \"\"\"\n",
    "    An EfficientNet model. Most easily loaded with the .from_name or .from_pretrained methods\n",
    "    Args:\n",
    "        blocks_args (list): A list of BlockArgs to construct blocks\n",
    "        global_params (namedtuple): A set of GlobalParams shared between blocks\n",
    "    Example:\n",
    "        model = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, blocks_args=None, global_params=None):\n",
    "        super().__init__()\n",
    "        assert isinstance(blocks_args, list), 'blocks_args should be a list'\n",
    "        assert len(blocks_args) > 0, 'block args must be greater than 0'\n",
    "        self._global_params = global_params\n",
    "        self._blocks_args = blocks_args\n",
    "\n",
    "        # Get static or dynamic convolution depending on image size\n",
    "        Conv2d = get_same_padding_conv2d(image_size=global_params.image_size)\n",
    "\n",
    "        # Batch norm parameters\n",
    "        bn_mom = 1 - self._global_params.batch_norm_momentum\n",
    "        bn_eps = self._global_params.batch_norm_epsilon\n",
    "\n",
    "        # Stem\n",
    "        in_channels = 3  # rgb\n",
    "        out_channels = round_filters(32, self._global_params)  # number of output channels\n",
    "        self._conv_stem = Conv2d(in_channels, out_channels, kernel_size=3, stride=2, bias=False)\n",
    "        self._bn0 = nn.BatchNorm2d(num_features=out_channels, momentum=bn_mom, eps=bn_eps)\n",
    "\n",
    "        # Build blocks\n",
    "        self._blocks = nn.ModuleList([])\n",
    "        for block_args in self._blocks_args:\n",
    "\n",
    "            # Update block input and output filters based on depth multiplier.\n",
    "            block_args = block_args._replace(\n",
    "                input_filters=round_filters(block_args.input_filters, self._global_params),\n",
    "                output_filters=round_filters(block_args.output_filters, self._global_params),\n",
    "                num_repeat=round_repeats(block_args.num_repeat, self._global_params)\n",
    "            )\n",
    "\n",
    "            # The first block needs to take care of stride and filter size increase.\n",
    "            self._blocks.append(MBConvBlock(block_args, self._global_params))\n",
    "            if block_args.num_repeat > 1:\n",
    "                block_args = block_args._replace(input_filters=block_args.output_filters, stride=1)\n",
    "            for _ in range(block_args.num_repeat - 1):\n",
    "                self._blocks.append(MBConvBlock(block_args, self._global_params))\n",
    "\n",
    "        # Head\n",
    "        in_channels = block_args.output_filters  # output of final block\n",
    "        out_channels = round_filters(1280, self._global_params)\n",
    "        self._conv_head = Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self._bn1 = nn.BatchNorm2d(num_features=out_channels, momentum=bn_mom, eps=bn_eps)\n",
    "\n",
    "        # Final linear layer\n",
    "        #self._dropout = self._global_params.dropout_rate\n",
    "        #self._fc = nn.Linear(out_channels, self._global_params.num_classes)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\" Returns output of the final convolution layer \"\"\"\n",
    "\n",
    "        # Stem\n",
    "        x = relu_fn(self._bn0(self._conv_stem(inputs)))\n",
    "\n",
    "        # Blocks\n",
    "        for idx, block in enumerate(self._blocks):\n",
    "            drop_connect_rate = self._global_params.drop_connect_rate\n",
    "            if drop_connect_rate:\n",
    "                drop_connect_rate *= float(idx) / len(self._blocks)\n",
    "            x = block(x, drop_connect_rate=drop_connect_rate)\n",
    "\n",
    "        # Head\n",
    "        x = relu_fn(self._bn1(self._conv_head(x)))\n",
    "\n",
    "        return x\n",
    "\n",
    "    #def forward(self, inputs):\n",
    "    #    \"\"\" Calls extract_features to extract features, applies final linear layer, and returns logits. \"\"\"\n",
    "    #\n",
    "    #    # Convolution layers\n",
    "    #    x = self.extract_features(inputs)\n",
    "    #\n",
    "    #    # Pooling and final linear layer\n",
    "    #    x = F.adaptive_avg_pool2d(x, 1).squeeze(-1).squeeze(-1)\n",
    "    #    if self._dropout:\n",
    "    #        x = F.dropout(x, p=self._dropout, training=self.training)\n",
    "    #    x = self._fc(x)\n",
    "    #    return x\n",
    "\n",
    "    @classmethod\n",
    "    def from_name(cls, model_name, override_params=None):\n",
    "        cls._check_model_name_is_valid(model_name)\n",
    "        blocks_args, global_params = get_model_params(model_name, override_params)\n",
    "        return EfficientNet(blocks_args, global_params)\n",
    "\n",
    "    @classmethod\n",
    "    def from_pretrained(cls, model_name, num_classes=1000):\n",
    "        model = EfficientNet.from_name(model_name, override_params={'num_classes': num_classes})\n",
    "        load_pretrained_weights(model, model_name, load_fc=(num_classes == 1000))\n",
    "        return model\n",
    "\n",
    "    @classmethod\n",
    "    def get_image_size(cls, model_name):\n",
    "        cls._check_model_name_is_valid(model_name)\n",
    "        _, _, res, _ = efficientnet_params(model_name)\n",
    "        return res\n",
    "\n",
    "    @classmethod\n",
    "    def _check_model_name_is_valid(cls, model_name, also_need_pretrained_weights=False):\n",
    "        \"\"\" Validates model name. None that pretrained weights are only available for\n",
    "        the first four models (efficientnet-b{i} for i in 0,1,2,3) at the moment. \"\"\"\n",
    "        num_models = 4 if also_need_pretrained_weights else 8\n",
    "        valid_models = ['efficientnet_b'+str(i) for i in range(num_models)]\n",
    "        if model_name.replace('-','_') not in valid_models:\n",
    "            raise ValueError('model_name should be one of: ' + ', '.join(valid_models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:48.561968Z",
     "start_time": "2019-09-02T17:57:48.551781Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils import model_zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:48.573162Z",
     "start_time": "2019-09-02T17:57:48.562928Z"
    }
   },
   "outputs": [],
   "source": [
    "url_map = {\n",
    "    'efficientnet-b0': 'http://storage.googleapis.com/public-models/efficientnet/efficientnet-b0-355c32eb.pth',\n",
    "    'efficientnet-b1': 'http://storage.googleapis.com/public-models/efficientnet/efficientnet-b1-f1951068.pth',\n",
    "    'efficientnet-b2': 'http://storage.googleapis.com/public-models/efficientnet/efficientnet-b2-8bb594d6.pth',\n",
    "    'efficientnet-b3': 'http://storage.googleapis.com/public-models/efficientnet/efficientnet-b3-5fb5a3c3.pth',\n",
    "    'efficientnet-b4': 'http://storage.googleapis.com/public-models/efficientnet/efficientnet-b4-6ed6700e.pth',\n",
    "    'efficientnet-b5': 'http://storage.googleapis.com/public-models/efficientnet/efficientnet-b5-b6417697.pth',\n",
    "    'efficientnet-b6': 'http://storage.googleapis.com/public-models/efficientnet/efficientnet-b6-c76e70fd.pth',\n",
    "    'efficientnet-b7': 'http://storage.googleapis.com/public-models/efficientnet/efficientnet-b7-dcc49843.pth',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:48.584854Z",
     "start_time": "2019-09-02T17:57:48.574054Z"
    }
   },
   "outputs": [],
   "source": [
    "# adapt load function to only load weights for feature extractor stage\n",
    "def load_pretrained_weights(model, model_name, load_fc=True):\n",
    "    \"\"\" Loads pretrained weights, and downloads if loading for the first time. \"\"\"\n",
    "    state_dict = model_zoo.load_url(url_map[model_name])\n",
    "    #if load_fc:\n",
    "    #    model.load_state_dict(state_dict)\n",
    "    #else:\n",
    "    state_dict.pop('_fc.weight')\n",
    "    state_dict.pop('_fc.bias')\n",
    "    res = model.load_state_dict(state_dict, strict=False)\n",
    "        #assert str(res.missing_keys) == str(['_fc.weight', '_fc.bias']), 'issue loading pretrained weights'\n",
    "    print('Loaded pretrained weights for {}'.format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:48.738683Z",
     "start_time": "2019-09-02T17:57:48.585782Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b3\n"
     ]
    }
   ],
   "source": [
    "# b3: input size = 300\n",
    "#efficientnet_b3 = EfficientNet.from_name('efficientnet-b3')\n",
    "efficientnet_f = EfficientNet.from_pretrained('efficientnet-b3')\n",
    "#efficientnet_b4f = EfficientNet.from_pretrained('efficientnet-b4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:48.749923Z",
     "start_time": "2019-09-02T17:57:48.739729Z"
    }
   },
   "outputs": [],
   "source": [
    "#efficientnet_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:48.761907Z",
     "start_time": "2019-09-02T17:57:48.750990Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Conv2dStaticSamePadding(\n",
       "   3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "   (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       " ), efficientnet_pytorch.utils.Conv2dStaticSamePadding)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficientnet_f._conv_stem, type(efficientnet_f._conv_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:48.777761Z",
     "start_time": "2019-09-02T17:57:48.766479Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2dStaticSamePadding(\n",
       "  6, 40, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "  (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       ")"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.Conv2dStaticSamePadding(6, 40, kernel_size=(3, 3), stride=(2, 2), bias=False, image_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:48.790059Z",
     "start_time": "2019-09-02T17:57:48.779598Z"
    }
   },
   "outputs": [],
   "source": [
    "p_dict = {pn: p for pn, p in efficientnet_f._conv_stem.named_parameters()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:48.801735Z",
     "start_time": "2019-09-02T17:57:48.790975Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['weight'])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:48.813605Z",
     "start_time": "2019-09-02T17:57:48.802651Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([40, 3, 3, 3]), True)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_dict['weight'].shape, p_dict['weight'].requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:48.824894Z",
     "start_time": "2019-09-02T17:57:48.814496Z"
    }
   },
   "outputs": [],
   "source": [
    "old_weight = p_dict['weight'].detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:48.836739Z",
     "start_time": "2019-09-02T17:57:48.825803Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([40, 3, 3, 3]), False)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_weight.shape, old_weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:48.848010Z",
     "start_time": "2019-09-02T17:57:48.837635Z"
    }
   },
   "outputs": [],
   "source": [
    "new_weight = torch.cat((old_weight, old_weight), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:48.859702Z",
     "start_time": "2019-09-02T17:57:48.849014Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([40, 6, 3, 3]), False)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_weight.shape, new_weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:48.872427Z",
     "start_time": "2019-09-02T17:57:48.860744Z"
    }
   },
   "outputs": [],
   "source": [
    "def show_input_stage_weights(weight=None, nrows=2, ncols=3):\n",
    "    fig, ax = plt.subplots(nrows=nrows, ncols=ncols)\n",
    "    k = 0\n",
    "    for i in range(nrows):\n",
    "        for j in range(ncols):\n",
    "            if nrows > 1:\n",
    "                ax[i,j].set_title(k)\n",
    "                ax[i,j].imshow(weight[0][k])\n",
    "                ax[i,j].axis(\"off\")\n",
    "            else:\n",
    "                ax[j].set_title(k)\n",
    "                ax[j].imshow(weight[0][k])\n",
    "                ax[j].axis(\"off\")\n",
    "            k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:48.883281Z",
     "start_time": "2019-09-02T17:57:48.873437Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot old_weight\n",
    "#show_input_stage_weights(old_weight, nrows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:48.894066Z",
     "start_time": "2019-09-02T17:57:48.884288Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot new_weight\n",
    "#show_input_stage_weights(new_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:48.905561Z",
     "start_time": "2019-09-02T17:57:48.895089Z"
    }
   },
   "outputs": [],
   "source": [
    "# replace first conv layer with a 6-channel version\n",
    "efficientnet_f._conv_stem = utils.Conv2dStaticSamePadding(6, 40, kernel_size=(3, 3),\n",
    "                                                          stride=(2, 2), bias=False, image_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:48.917204Z",
     "start_time": "2019-09-02T17:57:48.906582Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2dStaticSamePadding(\n",
       "  6, 40, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "  (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       ")"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficientnet_f._conv_stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:48.928833Z",
     "start_time": "2019-09-02T17:57:48.918235Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 6, 3, 3])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficientnet_f._conv_stem.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:48.939917Z",
     "start_time": "2019-09-02T17:57:48.929821Z"
    }
   },
   "outputs": [],
   "source": [
    "# set new_weights to nn.Parameter and overwrite it in the conv layer\n",
    "efficientnet_f._conv_stem.weight = nn.Parameter(new_weight) # hand over requires_grad False?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:48.956764Z",
     "start_time": "2019-09-02T17:57:48.940905Z"
    }
   },
   "outputs": [],
   "source": [
    "# check if weight was loaded properly\n",
    "assert torch.allclose(new_weight, efficientnet_f._conv_stem.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:48.982562Z",
     "start_time": "2019-09-02T17:57:48.960129Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([40, 6, 3, 3]), True)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficientnet_f._conv_stem.weight.shape, efficientnet_f._conv_stem.weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:48.998640Z",
     "start_time": "2019-09-02T17:57:48.984062Z"
    }
   },
   "outputs": [],
   "source": [
    "# network is in full train mode!\n",
    "#[p.requires_grad for p in efficientnet_b3f.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:49.012493Z",
     "start_time": "2019-09-02T17:57:48.999898Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_rg(model=efficientnet_f, option=False):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:49.024967Z",
     "start_time": "2019-09-02T17:57:49.013637Z"
    }
   },
   "outputs": [],
   "source": [
    "# set requires grad for the efficientnet to false (to later only set it true for the input)\n",
    "# WE WILL NOT DO THIS, because it should be not necessary!\n",
    "set_rg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:49.035443Z",
     "start_time": "2019-09-02T17:57:49.025894Z"
    }
   },
   "outputs": [],
   "source": [
    "# network is frozen\n",
    "#[p.requires_grad for p in efficientnet_b4f.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:49.046948Z",
     "start_time": "2019-09-02T17:57:49.036539Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficientnet_f._conv_stem.weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:49.057301Z",
     "start_time": "2019-09-02T17:57:49.047975Z"
    }
   },
   "outputs": [],
   "source": [
    "# set input stage to trainable\n",
    "#efficientnet_f._conv_stem.weight.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:49.068167Z",
     "start_time": "2019-09-02T17:57:49.058221Z"
    }
   },
   "outputs": [],
   "source": [
    "#efficientnet_f._conv_stem.weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:49.203718Z",
     "start_time": "2019-09-02T17:57:49.069194Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1536, 9, 9])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficientnet_f(torch.randn(1,6,sz,sz)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EfficientNet Pre-Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:49.215493Z",
     "start_time": "2019-09-02T17:57:49.204652Z"
    }
   },
   "outputs": [],
   "source": [
    "def resnet_pre_head(concat_pool:bool=True):\n",
    "    pool = AdaptiveConcatPool2d() if concat_pool else nn.AdaptiveAvgPool2d(1)\n",
    "    layers = [pool, Flatten()]\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:49.227416Z",
     "start_time": "2019-09-02T17:57:49.216431Z"
    }
   },
   "outputs": [],
   "source": [
    "efficientnet_f_prehead = resnet_pre_head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:49.239127Z",
     "start_time": "2019-09-02T17:57:49.228394Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): AdaptiveConcatPool2d(\n",
       "    (ap): AdaptiveAvgPool2d(output_size=1)\n",
       "    (mp): AdaptiveMaxPool2d(output_size=1)\n",
       "  )\n",
       "  (1): Flatten()\n",
       ")"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficientnet_f_prehead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:49.253212Z",
     "start_time": "2019-09-02T17:57:49.240116Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3072])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficientnet_f_prehead(torch.randn(2, 1536, 9, 9)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:49.264609Z",
     "start_time": "2019-09-02T17:57:49.254316Z"
    }
   },
   "outputs": [],
   "source": [
    "efficientnet_fph = nn.Sequential(efficientnet_f, efficientnet_f_prehead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:49.396223Z",
     "start_time": "2019-09-02T17:57:49.265614Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3072])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficientnet_fph(torch.randn(1,6,sz,sz)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CellType & Plate Group Feature Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:49.408581Z",
     "start_time": "2019-09-02T17:57:49.397214Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exps = len(set([exp2int[i] for i in exp2int])); exps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:49.423766Z",
     "start_time": "2019-09-02T17:57:49.409528Z"
    }
   },
   "outputs": [],
   "source": [
    "class CellTypePlateGroupFeatures(nn.Module):\n",
    "    '''CellType Feature Extractor.'''\n",
    "    def __init__(self, cell_types=4, plate_groups=4, exps=exps, emb_sz=128):\n",
    "        super(CellTypePlateGroupFeatures, self).__init__()\n",
    "        self.emb_ctint = nn.Embedding(cell_types, emb_sz)\n",
    "        self.emb_pgint = nn.Embedding(plate_groups, emb_sz)\n",
    "        self.emb_expint = nn.Embedding(exps, emb_sz)\n",
    "        \n",
    "    def forward(self, xb_ctint, xb_pgint, xb_expint, yb=None): # yb=None for training in non-AdaCos mode!\n",
    "        \n",
    "        ### CTINT\n",
    "        # check if we are in CutMix mode:\n",
    "        if isinstance(xb_ctint, tuple):\n",
    "            x1, x2, λ = xb_ctint\n",
    "            out1 = self.emb_ctint(x1)\n",
    "            out2 = self.emb_ctint(x2)\n",
    "            out_ctint = out1 * λ + out2 * (1-λ)\n",
    "        else: # if not CutMix, then normal mode\n",
    "            out_ctint = self.emb_ctint(xb_ctint)\n",
    "        \n",
    "        ## PGINT\n",
    "        # check if we are in CutMix mode:\n",
    "        if isinstance(xb_pgint, tuple):\n",
    "            x1, x2, λ = xb_pgint\n",
    "            out1 = self.emb_pgint(x1)\n",
    "            out2 = self.emb_pgint(x2)\n",
    "            out_pgint = out1 * λ + out2 * (1-λ)\n",
    "        else: # if not CutMix, then normal mode\n",
    "            out_pgint = self.emb_pgint(xb_pgint)\n",
    "            \n",
    "        ## EXPINT\n",
    "        # check if we are in CutMix mode:\n",
    "        if isinstance(xb_expint, tuple):\n",
    "            x1, x2, λ = xb_expint\n",
    "            out1 = self.emb_expint(x1)\n",
    "            out2 = self.emb_expint(x2)\n",
    "            out_expint = out1 * λ + out2 * (1-λ)\n",
    "        else: # if not CutMix, then normal mode\n",
    "            out_expint = self.emb_expint(xb_expint)\n",
    "        \n",
    "        out = torch.cat((out_ctint, out_pgint,  out_expint), dim=-1)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:49.435199Z",
     "start_time": "2019-09-02T17:57:49.424738Z"
    }
   },
   "outputs": [],
   "source": [
    "ctf = CellTypePlateGroupFeatures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:49.446922Z",
     "start_time": "2019-09-02T17:57:49.436168Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CellTypePlateGroupFeatures(\n",
       "  (emb_ctint): Embedding(4, 128)\n",
       "  (emb_pgint): Embedding(4, 128)\n",
       "  (emb_expint): Embedding(26, 128)\n",
       ")"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:49.458335Z",
     "start_time": "2019-09-02T17:57:49.447884Z"
    }
   },
   "outputs": [],
   "source": [
    "xb = (torch.tensor(ct2int['HEPG2']),\n",
    "      torch.tensor(fn2pgint['train/HEPG2-01/Plate1/B03_s1']),\n",
    "      torch.tensor(exp2int['train/HEPG2-01/Plate1/B03_s1'.split('/')[1]])\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:49.470082Z",
     "start_time": "2019-09-02T17:57:49.459313Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(0), tensor(0))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:49.482049Z",
     "start_time": "2019-09-02T17:57:49.471076Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([384])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctf(xb[0], xb[1], xb[2]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:49.493463Z",
     "start_time": "2019-09-02T17:57:49.483072Z"
    }
   },
   "outputs": [],
   "source": [
    "xb = (torch.tensor((1,3)), torch.tensor((1,3)), torch.tensor((1,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:49.505142Z",
     "start_time": "2019-09-02T17:57:49.494463Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 3]), tensor([1, 3]), tensor([1, 3]))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:49.517063Z",
     "start_time": "2019-09-02T17:57:49.506140Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 384])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctf(xb[0], xb[1], xb[2]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:49.528738Z",
     "start_time": "2019-09-02T17:57:49.518059Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 2)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct2int['HEPG2'], ct2int['RPE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:49.540570Z",
     "start_time": "2019-09-02T17:57:49.529730Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn2pgint['train/HEPG2-01/Plate1/B03_s1'], fn2pgint['train/RPE-01/Plate1/B03_s1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:49.552195Z",
     "start_time": "2019-09-02T17:57:49.541559Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 19)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp2int['HEPG2-01'], exp2int['RPE-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:49.563918Z",
     "start_time": "2019-09-02T17:57:49.553190Z"
    }
   },
   "outputs": [],
   "source": [
    "xb = ((torch.tensor(ct2int['HEPG2']), torch.tensor(ct2int['RPE']), 0.9),\n",
    "      (torch.tensor(fn2pgint['train/HEPG2-01/Plate1/B03_s1']),\n",
    "       torch.tensor(fn2pgint['train/RPE-01/Plate1/B03_s1']), 0.9),\n",
    "      (torch.tensor(exp2int['HEPG2-01']),\n",
    "       torch.tensor(exp2int['RPE-01']), 0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:49.576012Z",
     "start_time": "2019-09-02T17:57:49.564914Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([384])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctf(xb[0], xb[1], xb[2]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:49.587049Z",
     "start_time": "2019-09-02T17:57:49.577061Z"
    }
   },
   "outputs": [],
   "source": [
    "#class CellTypeFeatures(nn.Module):\n",
    "#    '''CellType Feature Extractor.'''\n",
    "#    def __init__(self, cell_types=4, emb_sz=128, lin_ftrs:Optional[Collection[int]]=None, nc=128):\n",
    "#        super(AdaCosNet, self).__init__()\n",
    "#        self.emb = nn.Embedding(cell_types, emb_sz)\n",
    "#        \n",
    "#        self.lin_ftrs = [emb_sz, 512, 512] if lin_ftrs is None else [emb_sz] + lin_ftrs + [nc]\n",
    "#\n",
    "#        \n",
    "#    def forward(self, xb, yb=None): # yb=None for training in non-AdaCos mode!\n",
    "#\n",
    "#        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaCos-Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:49.600719Z",
     "start_time": "2019-09-02T17:57:49.588050Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_adacos_head(nf:int, lin_ftrs:Optional[Collection[int]]=None, ps:Floats=0.5,\n",
    "                bn_final:bool=False): # concat_pool:bool=True, nc:int,\n",
    "    \"Model head that takes `nf` features, runs through `lin_ftrs`, and about `nc` classes.\"\n",
    "    \n",
    "    # ADDED TWO MORE 512 LAYERS !!!\n",
    "    lin_ftrs = [nf, 512, 512, 512, 512] if lin_ftrs is None else [nf] + lin_ftrs + [nc]\n",
    "    # remove last 512 fc layer to reduce MODEL SIZE ??? ???\n",
    "    \n",
    "    ps = listify(ps)\n",
    "    if len(ps) == 1: ps = [ps[0]/2] * (len(lin_ftrs)-2) + ps\n",
    "    actns = [nn.ReLU(inplace=True)] * (len(lin_ftrs)-2) + [None]\n",
    "    #pool = AdaptiveConcatPool2d() if concat_pool else nn.AdaptiveAvgPool2d(1)\n",
    "    #layers = [pool, Flatten()]\n",
    "    layers = []\n",
    "    for ni,no,p,actn in zip(lin_ftrs[:-1], lin_ftrs[1:], ps, actns):\n",
    "        layers += bn_drop_lin(ni, no, True, p, actn)\n",
    "    if bn_final: layers.append(nn.BatchNorm1d(lin_ftrs[-1], momentum=0.01))\n",
    "    #layers.append(AdaCos(lin_ftrs[-1], nc))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:49.625153Z",
     "start_time": "2019-09-02T17:57:49.601778Z"
    }
   },
   "outputs": [],
   "source": [
    "#adacos_head = create_adacos_head(nf=2048+1) \n",
    "adacos_head = create_adacos_head(nf=1536*2+128*3)\n",
    "# se_xresnet50f: 2048*2=4096, ctf: 128*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:49.636749Z",
     "start_time": "2019-09-02T17:57:49.626078Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): BatchNorm1d(3456, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (1): Dropout(p=0.25)\n",
       "  (2): Linear(in_features=3456, out_features=512, bias=True)\n",
       "  (3): ReLU(inplace)\n",
       "  (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (5): Dropout(p=0.25)\n",
       "  (6): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (7): ReLU(inplace)\n",
       "  (8): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (9): Dropout(p=0.25)\n",
       "  (10): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (11): ReLU(inplace)\n",
       "  (12): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (13): Dropout(p=0.5)\n",
       "  (14): Linear(in_features=512, out_features=512, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adacos_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:49.647218Z",
     "start_time": "2019-09-02T17:57:49.637680Z"
    }
   },
   "outputs": [],
   "source": [
    "#adacos_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:49.665119Z",
     "start_time": "2019-09-02T17:57:49.648329Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 512])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adacos_head(torch.randn(2, 1536*2+128*3)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:49.683948Z",
     "start_time": "2019-09-02T17:57:49.666076Z"
    }
   },
   "outputs": [],
   "source": [
    "# from https://github.com/4uiiurz1/pytorch-adacos/blob/master/metrics.py\n",
    "class AdaCos(nn.Module):\n",
    "    def __init__(self, num_features, num_classes, m=0.50):\n",
    "        super(AdaCos, self).__init__()\n",
    "        self.num_features = num_features\n",
    "        self.n_classes = num_classes\n",
    "        self.s = math.sqrt(2) * math.log(num_classes - 1)\n",
    "        self.m = m\n",
    "        self.We = nn.Parameter(torch.FloatTensor(num_classes, num_features))\n",
    "        nn.init.xavier_uniform_(self.We)\n",
    "\n",
    "    def forward(self, xb, yb):\n",
    "        \n",
    "        #print(yb.shape)\n",
    "        #pdb.set_trace()\n",
    "        \n",
    "        # normalize features\n",
    "        x = F.normalize(xb)\n",
    "        # normalize weights\n",
    "        W = F.normalize(self.We)\n",
    "        # dot product\n",
    "        logits = F.linear(x, W)\n",
    "        \n",
    "        # for training in non-AdaCos mode (= no yb date in the forward pass):\n",
    "        if yb is None:\n",
    "            print('yb = None')\n",
    "            return logits\n",
    "        \n",
    "        # feature re-scale\n",
    "        theta = torch.acos(torch.clamp(logits, -1.0 + 1e-7, 1.0 - 1e-7))\n",
    "        one_hot = torch.zeros_like(logits)\n",
    "        \n",
    "        # ORIGINAL\n",
    "        #one_hot.scatter_(1, yb.view(-1, 1).long(), 1)\n",
    "        #with torch.no_grad():\n",
    "        #    B_avg = torch.where(one_hot < 1, torch.exp(self.s * logits), torch.zeros_like(logits))\n",
    "        #    B_avg = torch.sum(B_avg) / xb.size(0)\n",
    "        #    #print(B_avg)\n",
    "        #    theta_med = torch.median(theta[one_hot == 1])\n",
    "        #    self.s = torch.log(B_avg) / torch.cos(torch.min(math.pi/4 * torch.ones_like(theta_med), theta_med))\n",
    "        #    #print(self.s)\n",
    "            \n",
    "        # ADAPTED FOR CUTMIX TO GET MIXED SCALE PARAMETER\n",
    "        with torch.no_grad():\n",
    "            # FROM nb_new_data_augmentation_adacos2.py LINE 888\n",
    "            # AND https://github.com/fastai/fastai/blob/master/fastai/callbacks/mixup.py#L40\n",
    "            if yb.ndim == 2:# and target.shape[-1] >1:\n",
    "                n_mod_patches = (yb.shape[-1] - 1) // 2\n",
    "                #c_ = yb[:, 1:n_mod_patches + 1]\n",
    "                c_ = yb[:, 0:n_mod_patches + 1]\n",
    "                W_ = yb[:, n_mod_patches + 1:]\n",
    "                self.s_scaled = []\n",
    "                \n",
    "                # this loop is only realdy needed when we have different probabilities inside a batch\n",
    "                # which we do not have (right now)! So this could be cleaned up, but we leave until\n",
    "                # we know we will not need the case with different probabilities in a batch.\n",
    "                for k in range(n_mod_patches+1):\n",
    "                    yb_new = c_[:, k].long()\n",
    "                    #pdb.set_trace()\n",
    "                    \n",
    "                    one_hot.scatter_(1, yb_new.view(-1,1).long(), 1)\n",
    "                    \n",
    "                    B_avg = torch.where(one_hot < 1, torch.exp(self.s * logits), torch.zeros_like(logits))\n",
    "                    B_avg = torch.sum(B_avg) / xb.size(0)\n",
    "                    theta_med = torch.median(theta[one_hot == 1])\n",
    "                    self.s = torch.log(B_avg) / torch.cos(torch.min(math.pi/4 * torch.ones_like(theta_med), theta_med))\n",
    "                    \n",
    "                    if k+1 == len(range(n_mod_patches+1)):\n",
    "                        #self.s_scaled.append((1-W_[:, k-1]) * self.s)\n",
    "                        self.s_scaled.append((1-W_[0, k-1]) * self.s)\n",
    "                        # For more than two the sum of W_[:, :k] has to be used!!!\n",
    "                    else:\n",
    "                        #self.s_scaled.append(W_[:, k] * self.s)\n",
    "                        self.s_scaled.append(W_[0, k] * self.s)\n",
    "                    # Mixed B_avg & self.s and single are not really far off, but now we have it coded\n",
    "                    # se we keep it (until it breaks something later).\n",
    "                self.s = torch.add(*self.s_scaled)\n",
    "                # Clean up, self.s_scaled is just a vector with the same entry multiple times\n",
    "                # when it is not indexed above with W_[0,... !\n",
    "            else:\n",
    "                one_hot.scatter_(1, yb.view(-1,1).long(), 1)\n",
    "                B_avg = torch.where(one_hot < 1, torch.exp(self.s * logits), torch.zeros_like(logits))\n",
    "                B_avg = torch.sum(B_avg) / xb.size(0)\n",
    "                theta_med = torch.median(theta[one_hot == 1])\n",
    "                self.s = torch.log(B_avg) / torch.cos(torch.min(math.pi/4 * torch.ones_like(theta_med), theta_med))\n",
    "        \n",
    "        output = self.s * logits\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:49.696978Z",
     "start_time": "2019-09-02T17:57:49.684966Z"
    }
   },
   "outputs": [],
   "source": [
    "class AdaCosNet(nn.Module):\n",
    "    '''Simple AdaCosNet connecter to run xb through the feature extractor head\n",
    "    and then feed xb and yb into the AdaCos layer.'''\n",
    "    def __init__(self, body1, body2, head):\n",
    "        super(AdaCosNet, self).__init__()\n",
    "        self.body1 = body1\n",
    "        self.body2 = body2\n",
    "        self.head = head\n",
    "        self.adacos = AdaCos(512, 277) # was 1108 !!!\n",
    "        \n",
    "    def forward(self, xb, yb=None): # yb=None for training in non-AdaCos mode!\n",
    "        xb_img, xb_ctint, xb_pgint, xb_expint = xb\n",
    "        resnet_features = self.body1(xb_img)\n",
    "        int_features = self.body2(xb_ctint, xb_pgint, xb_expint)\n",
    "        features = torch.cat((resnet_features, int_features), dim=-1)\n",
    "        out = self.head(features)\n",
    "        #print('xb.shape: ', xb.shape,', yb.shape: ', yb.shape)\n",
    "        out = self.adacos(out, yb)\n",
    "        #print('out: ',out.shape)\n",
    "        #pdb.set_trace()\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:49.709145Z",
     "start_time": "2019-09-02T17:57:49.697989Z"
    }
   },
   "outputs": [],
   "source": [
    "adacos_efficientnet = AdaCosNet(efficientnet_fph, ctf, adacos_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:49.726828Z",
     "start_time": "2019-09-02T17:57:49.710180Z"
    }
   },
   "outputs": [],
   "source": [
    "xb = (torch.randn(2,6,sz,sz),\n",
    "      #(torch.randint(4, (2,1)),  torch.randint(4, (2,1)))\n",
    "      torch.tensor((1,3)), torch.tensor((1,3)), torch.tensor((1,3))\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:49.946017Z",
     "start_time": "2019-09-02T17:57:49.727855Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yb = None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 277])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adacos_efficientnet(xb).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:50.166379Z",
     "start_time": "2019-09-02T17:57:49.947069Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 277])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adacos_efficientnet(xb, torch.tensor([276, 1])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:50.178197Z",
     "start_time": "2019-09-02T17:57:50.167394Z"
    }
   },
   "outputs": [],
   "source": [
    "test_target = torch.tensor(\n",
    "    [[2.4700e+02, 2.3900e+02, 7.8362e-01],\n",
    "     [2.3300e+02, 1.7400e+02, 7.8362e-01],\n",
    "     [1.7400e+02, 1.3400e+02, 7.8362e-01],\n",
    "     [1.9800e+02, 1.4700e+02, 7.8362e-01]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:50.591833Z",
     "start_time": "2019-09-02T17:57:50.179205Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 277])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adacos_efficientnet((torch.randn(4,6,sz,sz), \n",
    "                     torch.tensor((1,3,0,2)), torch.tensor((1,3,0,2)), torch.tensor((1,3,0,2))),\n",
    "                    test_target).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:50.606206Z",
     "start_time": "2019-09-02T17:57:50.594569Z"
    }
   },
   "outputs": [],
   "source": [
    "# Based on https://forums.fast.ai/t/teacher-forcing/29415/4\n",
    "# https://forums.fast.ai/t/on-batch-begin-callback/35201/3\n",
    "@dataclass\n",
    "class AppendBatchTargs(Callback):\n",
    "    learn:Learner\n",
    "    def __init__(self, learn):\n",
    "        super().__init__()\n",
    "    def on_batch_begin(self, last_input, last_target, **kwargs):\n",
    "        return {'last_input':(last_input, last_target), 'last_target':last_target}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosinus similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full single features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:50.619319Z",
     "start_time": "2019-09-02T17:57:50.608940Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://github.com/ducha-aiki/whale-identification-2018/blob/master/reproduce_problems.ipynb\n",
    "# And for test-time augmentation I used following random solution: switch train and val transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:50.633187Z",
     "start_time": "2019-09-02T17:57:50.622109Z"
    }
   },
   "outputs": [],
   "source": [
    "# extended tfms\n",
    "tfms = get_transforms(do_flip=True, flip_vert=True, \n",
    "                      max_rotate=90.0, max_zoom=1.1, \n",
    "                      max_lighting=0.2, max_warp=0.2, \n",
    "                      p_affine=0.75, p_lighting=0.75, \n",
    "                      xtra_tfms=[color_augmentation()])\n",
    "\n",
    "# crop_pad: https://forums.fast.ai/t/misc-issues/35386/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:50.646265Z",
     "start_time": "2019-09-02T17:57:50.635992Z"
    }
   },
   "outputs": [],
   "source": [
    "# extended tfms w/o color_augmentation !!!\n",
    "#tfms = get_transforms(do_flip=True, flip_vert=True, \n",
    "#                      max_rotate=90.0, max_zoom=1.1, \n",
    "#                      max_lighting=0.2, max_warp=0.2, \n",
    "#                      p_affine=0.75, p_lighting=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:50.660068Z",
     "start_time": "2019-09-02T17:57:50.649043Z"
    }
   },
   "outputs": [],
   "source": [
    "# \"crop_pad\" to sz\n",
    "tfms[0][0] = crop_pad(size=sz, row_pct=[0.,1.], col_pct=[0.,1.])\n",
    "tfms[1][0] = crop_pad(size=sz, row_pct=[0.,1.], col_pct=[0.,1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:50.673343Z",
     "start_time": "2019-09-02T17:57:50.662854Z"
    }
   },
   "outputs": [],
   "source": [
    "#sz, bs = 300, 8*2*2 # 3436MiB /  7952MiB\n",
    "#sz, bs = 300, 8*8 # 6884MiB /  7952MiB\n",
    "sz, bs = 300, 8*11 # 7938MiB /  7952MiB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:50.686406Z",
     "start_time": "2019-09-02T17:57:50.676120Z"
    }
   },
   "outputs": [],
   "source": [
    "#pg = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:53.036353Z",
     "start_time": "2019-09-02T17:57:50.689179Z"
    }
   },
   "outputs": [],
   "source": [
    "# VALID SPLIT (incl. tfms)\n",
    "data = (ImageList6Dct.from_df(df_train[df_train['pg'] == pg], path='train')\n",
    "        .split_from_df(col=-3) # FULL: .split_none() # !!!\n",
    "        .label_from_df(cols=-5)\n",
    "        .add_test(ImageList6Dct.from_df(df_test[df_test['pg'] == pg], path='test'))\n",
    "        .transform(tfms, size=sz)\n",
    "        .databunch(bs=bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:53.050231Z",
     "start_time": "2019-09-02T17:57:53.039329Z"
    }
   },
   "outputs": [],
   "source": [
    "data.normalize([stats_mean, stats_var]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:53.063520Z",
     "start_time": "2019-09-02T17:57:53.052977Z"
    }
   },
   "outputs": [],
   "source": [
    "#ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:53.078017Z",
     "start_time": "2019-09-02T17:57:53.066299Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:53.091141Z",
     "start_time": "2019-09-02T17:57:53.080803Z"
    }
   },
   "outputs": [],
   "source": [
    "#data.train_dl.dl.batch_sampler.sampler = torch.utils.data.SequentialSampler(data.train_ds)\n",
    "#data.train_dl.dl.batch_sampler.drop_last = False\n",
    "#\n",
    "#data.valid_dl.dl.batch_sampler.sampler = torch.utils.data.SequentialSampler(data.valid_ds)\n",
    "#data.valid_dl.dl.batch_sampler.drop_last = False\n",
    "#\n",
    "## DOES WORK TOO FOR TEST DL ??? ??? (Or do we need to set the test dataset to the valid dataset?)\n",
    "#data.test_dl.dl.batch_sampler.sampler = torch.utils.data.SequentialSampler(data.test_ds)\n",
    "#data.test_dl.dl.batch_sampler.drop_last = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:54.908948Z",
     "start_time": "2019-09-02T17:57:53.093919Z"
    }
   },
   "outputs": [],
   "source": [
    "learn = Learner(data, adacos_efficientnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:55.103633Z",
     "start_time": "2019-09-02T17:57:54.909930Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.load('effnet/adacos_efficientnet_b3_ct_pg_exp_Pre060e050pg'+str(pg)+'e100_190901');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:55.114393Z",
     "start_time": "2019-09-02T17:57:55.104578Z"
    }
   },
   "outputs": [],
   "source": [
    "#def get_feats(model, dataloader, cycles=1):\n",
    "#    feats = []\n",
    "#    targs = []\n",
    "#    model.eval()\n",
    "#    with torch.no_grad():\n",
    "#        for i in range(cycles): # for TTA\n",
    "#            for xb, yb in dataloader:\n",
    "#                body_out = model.body(xb)\n",
    "#                head_out = model.head(body_out)\n",
    "#                feats.append(head_out.cpu())\n",
    "#                targs.append(yb.cpu())\n",
    "#    return feats, targs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:55.126470Z",
     "start_time": "2019-09-02T17:57:55.115357Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_feats(model, dataloader, cycles=1):\n",
    "    feats = []\n",
    "    targs = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(cycles): # for TTA\n",
    "            for xb, yb in dataloader:\n",
    "                xb_img, xb_ctint, xb_pgint, xb_expint = xb\n",
    "                img_features = model.body1(xb_img)\n",
    "                int_features = model.body2(xb_ctint, xb_pgint, xb_expint)\n",
    "                features = torch.cat((img_features, int_features), dim=-1)\n",
    "                out = model.head(features)\n",
    "                feats.append(out.cpu())\n",
    "                targs.append(yb.cpu())\n",
    "    return feats, targs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-02T17:57:55.138944Z",
     "start_time": "2019-09-02T17:57:55.127490Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_img_exp_feats(model, dataloader, cycles=1):\n",
    "    feats = []\n",
    "    targs = []\n",
    "    img_feats = []\n",
    "    exp_input = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(cycles): # for TTA\n",
    "            for xb, yb in dataloader:\n",
    "                xb_img, xb_ctint, xb_pgint, xb_expint = xb\n",
    "                img_features = model.body1(xb_img)\n",
    "                int_features = model.body2(xb_ctint, xb_pgint, xb_expint)\n",
    "                features = torch.cat((img_features, int_features), dim=-1)\n",
    "                out = model.head(features)\n",
    "                feats.append(out.cpu())\n",
    "                targs.append(yb.cpu())\n",
    "                img_feats.append(img_features)\n",
    "                exp_input.append(xb_expint.cpu())\n",
    "    return feats, targs, img_feats, exp_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-02T17:57:47.667Z"
    }
   },
   "outputs": [],
   "source": [
    "feats, targs = get_feats(learn.model, learn.data.train_dl, cycles=3)\n",
    "#feats, targs, img_feats, exp_input = get_img_exp_feats(learn.model, learn.data.train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-02T17:57:47.673Z"
    }
   },
   "outputs": [],
   "source": [
    "feats = torch.cat(feats, dim=0)\n",
    "targs = torch.cat(targs, dim=0)\n",
    "#img_feats = torch.cat(img_feats, dim=0)\n",
    "#exp_input = torch.cat(exp_input, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-02T17:57:47.680Z"
    }
   },
   "outputs": [],
   "source": [
    "# get class from data classes index\n",
    "targs_cl = torch.tensor([learn.data.classes[t] for t in targs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-02T17:57:47.687Z"
    }
   },
   "outputs": [],
   "source": [
    "feats.shape, targs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-02T17:57:47.693Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save('pred/feats_train_pg'+str(pg)+'.npy', feats)\n",
    "np.save('pred/targs_train_pg'+str(pg)+'.npy', targs)\n",
    "np.save('pred/targs_cl_train_pg'+str(pg)+'.npy', targs_cl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-02T17:57:47.701Z"
    }
   },
   "outputs": [],
   "source": [
    "feats, targs = get_feats(learn.model, learn.data.valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-02T17:57:47.708Z"
    }
   },
   "outputs": [],
   "source": [
    "feats = torch.cat(feats, dim=0)\n",
    "targs = torch.cat(targs, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-02T17:57:47.715Z"
    }
   },
   "outputs": [],
   "source": [
    "# get class from data classes index\n",
    "targs_cl = torch.tensor([learn.data.classes[t] for t in targs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-02T17:57:47.723Z"
    }
   },
   "outputs": [],
   "source": [
    "feats.shape, feats.shape, targs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-02T17:57:47.730Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save('pred/feats_valid_pg'+str(pg)+'.npy', feats)\n",
    "np.save('pred/targs_valid_pg'+str(pg)+'.npy', targs)\n",
    "np.save('pred/targs_cl_valid_pg'+str(pg)+'.npy', targs_cl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-02T17:57:47.738Z"
    }
   },
   "outputs": [],
   "source": [
    "feats, targs = get_feats(learn.model, learn.data.test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-02T17:57:47.745Z"
    }
   },
   "outputs": [],
   "source": [
    "del targs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-02T17:57:47.753Z"
    }
   },
   "outputs": [],
   "source": [
    "feats = torch.cat(feats, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-02T17:57:47.760Z"
    }
   },
   "outputs": [],
   "source": [
    "feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-02T17:57:47.767Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save('pred/feats_test_pg'+str(pg)+'.npy', feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-02T17:57:47.775Z"
    }
   },
   "outputs": [],
   "source": [
    "len(learn.data.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-02T17:57:47.783Z"
    }
   },
   "outputs": [],
   "source": [
    "# get the names\n",
    "preds_names = learn.data.test_ds.x.items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-02T17:57:47.791Z"
    }
   },
   "outputs": [],
   "source": [
    "# without site\n",
    "#preds_names = [x.split('/')[1]+'_'+x.split('/')[2][-1]+'_'+x.split('/')[3][:3] for x in preds_names]\n",
    "\n",
    "# with site\n",
    "preds_names = [x.split('/')[1]+'_'+x.split('/')[2][-1]+'_'+x.split('/')[3] for x in preds_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-02T17:57:47.800Z"
    }
   },
   "outputs": [],
   "source": [
    "preds_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-02T17:57:47.807Z"
    }
   },
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/27745500/how-to-save-a-list-to-a-file-and-read-it-as-a-list-type\n",
    "with open('pred/preds_test_pg'+str(pg)+'_names.txt', 'wb') as fp:   #Pickling\n",
    "    pickle.dump(preds_names, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-02T17:57:47.815Z"
    }
   },
   "outputs": [],
   "source": [
    "#with open('pred/preds_test_pg'+str(pg)+'_names.txt', 'rb') as fp:   # Unpickling\n",
    "#    b = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-02T17:57:47.823Z"
    }
   },
   "outputs": [],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-02T17:57:47.832Z"
    }
   },
   "outputs": [],
   "source": [
    "preds_test = np.load('pred/preds_test_pg'+str(pg)+'.npy')\n",
    "dist_test = np.load('pred/dist_test_pg'+str(pg)+'.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-02T17:57:47.839Z"
    }
   },
   "outputs": [],
   "source": [
    "len(preds_names), len(preds_test), len(dist_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-02T17:57:47.848Z"
    }
   },
   "outputs": [],
   "source": [
    "#preds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-02T17:57:47.857Z"
    }
   },
   "outputs": [],
   "source": [
    "#dist_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-02T17:57:47.867Z"
    }
   },
   "outputs": [],
   "source": [
    "df_preds = pd.DataFrame({'id_code_site': preds_names, 'sirna': preds_test, 'cossim': dist_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-02T17:57:47.879Z"
    }
   },
   "outputs": [],
   "source": [
    "# get id_code without site\n",
    "df_preds['id_code'] = df_preds['id_code_site'].apply(lambda x: x[:-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-02T17:57:47.887Z"
    }
   },
   "outputs": [],
   "source": [
    "# get row indices with highest cosine similiarity\n",
    "idx = []\n",
    "for i, r in enumerate(df_preds.sort_values('id_code').iterrows()):\n",
    "    #print(r)\n",
    "    #print('i: ',i)\n",
    "    #print('idx: ',r[0])\n",
    "    #print(r[1]['cossim'])\n",
    "    if i % 2:\n",
    "        # distance from row 2 is \n",
    "        if dist < r[1]['cossim']:\n",
    "            idx.append(r[0])\n",
    "        else:\n",
    "            idx.append(idx_row_before)\n",
    "    else:\n",
    "        # save dist from row 1 for comparison in next iteration\n",
    "        dist = r[1]['cossim']\n",
    "        idx_row_before = r[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-02T17:57:47.896Z"
    }
   },
   "outputs": [],
   "source": [
    "idx[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-02T17:57:47.905Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_preds.sort_values('id_code').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-02T17:57:47.912Z"
    }
   },
   "outputs": [],
   "source": [
    "#df_preds.loc[idx,['id_code','sirna']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-02T17:57:47.924Z"
    }
   },
   "outputs": [],
   "source": [
    "# 'effnet/adacos_efficientnet_b3_ct_pg_exp_Pre060e050pg'+str(pg)+'e100_190901'\n",
    "model = 'adacos_efficientnet_b3_ct_pg_exp_Pre060e050pg'+str(pg)+'e100_190901_3xTTA-cossim'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-02T17:57:47.932Z"
    }
   },
   "outputs": [],
   "source": [
    "df_preds.loc[idx,['id_code','sirna']].to_csv('sub/'+model+'.csv.gz', index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-02T17:57:47.939Z"
    }
   },
   "outputs": [],
   "source": [
    "#!kaggle competitions submit -c recursion-cellular-image-classification -f sub/{model}.csv.gz -m \"{model}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-02T17:57:47.948Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('pred/preds_test_pg'+str(pg)+'_names.txt', 'rb') as fp:   # Unpickling\n",
    "    preds_names = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-02T17:57:47.956Z"
    }
   },
   "outputs": [],
   "source": [
    "preds_test_full = np.load('pred/preds_test_pg'+str(pg)+'_full.npy')\n",
    "dist_test_full = np.load('pred/dist_test_pg'+str(pg)+'_full.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-02T17:57:47.964Z"
    }
   },
   "outputs": [],
   "source": [
    "preds_test_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-02T17:57:47.973Z"
    }
   },
   "outputs": [],
   "source": [
    "dist_test_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-02T17:57:47.981Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    df_preds_full = pd.DataFrame({'id_code_site': preds_names,\n",
    "                                  'sirna': preds_test_full[:,i],\n",
    "                                  'cossim': dist_test_full[:,i]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-02T17:57:47.989Z"
    }
   },
   "outputs": [],
   "source": [
    "type(preds_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-02T17:57:48.001Z"
    }
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "df_preds_full = pd.DataFrame({'id_code_site': preds_names,\n",
    "                                  'sirna': preds_test_full[:,i],\n",
    "                                  'cossim': dist_test_full[:,i]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-02T17:57:48.010Z"
    }
   },
   "outputs": [],
   "source": [
    "df_preds_full.sort_values(by='cossim', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-02T17:57:48.019Z"
    }
   },
   "outputs": [],
   "source": [
    "df_preds_full.sort_values(by='cossim', ascending=False).tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-02T17:57:48.026Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "for i, d in df_preds_full.sort_values(by='cossim', ascending=False).iterrows():\n",
    "    print(i)\n",
    "    print(d)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-02T17:57:48.034Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test.head()#.experiment.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-02T17:57:48.041Z"
    }
   },
   "outputs": [],
   "source": [
    "df_preds_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-02T17:57:48.049Z"
    }
   },
   "outputs": [],
   "source": [
    "df_preds_full.groupby('sirna')['id_code_site'].nunique()#.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-09-02T17:57:48.059Z"
    }
   },
   "outputs": [],
   "source": [
    "# ERROR ANALYSIS !!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "488px",
    "width": "305px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "206px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
