{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:13.068996Z",
     "start_time": "2019-08-22T17:58:12.910595Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:13.770848Z",
     "start_time": "2019-08-22T17:58:13.119261Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from fastai.vision import *\n",
    "from fastai.vision.models.xresnet import *\n",
    "\n",
    "# for datablock API\n",
    "from fastai.vision.image import _resolve_tfms, _get_crop_target, _round_multiple, _get_resize_target, _affine_grid, _grid_sample, _affine_mult\n",
    "\n",
    "# for XResNet\n",
    "#from fastai.vision.models.xresnet import act_fn, init_cnn, conv, noop, conv_layer, ResBlock, filt_sz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:13.782232Z",
     "start_time": "2019-08-22T17:58:13.772197Z"
    }
   },
   "outputs": [],
   "source": [
    "from fastai.callbacks import CSVLogger, ReduceLROnPlateauCallback, SaveModelCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:13.794227Z",
     "start_time": "2019-08-22T17:58:13.783473Z"
    }
   },
   "outputs": [],
   "source": [
    "from efficientnet_pytorch import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:13.805628Z",
     "start_time": "2019-08-22T17:58:13.795338Z"
    }
   },
   "outputs": [],
   "source": [
    "from nb_new_data_augmentation_adacos_celltype_plategroup_exp import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:13.974583Z",
     "start_time": "2019-08-22T17:58:13.959832Z"
    }
   },
   "outputs": [],
   "source": [
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:14.295981Z",
     "start_time": "2019-08-22T17:58:14.251570Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.55'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6D image with celltype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:14.730682Z",
     "start_time": "2019-08-22T17:58:14.715826Z"
    }
   },
   "outputs": [],
   "source": [
    "class Image6Dct(Image):\n",
    "    \"Support applying transforms to image data in `px`.\"\n",
    "    def __init__(self, px:Tensor, ctint, pgint, expint): # ct\n",
    "        self._px = px\n",
    "        self._logit_px=None\n",
    "        #self.ct = ct\n",
    "        self.ctint = ctint\n",
    "        self.pgint = pgint\n",
    "        self.expint = expint\n",
    "        self._flow=None\n",
    "        self._affine_mat=None\n",
    "        self.sample_kwargs = {}\n",
    "    \n",
    "    def _repr_image_format(self, format_str):\n",
    "        with BytesIO() as str_buffer:\n",
    "            #plt.imsave(str_buffer, image2np(self.px[:3]), format=format_str)\n",
    "            plt.imsave(str_buffer, \n",
    "                       np.concatenate((image2np(self.px[:3]), \n",
    "                                       image2np(self.px[3:])), axis=1),\n",
    "                       format=format_str)\n",
    "            return str_buffer.getvalue()\n",
    "        \n",
    "    def clone(self):\n",
    "        \"Mimic the behavior of torch.clone for `Image` objects.\"\n",
    "        return self.__class__(self.px.clone(), self.ctint.clone(), self.pgint.clone(), self.expint.clone()) # self.ct.clone(), \n",
    "\n",
    "    @property\n",
    "    def data(self)->TensorImage:\n",
    "        \"Return this images pixels as a tensor.\"\n",
    "        return self.px, self.ctint, self.pgint, self.expint\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:14.935910Z",
     "start_time": "2019-08-22T17:58:14.909883Z"
    }
   },
   "outputs": [],
   "source": [
    "def open_image_6Dct(fn:PathOrStr, div:bool=True, convert_mode:str='L', cls:type=Image6Dct,\n",
    "        after_open:Callable=None)->Image:\n",
    "    \"Return `Image` object created from image in file `fn`.\"\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", UserWarning) # EXIF warning from TiffPlugin\n",
    "        \n",
    "        x = []\n",
    "        for i in range(6):\n",
    "            c = PIL.Image.open(fn+'_w'+str(i+1)+'.png').convert(convert_mode)\n",
    "            if after_open: c = after_open(c)\n",
    "            c = np.asarray(c)\n",
    "            c = torch.from_numpy(c.astype(np.float32, copy=False))\n",
    "            x.append(c)\n",
    "    ct = fn.split('/')[1].split('-')[0] # get cell type\n",
    "    ctint = torch.tensor(ct2int[ct])\n",
    "    pgint = torch.tensor(fn2pgint[fn])\n",
    "    exp = fn.split('/')[1] # get experiment\n",
    "    expint = torch.tensor(exp2int[exp])\n",
    "    x = torch.stack(x)\n",
    "    if div: x.div_(255)\n",
    "    return cls(x, ctint, pgint, expint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:15.192443Z",
     "start_time": "2019-08-22T17:58:15.143994Z"
    }
   },
   "outputs": [],
   "source": [
    "# number experiments so that cell types do not overlap\n",
    "# and the valid and test dataset do have a embedding they can use!\n",
    "exp2int = {'HEPG2-01': 0,\n",
    "           'HEPG2-02': 1,\n",
    "           'HEPG2-03': 2,\n",
    "           'HEPG2-04': 3,\n",
    "           'HEPG2-05': 4,\n",
    "           # valid\n",
    "           'HEPG2-06': 0,\n",
    "           'HEPG2-07': 1,\n",
    "           # test\n",
    "           'HEPG2-08': 0,\n",
    "           'HEPG2-09': 1,\n",
    "           'HEPG2-10': 2,\n",
    "           'HEPG2-11': 3,           \n",
    "             \n",
    "           # train\n",
    "           'HUVEC-01': 5,\n",
    "           'HUVEC-02': 6,\n",
    "           'HUVEC-03': 7,\n",
    "           'HUVEC-04': 8,\n",
    "           'HUVEC-05': 9,\n",
    "           'HUVEC-06': 10,\n",
    "           'HUVEC-07': 11, \n",
    "           'HUVEC-08': 12,\n",
    "           'HUVEC-09': 13,\n",
    "           'HUVEC-10': 14,\n",
    "           'HUVEC-11': 15,\n",
    "           'HUVEC-12': 16,\n",
    "           'HUVEC-13': 17,\n",
    "           'HUVEC-14': 18, \n",
    "           # valid\n",
    "           'HUVEC-15': 5,\n",
    "           'HUVEC-16': 6, \n",
    "           # test\n",
    "           'HUVEC-17': 5,\n",
    "           'HUVEC-18': 6,\n",
    "           'HUVEC-19': 7,\n",
    "           'HUVEC-20': 8,\n",
    "           'HUVEC-21': 9,\n",
    "           'HUVEC-22': 10,\n",
    "           'HUVEC-23': 11,\n",
    "           'HUVEC-24': 12,\n",
    "             \n",
    "           # train\n",
    "           'RPE-01': 19,\n",
    "           'RPE-02': 20,\n",
    "           'RPE-03': 21,\n",
    "           'RPE-04': 22,\n",
    "           'RPE-05': 23,\n",
    "           # valid\n",
    "           'RPE-06': 19,\n",
    "           'RPE-07': 20,\n",
    "           # test\n",
    "           'RPE-08': 19,\n",
    "           'RPE-09': 20,\n",
    "           'RPE-10': 21,\n",
    "           'RPE-11': 22,\n",
    "             \n",
    "           # train\n",
    "           'U2OS-01': 24,\n",
    "           'U2OS-02': 25,\n",
    "           # valid\n",
    "           'U2OS-03': 24,\n",
    "           # test\n",
    "           'U2OS-04': 24,\n",
    "           'U2OS-05': 25\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:15.440767Z",
     "start_time": "2019-08-22T17:58:15.423835Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HEPG2-01': 0,\n",
       " 'HEPG2-02': 1,\n",
       " 'HEPG2-03': 2,\n",
       " 'HEPG2-04': 3,\n",
       " 'HEPG2-05': 4,\n",
       " 'HEPG2-06': 0,\n",
       " 'HEPG2-07': 1,\n",
       " 'HEPG2-08': 0,\n",
       " 'HEPG2-09': 1,\n",
       " 'HEPG2-10': 2,\n",
       " 'HEPG2-11': 3,\n",
       " 'HUVEC-01': 5,\n",
       " 'HUVEC-02': 6,\n",
       " 'HUVEC-03': 7,\n",
       " 'HUVEC-04': 8,\n",
       " 'HUVEC-05': 9,\n",
       " 'HUVEC-06': 10,\n",
       " 'HUVEC-07': 11,\n",
       " 'HUVEC-08': 12,\n",
       " 'HUVEC-09': 13,\n",
       " 'HUVEC-10': 14,\n",
       " 'HUVEC-11': 15,\n",
       " 'HUVEC-12': 16,\n",
       " 'HUVEC-13': 17,\n",
       " 'HUVEC-14': 18,\n",
       " 'HUVEC-15': 5,\n",
       " 'HUVEC-16': 6,\n",
       " 'HUVEC-17': 5,\n",
       " 'HUVEC-18': 6,\n",
       " 'HUVEC-19': 7,\n",
       " 'HUVEC-20': 8,\n",
       " 'HUVEC-21': 9,\n",
       " 'HUVEC-22': 10,\n",
       " 'HUVEC-23': 11,\n",
       " 'HUVEC-24': 12,\n",
       " 'RPE-01': 19,\n",
       " 'RPE-02': 20,\n",
       " 'RPE-03': 21,\n",
       " 'RPE-04': 22,\n",
       " 'RPE-05': 23,\n",
       " 'RPE-06': 19,\n",
       " 'RPE-07': 20,\n",
       " 'RPE-08': 19,\n",
       " 'RPE-09': 20,\n",
       " 'RPE-10': 21,\n",
       " 'RPE-11': 22,\n",
       " 'U2OS-01': 24,\n",
       " 'U2OS-02': 25,\n",
       " 'U2OS-03': 24,\n",
       " 'U2OS-04': 24,\n",
       " 'U2OS-05': 25}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp2int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:16.026464Z",
     "start_time": "2019-08-22T17:58:15.942727Z"
    }
   },
   "outputs": [],
   "source": [
    "df_full_plate_pattern = pd.read_csv('full_dataset_v2_path_plate_groups_only_20190812.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:16.171243Z",
     "start_time": "2019-08-22T17:58:16.151336Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>plate_pattern</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train/HEPG2-01/Plate1/B03_s1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train/HEPG2-01/Plate1/B04_s1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train/HEPG2-01/Plate1/B05_s1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train/HEPG2-01/Plate1/B06_s1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train/HEPG2-01/Plate1/B07_s1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           path  plate_pattern\n",
       "0  train/HEPG2-01/Plate1/B03_s1              0\n",
       "1  train/HEPG2-01/Plate1/B04_s1              0\n",
       "2  train/HEPG2-01/Plate1/B05_s1              0\n",
       "3  train/HEPG2-01/Plate1/B06_s1              0\n",
       "4  train/HEPG2-01/Plate1/B07_s1              0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full_plate_pattern.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:16.878196Z",
     "start_time": "2019-08-22T17:58:16.847006Z"
    }
   },
   "outputs": [],
   "source": [
    "fn2pgint = dict(zip(df_full_plate_pattern.path.values, \n",
    "                              df_full_plate_pattern.plate_pattern.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:17.079216Z",
     "start_time": "2019-08-22T17:58:17.036446Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn2pgint['train/HEPG2-01/Plate1/B03_s1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:17.264526Z",
     "start_time": "2019-08-22T17:58:17.223182Z"
    }
   },
   "outputs": [],
   "source": [
    "# cell types from rcic_v10_inspect_image_data.ipynb \"pixel stats\"\n",
    "cts = ['HEPG2', 'HUVEC', 'RPE', 'U2OS']\n",
    "int2ct = {i: ct for i, ct in enumerate(cts)}\n",
    "ct2int = {ct: i for i, ct in int2ct.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:17.438112Z",
     "start_time": "2019-08-22T17:58:17.421488Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'HEPG2', 1: 'HUVEC', 2: 'RPE', 3: 'U2OS'}\n",
      "{'HEPG2': 0, 'HUVEC': 1, 'RPE': 2, 'U2OS': 3}\n"
     ]
    }
   ],
   "source": [
    "print(int2ct)\n",
    "print(ct2int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:17.654267Z",
     "start_time": "2019-08-22T17:58:17.610506Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HEPG2'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct = 'train/HEPG2-01/Plate1/B03_s1'.split('/')[1].split('-')[0]; ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:17.837730Z",
     "start_time": "2019-08-22T17:58:17.794976Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct2int[ct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:18.028209Z",
     "start_time": "2019-08-22T17:58:18.011811Z"
    }
   },
   "outputs": [],
   "source": [
    "PATH_trunc = 'train/HEPG2-01/Plate1/B03_s1' # path is missing suffix \"_w1.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:18.440912Z",
     "start_time": "2019-08-22T17:58:18.383828Z"
    }
   },
   "outputs": [],
   "source": [
    "img = open_image_6Dct(PATH_trunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:18.690133Z",
     "start_time": "2019-08-22T17:58:18.679320Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 512, 512])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.px.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:18.968973Z",
     "start_time": "2019-08-22T17:58:18.921677Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(0), tensor(0))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.ctint, img.pgint, img.expint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:19.438379Z",
     "start_time": "2019-08-22T17:58:19.421136Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Tensor, torch.Tensor, torch.Tensor)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(img.ctint), type(img.pgint), type(img.expint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:20.115642Z",
     "start_time": "2019-08-22T17:58:20.100629Z"
    }
   },
   "outputs": [],
   "source": [
    "class ImageList6Dct(ImageList): #ImageList\n",
    "    def __init__(self, *args, convert_mode='L', after_open:Callable=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.convert_mode,self.after_open = convert_mode,after_open\n",
    "        self.copy_new.append('convert_mode')\n",
    "        self.c,self.sizes = 6,{}\n",
    "        \n",
    "    def open(self, fn):\n",
    "        \"Open image in `fn`, subclass and overwrite for custom behavior.\"\n",
    "        return open_image_6Dct(fn, convert_mode=self.convert_mode, after_open=self.after_open)\n",
    "\n",
    "#    def show(self, img):\n",
    "#        #return torch.cat((img[i][:3], img[i][3:]), dim=1)\n",
    "#        show_image(img)\n",
    "    \n",
    "    # https://docs.fast.ai/tutorial.itemlist.html#Advanced-show-methods\n",
    "    def show_xys(self, xs, ys, figsize:Tuple[int,int]=(15,10), **kwargs):\n",
    "        \"Show the `xs` and `ys` on a figure of `figsize`. `kwargs` are passed to the show method.\"\n",
    "        rows = int(math.sqrt(len(xs)))\n",
    "        fig, axs = plt.subplots(rows,rows,figsize=figsize)\n",
    "        for i, ax in enumerate(axs.flatten() if rows > 1 else [axs]):\n",
    "            #xs[i].show(ax=ax, y=ys[i], **kwargs)\n",
    "            img = Image6D(torch.cat((xs[i].data[:3], xs[i].data[3:]), dim=2)) # works but not elegant?\n",
    "            #img = Image6D(xs[i]) # does not work?\n",
    "            img.show(ax=ax, y=ys[i], **kwargs)\n",
    "        plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:20.311107Z",
     "start_time": "2019-08-22T17:58:20.295408Z"
    }
   },
   "outputs": [],
   "source": [
    "#def show_image(img:Image, ax:plt.Axes=None, figsize:tuple=(3,3), hide_axis:bool=True, cmap:str='binary',\n",
    "#                alpha:float=None, **kwargs)->plt.Axes:\n",
    "#    \"Display `Image` in notebook.\"\n",
    "#    if ax is None: fig,ax = plt.subplots(figsize=figsize)\n",
    "#    pdb.set_trace()\n",
    "#    #ax.imshow(image2np(img.data), cmap=cmap, alpha=alpha, **kwargs)\n",
    "#    ax.imshow(np.concatenate((image2np(self.px[:3]),\n",
    "#                              image2np(self.px[3:])), axis=1),\n",
    "#              cmap=cmap, alpha=alpha, **kwargs)\n",
    "#    if hide_axis: ax.axis('off')\n",
    "#    return ax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset raw files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:21.992408Z",
     "start_time": "2019-08-22T17:58:21.897668Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('full_train_dataset_valid-split-ex_v2_20190727.csv', index_col=0)\n",
    "df_test = pd.read_csv('full_test_dataset_v2_20190727.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:22.261584Z",
     "start_time": "2019-08-22T17:58:22.218668Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73030, 5)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:22.704255Z",
     "start_time": "2019-08-22T17:58:22.684579Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>experiment</th>\n",
       "      <th>sirna</th>\n",
       "      <th>multi</th>\n",
       "      <th>valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36510</th>\n",
       "      <td>U2OS-03/Plate4/O19_s2</td>\n",
       "      <td>U2OS-03</td>\n",
       "      <td>103</td>\n",
       "      <td>U2OS-03 103</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36511</th>\n",
       "      <td>U2OS-03/Plate4/O20_s2</td>\n",
       "      <td>U2OS-03</td>\n",
       "      <td>202</td>\n",
       "      <td>U2OS-03 202</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36512</th>\n",
       "      <td>U2OS-03/Plate4/O21_s2</td>\n",
       "      <td>U2OS-03</td>\n",
       "      <td>824</td>\n",
       "      <td>U2OS-03 824</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36513</th>\n",
       "      <td>U2OS-03/Plate4/O22_s2</td>\n",
       "      <td>U2OS-03</td>\n",
       "      <td>328</td>\n",
       "      <td>U2OS-03 328</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36514</th>\n",
       "      <td>U2OS-03/Plate4/O23_s2</td>\n",
       "      <td>U2OS-03</td>\n",
       "      <td>509</td>\n",
       "      <td>U2OS-03 509</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        path experiment  sirna        multi  valid\n",
       "36510  U2OS-03/Plate4/O19_s2    U2OS-03    103  U2OS-03 103      1\n",
       "36511  U2OS-03/Plate4/O20_s2    U2OS-03    202  U2OS-03 202      1\n",
       "36512  U2OS-03/Plate4/O21_s2    U2OS-03    824  U2OS-03 824      1\n",
       "36513  U2OS-03/Plate4/O22_s2    U2OS-03    328  U2OS-03 328      1\n",
       "36514  U2OS-03/Plate4/O23_s2    U2OS-03    509  U2OS-03 509      1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:22.942615Z",
     "start_time": "2019-08-22T17:58:22.896136Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>experiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19892</th>\n",
       "      <td>U2OS-05/Plate4/O19_s2</td>\n",
       "      <td>U2OS-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19893</th>\n",
       "      <td>U2OS-05/Plate4/O20_s2</td>\n",
       "      <td>U2OS-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19894</th>\n",
       "      <td>U2OS-05/Plate4/O21_s2</td>\n",
       "      <td>U2OS-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19895</th>\n",
       "      <td>U2OS-05/Plate4/O22_s2</td>\n",
       "      <td>U2OS-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19896</th>\n",
       "      <td>U2OS-05/Plate4/O23_s2</td>\n",
       "      <td>U2OS-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        path experiment\n",
       "19892  U2OS-05/Plate4/O19_s2    U2OS-05\n",
       "19893  U2OS-05/Plate4/O20_s2    U2OS-05\n",
       "19894  U2OS-05/Plate4/O21_s2    U2OS-05\n",
       "19895  U2OS-05/Plate4/O22_s2    U2OS-05\n",
       "19896  U2OS-05/Plate4/O23_s2    U2OS-05"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color augmentation transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Color Augmentation: Color variability can be increased by applying random color transformations to original training samples. We perform color augmentation by transforming every color channels Ic ← ac · Ic + bc, where ac and bc are drawn from uniform distributions ac ∼ U [0.9, 1.1] and bc ∼ U [−10, +10].\" from Domain-adversarial neural networks to address the appearance variability of histopathology images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:23.600137Z",
     "start_time": "2019-08-22T17:58:23.584955Z"
    }
   },
   "outputs": [],
   "source": [
    "# from https://github.com/fastai/fastai/blob/master/fastai/vision/transform.py#L137\n",
    "#def _rgb_randomize(x, channel:int=None, thresh:float=0.3):\n",
    "#    \"Randomize one of the channels of the input image\"\n",
    "#    if channel is None: channel = np.random.randint(0, x.shape[0] - 1)\n",
    "#    x[channel] = torch.rand(x.shape[1:]) * np.random.uniform(0, thresh)\n",
    "#    return x\n",
    "#\n",
    "#rgb_randomize = TfmPixel(_rgb_randomize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:23.831582Z",
     "start_time": "2019-08-22T17:58:23.792401Z"
    }
   },
   "outputs": [],
   "source": [
    "# Scaling factor comes from byte tensor?\n",
    "#10/255 = 0.0392156862745098"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:24.060835Z",
     "start_time": "2019-08-22T17:58:24.040315Z"
    }
   },
   "outputs": [],
   "source": [
    "def _color_augmentation(x):\n",
    "    \"Randomize all channels of the input image\"\n",
    "    channel_count = x.shape[0] - 1\n",
    "    \n",
    "    # by transforming every color channels Ic ← ac · Ic + bc, \n",
    "    # where ac and bc are drawn from uniform distributions \n",
    "    # ac ∼ U [0.9, 1.1] and \n",
    "    # bc ∼ U [−10, +10].\n",
    "    \n",
    "    # x [0,1]\n",
    "    \n",
    "    for c in range(channel_count):\n",
    "        #pdb.set_trace()\n",
    "        #print(x.min(), x.max())\n",
    "        ac = np.random.uniform(0.9, 1.1) #np.random.uniform(0.9, 1.1)\n",
    "        bc = np.random.uniform(-0.1,0.1) #np.random.uniform(-10, 10)\n",
    "        x[c] = x[c] * ac + bc\n",
    "        \n",
    "        # clipping to min 0 and max 1\n",
    "        x[c] = torch.clamp(x[c], 0., 1.)\n",
    "    \n",
    "    return x\n",
    "\n",
    "color_augmentation = TfmPixel(_color_augmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforms setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:24.776292Z",
     "start_time": "2019-08-22T17:58:24.758892Z"
    }
   },
   "outputs": [],
   "source": [
    "## AdaCos-SE-XResNet50c --> FP32 !!!\n",
    "# TRAINING\n",
    "#sz, bs = 128, 8*20 # 7576MiB /  7952MiB INCREASE?\n",
    "#sz, bs = 256, 8*5 # 7341MiB /  7952MiB\n",
    "#sz, bs = 512, 8 #\n",
    "# PREDICTION\n",
    "#sz, bs = 256, 8*25 # 5391MiB /  7952MiB\n",
    "#sz, bs = 256, 8*40 # 7741MiB /  7952MiB\n",
    "#sz, bs = 512, 8*5 # 6051MiB /  7952MiB\n",
    "# DATA AUGM W/O AdaCos\n",
    "#sz, bs = 128, 8*42 # 7937MiB /  7952MiB\n",
    "#sz, bs = 256, 8*13 # \n",
    "#sz, bs = 512, 8*3 # \n",
    "\n",
    "\n",
    "## EfficientNet-B3\n",
    "#sz, bs = 300, 8 # 4167MiB /  7952MiB\n",
    "sz, bs = 300, 8*2 # 78??MiB /  7952MiB // FP16: 4397MiB /  7952MiB\n",
    "#sz, bs = 300, 8*4 # FP16: 7805MiB /  7952MiB\n",
    "\n",
    "# EfficientNet-B4\n",
    "#sz, bs = 380, 8  # 7796MiB /  7952MiB\n",
    "#sz, bs = 380, 8*2 # FP16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:25.091829Z",
     "start_time": "2019-08-22T17:58:25.049369Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 16)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sz, bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:25.334926Z",
     "start_time": "2019-08-22T17:58:25.319377Z"
    }
   },
   "outputs": [],
   "source": [
    "# cutout params\n",
    "#int(sz*0.1), int(sz*0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:25.590808Z",
     "start_time": "2019-08-22T17:58:25.575832Z"
    }
   },
   "outputs": [],
   "source": [
    "# normal tfms\n",
    "#tfms = get_transforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:26.022035Z",
     "start_time": "2019-08-22T17:58:26.008977Z"
    }
   },
   "outputs": [],
   "source": [
    "# extended tfms\n",
    "tfms = get_transforms(do_flip=True, flip_vert=True, \n",
    "                      max_rotate=90.0, max_zoom=1.1, \n",
    "                      max_lighting=0.2, max_warp=0.2, \n",
    "                      p_affine=0.75, p_lighting=0.75, \n",
    "                      xtra_tfms=[color_augmentation()])\n",
    "\n",
    "# crop_pad: https://forums.fast.ai/t/misc-issues/35386/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:26.245287Z",
     "start_time": "2019-08-22T17:58:26.229960Z"
    }
   },
   "outputs": [],
   "source": [
    "# extended tfms\n",
    "#tfms = get_transforms(do_flip=True, flip_vert=True, \n",
    "#                      max_rotate=90.0, max_zoom=1.1, \n",
    "#                      max_lighting=0.2, max_warp=0.2, \n",
    "#                      p_affine=0.75, p_lighting=0.75, \n",
    "#                      xtra_tfms=[color_augmentation(), \n",
    "#                                 cutout(n_holes=(1,4), length=(int(sz*0.1), int(sz*0.5)), p=.5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:26.469857Z",
     "start_time": "2019-08-22T17:58:26.429301Z"
    }
   },
   "outputs": [],
   "source": [
    "#tfms = [[crop(size=sz, row_pct=(0,1), col_pct=(0,1))], []]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:27.054189Z",
     "start_time": "2019-08-22T17:58:27.038450Z"
    }
   },
   "outputs": [],
   "source": [
    "#tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:28.012999Z",
     "start_time": "2019-08-22T17:58:27.999786Z"
    }
   },
   "outputs": [],
   "source": [
    "# change \"crop_pad\" from get_transforms to \"crop\"\n",
    "# CENTER for FIXED cropping\n",
    "tfms[0][0] = crop(size=sz, row_pct=[0.5,0.5], col_pct=[0.5,0.5])\n",
    "tfms[1][0] = crop(size=sz, row_pct=[0.5,0.5], col_pct=[0.5,0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:28.290064Z",
     "start_time": "2019-08-22T17:58:28.272704Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.5, 0.5], [0.5, 0.5])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train crop\n",
    "tfms[0][0].kwargs['row_pct'], tfms[0][0].kwargs['col_pct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:28.533355Z",
     "start_time": "2019-08-22T17:58:28.490178Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.5, 0.5], [0.5, 0.5])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# valid crop\n",
    "tfms[1][0].kwargs['row_pct'], tfms[1][0].kwargs['col_pct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:28.702124Z",
     "start_time": "2019-08-22T17:58:28.686330Z"
    }
   },
   "outputs": [],
   "source": [
    "#tfms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:31.784083Z",
     "start_time": "2019-08-22T17:58:31.166606Z"
    }
   },
   "outputs": [],
   "source": [
    "# VALID SPLIT (incl. tfms)\n",
    "data = (ImageList6Dct.from_df(df_train, path='train')\n",
    "        .split_from_df(col=-1) # split_by_rand_pct()\n",
    "        .label_from_df(cols=-3)\n",
    "        .add_test(ImageList6Dct.from_df(df_test, path='test'))\n",
    "        .transform(tfms, size=sz) # remove size so we get the crop size!\n",
    "        .databunch(bs=bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T05:01:55.360572Z",
     "start_time": "2019-08-19T05:01:55.169235Z"
    }
   },
   "outputs": [],
   "source": [
    "# FULL DATASET (incl. tfms)\n",
    "data = (ImageList6D.from_df(df_train, path='train')\n",
    "        .split_none() # !!!\n",
    "        .label_from_df(cols=-3)\n",
    "        .add_test(ImageList6D.from_df(df_test, path='test'))\n",
    "        .transform(tfms, size=sz)\n",
    "        .databunch(bs=bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T18:39:14.121475Z",
     "start_time": "2019-08-02T18:39:08.866676Z"
    }
   },
   "outputs": [],
   "source": [
    "# VALID SPLIT PREDICTION (NO tfms)\n",
    "data = (ImageList6D.from_df(df_train, path='train')\n",
    "        .split_from_df(col=-1) \n",
    "        .label_from_df(cols=-3) # label_delim=' ' for MultiCategoryList !\n",
    "        .add_test(ImageList6D.from_df(df_test, path='test'))\n",
    "        .transform(size=sz) # !!!\n",
    "        .databunch(bs=bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FULL DATASET PREDICTION (NO tfms)\n",
    "data = (ImageList6D.from_df(df_train, path='train')\n",
    "        .split_none() # !!!\n",
    "        .label_from_df(cols=-3)\n",
    "        .add_test(ImageList6D.from_df(df_test, path='test'))\n",
    "        .transform(size=sz)\n",
    "        .databunch(bs=bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T17:22:59.225424Z",
     "start_time": "2019-08-15T17:22:58.864686Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageDataBunch;\n",
       "\n",
       "Train: LabelList (57554 items)\n",
       "x: ImageList6Dct\n",
       "Image6Dct (6, 380, 380),Image6Dct (6, 380, 380),Image6Dct (6, 380, 380),Image6Dct (6, 380, 380),Image6Dct (6, 380, 380)\n",
       "y: CategoryList\n",
       "513,840,1020,254,144\n",
       "Path: train;\n",
       "\n",
       "Valid: LabelList (15476 items)\n",
       "x: ImageList6Dct\n",
       "Image6Dct (6, 380, 380),Image6Dct (6, 380, 380),Image6Dct (6, 380, 380),Image6Dct (6, 380, 380),Image6Dct (6, 380, 380)\n",
       "y: CategoryList\n",
       "352,361,503,505,70\n",
       "Path: train;\n",
       "\n",
       "Test: LabelList (39794 items)\n",
       "x: ImageList6Dct\n",
       "Image6Dct (6, 380, 380),Image6Dct (6, 380, 380),Image6Dct (6, 380, 380),Image6Dct (6, 380, 380),Image6Dct (6, 380, 380)\n",
       "y: EmptyLabelList\n",
       ",,,,\n",
       "Path: train"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CHANGED LINE 65 to:\n",
    "# nano ~/anaconda3/envs/fastai/lib/python3.6/site-packages/fastai/vision/data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T10:36:41.864055Z",
     "start_time": "2019-08-10T10:36:41.846780Z"
    }
   },
   "source": [
    "```\n",
    "~/anaconda3/envs/fastai/lib/python3.6/site-packages/fastai/vision/data.py in _normalize_batch(b, mean, std, do_x, do_y)\n",
    "     64     \"`b` = `x`,`y` - normalize `x` array of imgs and `do_y` optionally `y`.\"\n",
    "     65     x,y = b\n",
    "---> 66     mean,std = mean.to(x.device),std.to(x.device)\n",
    "     67     if do_x: x = normalize(x,mean,std)\n",
    "     68     if do_y and len(y.shape) == 4: y = normalize(y,mean,std)\n",
    "\n",
    "AttributeError: 'list' object has no attribute 'device'\n",
    "```\n",
    "CHANGED TO:\n",
    "```\n",
    "def _normalize_batch(b:Tuple[Tensor,Tensor], mean:FloatTensor, std:FloatTensor, do_x:bool$\n",
    "    \"`b` = `x`,`y` - normalize `x` array of imgs and `do_y` optionally `y`.\"\n",
    "    (x,cint,pgint,expint),y = b\n",
    "    mean,std = mean.to(x.device),std.to(x.device)\n",
    "    if do_x: x = normalize(x,mean,std)\n",
    "    if do_y and len(y.shape) == 4: y = normalize(y,mean,std)\n",
    "    return (x,cint,pgint,expint),y\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T20:18:16.683744Z",
     "start_time": "2019-08-12T20:18:16.667903Z"
    }
   },
   "outputs": [],
   "source": [
    "#data.batch_stats() # DOES NOT WORK?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:35.227508Z",
     "start_time": "2019-08-22T17:58:35.215799Z"
    }
   },
   "outputs": [],
   "source": [
    "# From https://github.com/recursionpharma/rxrx1-utils/blob/master/rxrx/main.py\n",
    "# The mean and stds for each of the channels\n",
    "GLOBAL_PIXEL_STATS = (np.array([6.74696984, 14.74640167, 10.51260864,\n",
    "                                10.45369445,  5.49959796, 9.81545561]),\n",
    "                       np.array([7.95876312, 12.17305868, 5.86172946,\n",
    "                                 7.83451711, 4.701167, 5.43130431]))\n",
    "\n",
    "stats_mean = torch.tensor(GLOBAL_PIXEL_STATS[0]/255).float()\n",
    "stats_var = torch.tensor(GLOBAL_PIXEL_STATS[1]/255).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:35.544336Z",
     "start_time": "2019-08-22T17:58:35.528775Z"
    }
   },
   "outputs": [],
   "source": [
    "#stats_mean, stats_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:36.123292Z",
     "start_time": "2019-08-22T17:58:35.732074Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageDataBunch;\n",
       "\n",
       "Train: LabelList (57554 items)\n",
       "x: ImageList6Dct\n",
       "Image6Dct (6, 300, 300),Image6Dct (6, 300, 300),Image6Dct (6, 300, 300),Image6Dct (6, 300, 300),Image6Dct (6, 300, 300)\n",
       "y: CategoryList\n",
       "513,840,1020,254,144\n",
       "Path: train;\n",
       "\n",
       "Valid: LabelList (15476 items)\n",
       "x: ImageList6Dct\n",
       "Image6Dct (6, 300, 300),Image6Dct (6, 300, 300),Image6Dct (6, 300, 300),Image6Dct (6, 300, 300),Image6Dct (6, 300, 300)\n",
       "y: CategoryList\n",
       "352,361,503,505,70\n",
       "Path: train;\n",
       "\n",
       "Test: LabelList (39794 items)\n",
       "x: ImageList6Dct\n",
       "Image6Dct (6, 300, 300),Image6Dct (6, 300, 300),Image6Dct (6, 300, 300),Image6Dct (6, 300, 300),Image6Dct (6, 300, 300)\n",
       "y: EmptyLabelList\n",
       ",,,,\n",
       "Path: train"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.normalize([stats_mean, stats_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:36.134626Z",
     "start_time": "2019-08-22T17:58:36.125009Z"
    }
   },
   "outputs": [],
   "source": [
    "#data.batch_stats() # DOES NOT WORK?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:04:39.628122Z",
     "start_time": "2019-08-22T17:04:39.617357Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T04:59:08.314604Z",
     "start_time": "2019-08-19T04:59:08.298539Z"
    }
   },
   "outputs": [],
   "source": [
    "#data.stats # results is copied below\n",
    "#[tensor([0.0456, 0.0702, 0.0447, 0.0468, 0.0407, 0.0399]),\n",
    "# tensor([0.0644, 0.0733, 0.0536, 0.0633, 0.0555, 0.0392])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T04:59:08.562970Z",
     "start_time": "2019-08-19T04:59:08.520396Z"
    }
   },
   "outputs": [],
   "source": [
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T04:59:08.841060Z",
     "start_time": "2019-08-19T04:59:08.823589Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1108, 1108, [1103, 1104, 1105, 1106, 1107])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.c, len(data.classes), data.classes[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T04:59:09.218631Z",
     "start_time": "2019-08-19T04:59:09.175251Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Image6Dct (6, 380, 380), Category 513)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T04:59:09.542834Z",
     "start_time": "2019-08-19T04:59:09.521365Z"
    }
   },
   "outputs": [],
   "source": [
    "#data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T04:59:10.035754Z",
     "start_time": "2019-08-19T04:59:09.958876Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category 513, 513)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train_ds[0][1], data.train_ds[0][1].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T04:59:10.516555Z",
     "start_time": "2019-08-19T04:59:10.332893Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(0), tensor(0))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train_ds[0][0].ctint, data.train_ds[0][0].pgint, data.train_ds[0][0].expint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T04:59:10.876680Z",
     "start_time": "2019-08-19T04:59:10.804856Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.train_ds[0][0].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T04:59:12.003619Z",
     "start_time": "2019-08-19T04:59:11.902497Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6, 380, 380]), torch.Size([]), torch.Size([]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train_ds[0][0].data[0].shape, data.train_ds[0][0].data[1].shape, data.train_ds[0][0].data[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T04:59:33.985444Z",
     "start_time": "2019-08-19T04:59:33.969873Z"
    }
   },
   "outputs": [],
   "source": [
    "#data.train_ds[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T16:45:38.664069Z",
     "start_time": "2019-08-13T16:45:38.648381Z"
    }
   },
   "outputs": [],
   "source": [
    "#data.train_ds[0][0].apply_tfms(crop(size=300, row_pct=(0,1), col_pct=(0,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-02T18:40:04.377527Z",
     "start_time": "2019-08-02T18:40:04.015804Z"
    }
   },
   "outputs": [],
   "source": [
    "### ORIGINAL 512px NO TFMS\n",
    "data.train_ds[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Adversarial full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-18T18:48:30.937436Z",
     "start_time": "2019-07-18T18:48:22.421758Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_a = (ImageList6D.from_df(df_train, path='train') # SET CORRECT DF!!!\n",
    "        .split_from_df(col=-1) # split_by_rand_pct()\n",
    "        .label_from_df(cols=-2, label_delim=' ') # label_delim=' ' for MultiCategoryList !\n",
    "        .add_test(ImageList6D.from_df(df_train, path='train'))\n",
    "        .transform(tfms, size=sz) # .transform(size=sz)\n",
    "        .databunch(bs=bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-13T08:16:52.668548Z",
     "start_time": "2019-07-13T08:16:52.441661Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-13T08:16:52.681315Z",
     "start_time": "2019-07-13T08:16:52.670670Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_a.c, len(data_a.classes), data_a.classes[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-13T08:16:52.692431Z",
     "start_time": "2019-07-13T08:16:52.682289Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_a.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-13T08:16:52.728302Z",
     "start_time": "2019-07-13T08:16:52.693336Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_a.train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-13T08:16:52.738982Z",
     "start_time": "2019-07-13T08:16:52.729257Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#data_a.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-13T08:16:52.799807Z",
     "start_time": "2019-07-13T08:16:52.739866Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_a.train_ds[0][1], data_a.train_ds[0][1].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-13T08:16:52.836313Z",
     "start_time": "2019-07-13T08:16:52.801091Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_a.train_ds[0][1].data.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-13T08:16:52.873199Z",
     "start_time": "2019-07-13T08:16:52.837338Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.where(data_a.train_ds[0][1].data > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-13T08:16:52.910261Z",
     "start_time": "2019-07-13T08:16:52.874115Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "[data_a.classes[j] for j in np.where(data_a.train_ds[0][1].data > 0.5)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-13T08:16:52.962924Z",
     "start_time": "2019-07-13T08:16:52.911167Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_a.train_ds[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-13T08:16:52.973658Z",
     "start_time": "2019-07-13T08:16:52.963880Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# DOES NOT WORK?\n",
    "#data_a.train_ds[0][0].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3d to 6d from old/rcic_multicat_v9_resnet50-pretrained_colaug.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:40.440914Z",
     "start_time": "2019-08-22T17:58:40.424234Z"
    }
   },
   "outputs": [],
   "source": [
    "from efficientnet_pytorch.utils import get_same_padding_conv2d, round_filters, round_repeats, relu_fn\n",
    "from efficientnet_pytorch.model import MBConvBlock, load_pretrained_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:40.830460Z",
     "start_time": "2019-08-22T17:58:40.747706Z"
    }
   },
   "outputs": [],
   "source": [
    "# put feature extractor into forward method\n",
    "class EfficientNet(nn.Module):\n",
    "    \"\"\"\n",
    "    An EfficientNet model. Most easily loaded with the .from_name or .from_pretrained methods\n",
    "    Args:\n",
    "        blocks_args (list): A list of BlockArgs to construct blocks\n",
    "        global_params (namedtuple): A set of GlobalParams shared between blocks\n",
    "    Example:\n",
    "        model = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, blocks_args=None, global_params=None):\n",
    "        super().__init__()\n",
    "        assert isinstance(blocks_args, list), 'blocks_args should be a list'\n",
    "        assert len(blocks_args) > 0, 'block args must be greater than 0'\n",
    "        self._global_params = global_params\n",
    "        self._blocks_args = blocks_args\n",
    "\n",
    "        # Get static or dynamic convolution depending on image size\n",
    "        Conv2d = get_same_padding_conv2d(image_size=global_params.image_size)\n",
    "\n",
    "        # Batch norm parameters\n",
    "        bn_mom = 1 - self._global_params.batch_norm_momentum\n",
    "        bn_eps = self._global_params.batch_norm_epsilon\n",
    "\n",
    "        # Stem\n",
    "        in_channels = 3  # rgb\n",
    "        out_channels = round_filters(32, self._global_params)  # number of output channels\n",
    "        self._conv_stem = Conv2d(in_channels, out_channels, kernel_size=3, stride=2, bias=False)\n",
    "        self._bn0 = nn.BatchNorm2d(num_features=out_channels, momentum=bn_mom, eps=bn_eps)\n",
    "\n",
    "        # Build blocks\n",
    "        self._blocks = nn.ModuleList([])\n",
    "        for block_args in self._blocks_args:\n",
    "\n",
    "            # Update block input and output filters based on depth multiplier.\n",
    "            block_args = block_args._replace(\n",
    "                input_filters=round_filters(block_args.input_filters, self._global_params),\n",
    "                output_filters=round_filters(block_args.output_filters, self._global_params),\n",
    "                num_repeat=round_repeats(block_args.num_repeat, self._global_params)\n",
    "            )\n",
    "\n",
    "            # The first block needs to take care of stride and filter size increase.\n",
    "            self._blocks.append(MBConvBlock(block_args, self._global_params))\n",
    "            if block_args.num_repeat > 1:\n",
    "                block_args = block_args._replace(input_filters=block_args.output_filters, stride=1)\n",
    "            for _ in range(block_args.num_repeat - 1):\n",
    "                self._blocks.append(MBConvBlock(block_args, self._global_params))\n",
    "\n",
    "        # Head\n",
    "        in_channels = block_args.output_filters  # output of final block\n",
    "        out_channels = round_filters(1280, self._global_params)\n",
    "        self._conv_head = Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self._bn1 = nn.BatchNorm2d(num_features=out_channels, momentum=bn_mom, eps=bn_eps)\n",
    "\n",
    "        # Final linear layer\n",
    "        #self._dropout = self._global_params.dropout_rate\n",
    "        #self._fc = nn.Linear(out_channels, self._global_params.num_classes)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\" Returns output of the final convolution layer \"\"\"\n",
    "\n",
    "        # Stem\n",
    "        x = relu_fn(self._bn0(self._conv_stem(inputs)))\n",
    "\n",
    "        # Blocks\n",
    "        for idx, block in enumerate(self._blocks):\n",
    "            drop_connect_rate = self._global_params.drop_connect_rate\n",
    "            if drop_connect_rate:\n",
    "                drop_connect_rate *= float(idx) / len(self._blocks)\n",
    "            x = block(x, drop_connect_rate=drop_connect_rate)\n",
    "\n",
    "        # Head\n",
    "        x = relu_fn(self._bn1(self._conv_head(x)))\n",
    "\n",
    "        return x\n",
    "\n",
    "    #def forward(self, inputs):\n",
    "    #    \"\"\" Calls extract_features to extract features, applies final linear layer, and returns logits. \"\"\"\n",
    "    #\n",
    "    #    # Convolution layers\n",
    "    #    x = self.extract_features(inputs)\n",
    "    #\n",
    "    #    # Pooling and final linear layer\n",
    "    #    x = F.adaptive_avg_pool2d(x, 1).squeeze(-1).squeeze(-1)\n",
    "    #    if self._dropout:\n",
    "    #        x = F.dropout(x, p=self._dropout, training=self.training)\n",
    "    #    x = self._fc(x)\n",
    "    #    return x\n",
    "\n",
    "    @classmethod\n",
    "    def from_name(cls, model_name, override_params=None):\n",
    "        cls._check_model_name_is_valid(model_name)\n",
    "        blocks_args, global_params = get_model_params(model_name, override_params)\n",
    "        return EfficientNet(blocks_args, global_params)\n",
    "\n",
    "    @classmethod\n",
    "    def from_pretrained(cls, model_name, num_classes=1000):\n",
    "        model = EfficientNet.from_name(model_name, override_params={'num_classes': num_classes})\n",
    "        load_pretrained_weights(model, model_name, load_fc=(num_classes == 1000))\n",
    "        return model\n",
    "\n",
    "    @classmethod\n",
    "    def get_image_size(cls, model_name):\n",
    "        cls._check_model_name_is_valid(model_name)\n",
    "        _, _, res, _ = efficientnet_params(model_name)\n",
    "        return res\n",
    "\n",
    "    @classmethod\n",
    "    def _check_model_name_is_valid(cls, model_name, also_need_pretrained_weights=False):\n",
    "        \"\"\" Validates model name. None that pretrained weights are only available for\n",
    "        the first four models (efficientnet-b{i} for i in 0,1,2,3) at the moment. \"\"\"\n",
    "        num_models = 4 if also_need_pretrained_weights else 8\n",
    "        valid_models = ['efficientnet_b'+str(i) for i in range(num_models)]\n",
    "        if model_name.replace('-','_') not in valid_models:\n",
    "            raise ValueError('model_name should be one of: ' + ', '.join(valid_models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:40.943616Z",
     "start_time": "2019-08-22T17:58:40.927712Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils import model_zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:41.133504Z",
     "start_time": "2019-08-22T17:58:41.120632Z"
    }
   },
   "outputs": [],
   "source": [
    "url_map = {\n",
    "    'efficientnet-b0': 'http://storage.googleapis.com/public-models/efficientnet/efficientnet-b0-355c32eb.pth',\n",
    "    'efficientnet-b1': 'http://storage.googleapis.com/public-models/efficientnet/efficientnet-b1-f1951068.pth',\n",
    "    'efficientnet-b2': 'http://storage.googleapis.com/public-models/efficientnet/efficientnet-b2-8bb594d6.pth',\n",
    "    'efficientnet-b3': 'http://storage.googleapis.com/public-models/efficientnet/efficientnet-b3-5fb5a3c3.pth',\n",
    "    'efficientnet-b4': 'http://storage.googleapis.com/public-models/efficientnet/efficientnet-b4-6ed6700e.pth',\n",
    "    'efficientnet-b5': 'http://storage.googleapis.com/public-models/efficientnet/efficientnet-b5-b6417697.pth',\n",
    "    'efficientnet-b6': 'http://storage.googleapis.com/public-models/efficientnet/efficientnet-b6-c76e70fd.pth',\n",
    "    'efficientnet-b7': 'http://storage.googleapis.com/public-models/efficientnet/efficientnet-b7-dcc49843.pth',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:41.478949Z",
     "start_time": "2019-08-22T17:58:41.460924Z"
    }
   },
   "outputs": [],
   "source": [
    "# adapt load function to only load weights for feature extractor stage\n",
    "def load_pretrained_weights(model, model_name, load_fc=True):\n",
    "    \"\"\" Loads pretrained weights, and downloads if loading for the first time. \"\"\"\n",
    "    state_dict = model_zoo.load_url(url_map[model_name])\n",
    "    #if load_fc:\n",
    "    #    model.load_state_dict(state_dict)\n",
    "    #else:\n",
    "    state_dict.pop('_fc.weight')\n",
    "    state_dict.pop('_fc.bias')\n",
    "    res = model.load_state_dict(state_dict, strict=False)\n",
    "        #assert str(res.missing_keys) == str(['_fc.weight', '_fc.bias']), 'issue loading pretrained weights'\n",
    "    print('Loaded pretrained weights for {}'.format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:41.853178Z",
     "start_time": "2019-08-22T17:58:41.687875Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b3\n"
     ]
    }
   ],
   "source": [
    "# b3: input size = 300\n",
    "#efficientnet_b3 = EfficientNet.from_name('efficientnet-b3')\n",
    "efficientnet_f = EfficientNet.from_pretrained('efficientnet-b3')\n",
    "#efficientnet_b4f = EfficientNet.from_pretrained('efficientnet-b4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:41.882343Z",
     "start_time": "2019-08-22T17:58:41.871165Z"
    }
   },
   "outputs": [],
   "source": [
    "#efficientnet_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:42.321196Z",
     "start_time": "2019-08-22T17:58:42.303579Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Conv2dStaticSamePadding(\n",
       "   3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "   (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       " ), efficientnet_pytorch.utils.Conv2dStaticSamePadding)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficientnet_f._conv_stem, type(efficientnet_f._conv_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:42.539540Z",
     "start_time": "2019-08-22T17:58:42.521362Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2dStaticSamePadding(\n",
       "  6, 40, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "  (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.Conv2dStaticSamePadding(6, 40, kernel_size=(3, 3), stride=(2, 2), bias=False, image_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:42.726127Z",
     "start_time": "2019-08-22T17:58:42.708988Z"
    }
   },
   "outputs": [],
   "source": [
    "p_dict = {pn: p for pn, p in efficientnet_f._conv_stem.named_parameters()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:42.991097Z",
     "start_time": "2019-08-22T17:58:42.974867Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['weight'])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:43.321413Z",
     "start_time": "2019-08-22T17:58:43.304277Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([40, 3, 3, 3]), True)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_dict['weight'].shape, p_dict['weight'].requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:43.871411Z",
     "start_time": "2019-08-22T17:58:43.854597Z"
    }
   },
   "outputs": [],
   "source": [
    "old_weight = p_dict['weight'].detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:44.103344Z",
     "start_time": "2019-08-22T17:58:44.060102Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([40, 3, 3, 3]), False)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_weight.shape, old_weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:44.283402Z",
     "start_time": "2019-08-22T17:58:44.242286Z"
    }
   },
   "outputs": [],
   "source": [
    "new_weight = torch.cat((old_weight, old_weight), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:44.813028Z",
     "start_time": "2019-08-22T17:58:44.796198Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([40, 6, 3, 3]), False)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_weight.shape, new_weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:45.190748Z",
     "start_time": "2019-08-22T17:58:45.174349Z"
    }
   },
   "outputs": [],
   "source": [
    "def show_input_stage_weights(weight=None, nrows=2, ncols=3):\n",
    "    fig, ax = plt.subplots(nrows=nrows, ncols=ncols)\n",
    "    k = 0\n",
    "    for i in range(nrows):\n",
    "        for j in range(ncols):\n",
    "            if nrows > 1:\n",
    "                ax[i,j].set_title(k)\n",
    "                ax[i,j].imshow(weight[0][k])\n",
    "                ax[i,j].axis(\"off\")\n",
    "            else:\n",
    "                ax[j].set_title(k)\n",
    "                ax[j].imshow(weight[0][k])\n",
    "                ax[j].axis(\"off\")\n",
    "            k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:45.699489Z",
     "start_time": "2019-08-22T17:58:45.685034Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot old_weight\n",
    "#show_input_stage_weights(old_weight, nrows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:45.936039Z",
     "start_time": "2019-08-22T17:58:45.895911Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot new_weight\n",
    "#show_input_stage_weights(new_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:46.208667Z",
     "start_time": "2019-08-22T17:58:46.191221Z"
    }
   },
   "outputs": [],
   "source": [
    "# replace first conv layer with a 6-channel version\n",
    "efficientnet_f._conv_stem = utils.Conv2dStaticSamePadding(6, 40, kernel_size=(3, 3),\n",
    "                                                          stride=(2, 2), bias=False, image_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:46.464864Z",
     "start_time": "2019-08-22T17:58:46.448102Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2dStaticSamePadding(\n",
       "  6, 40, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "  (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficientnet_f._conv_stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:46.683225Z",
     "start_time": "2019-08-22T17:58:46.667940Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 6, 3, 3])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficientnet_f._conv_stem.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:46.917215Z",
     "start_time": "2019-08-22T17:58:46.876803Z"
    }
   },
   "outputs": [],
   "source": [
    "# set new_weights to nn.Parameter and overwrite it in the conv layer\n",
    "efficientnet_f._conv_stem.weight = nn.Parameter(new_weight) # hand over requires_grad False?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:47.179749Z",
     "start_time": "2019-08-22T17:58:47.163586Z"
    }
   },
   "outputs": [],
   "source": [
    "# check if weight was loaded properly\n",
    "assert torch.allclose(new_weight, efficientnet_f._conv_stem.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:47.656126Z",
     "start_time": "2019-08-22T17:58:47.639136Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([40, 6, 3, 3]), True)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficientnet_f._conv_stem.weight.shape, efficientnet_f._conv_stem.weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:48.128165Z",
     "start_time": "2019-08-22T17:58:48.112684Z"
    }
   },
   "outputs": [],
   "source": [
    "# network is in full train mode!\n",
    "#[p.requires_grad for p in efficientnet_b3f.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:48.418365Z",
     "start_time": "2019-08-22T17:58:48.377875Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_rg(model=efficientnet_f, option=False):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:48.706334Z",
     "start_time": "2019-08-22T17:58:48.689894Z"
    }
   },
   "outputs": [],
   "source": [
    "# set requires grad for the efficientnet to false (to later only set it true for the input)\n",
    "# WE WILL NOT DO THIS, because it should be not necessary!\n",
    "set_rg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:49.262934Z",
     "start_time": "2019-08-22T17:58:49.247703Z"
    }
   },
   "outputs": [],
   "source": [
    "# network is frozen\n",
    "#[p.requires_grad for p in efficientnet_b4f.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:49.670384Z",
     "start_time": "2019-08-22T17:58:49.655488Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficientnet_f._conv_stem.weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:50.153143Z",
     "start_time": "2019-08-22T17:58:50.138321Z"
    }
   },
   "outputs": [],
   "source": [
    "# set input stage to trainable\n",
    "#efficientnet_f._conv_stem.weight.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:50.750155Z",
     "start_time": "2019-08-22T17:58:50.734651Z"
    }
   },
   "outputs": [],
   "source": [
    "#efficientnet_f._conv_stem.weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:51.096880Z",
     "start_time": "2019-08-22T17:58:50.930293Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1536, 9, 9])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficientnet_f(torch.randn(1,6,sz,sz)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EfficientNet Pre-Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:52.978105Z",
     "start_time": "2019-08-22T17:58:52.965115Z"
    }
   },
   "outputs": [],
   "source": [
    "def resnet_pre_head(concat_pool:bool=True):\n",
    "    pool = AdaptiveConcatPool2d() if concat_pool else nn.AdaptiveAvgPool2d(1)\n",
    "    layers = [pool, Flatten()]\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:53.260385Z",
     "start_time": "2019-08-22T17:58:53.244314Z"
    }
   },
   "outputs": [],
   "source": [
    "efficientnet_f_prehead = resnet_pre_head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:53.484936Z",
     "start_time": "2019-08-22T17:58:53.436911Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): AdaptiveConcatPool2d(\n",
       "    (ap): AdaptiveAvgPool2d(output_size=1)\n",
       "    (mp): AdaptiveMaxPool2d(output_size=1)\n",
       "  )\n",
       "  (1): Flatten()\n",
       ")"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficientnet_f_prehead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:53.638294Z",
     "start_time": "2019-08-22T17:58:53.619441Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3072])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficientnet_f_prehead(torch.randn(2, 1536, 9, 9)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:53.841196Z",
     "start_time": "2019-08-22T17:58:53.830656Z"
    }
   },
   "outputs": [],
   "source": [
    "efficientnet_fph = nn.Sequential(efficientnet_f, efficientnet_f_prehead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:54.394375Z",
     "start_time": "2019-08-22T17:58:54.266269Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3072])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficientnet_fph(torch.randn(1,6,sz,sz)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CellType & Plate Group Feature Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:54.597320Z",
     "start_time": "2019-08-22T17:58:54.586120Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exps = len(set([exp2int[i] for i in exp2int])); exps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:54.946625Z",
     "start_time": "2019-08-22T17:58:54.878676Z"
    }
   },
   "outputs": [],
   "source": [
    "class CellTypePlateGroupFeatures(nn.Module):\n",
    "    '''CellType Feature Extractor.'''\n",
    "    def __init__(self, cell_types=4, plate_groups=4, exps=exps, emb_sz=128):\n",
    "        super(CellTypePlateGroupFeatures, self).__init__()\n",
    "        self.emb_ctint = nn.Embedding(cell_types, emb_sz)\n",
    "        self.emb_pgint = nn.Embedding(plate_groups, emb_sz)\n",
    "        self.emb_expint = nn.Embedding(exps, emb_sz)\n",
    "        \n",
    "    def forward(self, xb_ctint, xb_pgint, xb_expint, yb=None): # yb=None for training in non-AdaCos mode!\n",
    "        \n",
    "        ### CTINT\n",
    "        # check if we are in CutMix mode:\n",
    "        if isinstance(xb_ctint, tuple):\n",
    "            x1, x2, λ = xb_ctint\n",
    "            out1 = self.emb_ctint(x1)\n",
    "            out2 = self.emb_ctint(x2)\n",
    "            out_ctint = out1 * λ + out2 * (1-λ)\n",
    "        else: # if not CutMix, then normal mode\n",
    "            out_ctint = self.emb_ctint(xb_ctint)\n",
    "        \n",
    "        ## PGINT\n",
    "        # check if we are in CutMix mode:\n",
    "        if isinstance(xb_pgint, tuple):\n",
    "            x1, x2, λ = xb_pgint\n",
    "            out1 = self.emb_pgint(x1)\n",
    "            out2 = self.emb_pgint(x2)\n",
    "            out_pgint = out1 * λ + out2 * (1-λ)\n",
    "        else: # if not CutMix, then normal mode\n",
    "            out_pgint = self.emb_pgint(xb_pgint)\n",
    "            \n",
    "        ## EXPINT\n",
    "        # check if we are in CutMix mode:\n",
    "        if isinstance(xb_expint, tuple):\n",
    "            x1, x2, λ = xb_expint\n",
    "            out1 = self.emb_pgint(x1)\n",
    "            out2 = self.emb_pgint(x2)\n",
    "            out_expint = out1 * λ + out2 * (1-λ)\n",
    "        else: # if not CutMix, then normal mode\n",
    "            out_expint = self.emb_expint(xb_expint)\n",
    "        \n",
    "        out = torch.cat((out_ctint, out_pgint,  out_expint), dim=-1)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:55.303603Z",
     "start_time": "2019-08-22T17:58:55.287142Z"
    }
   },
   "outputs": [],
   "source": [
    "ctf = CellTypePlateGroupFeatures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:55.688633Z",
     "start_time": "2019-08-22T17:58:55.672331Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CellTypePlateGroupFeatures(\n",
       "  (emb_ctint): Embedding(4, 128)\n",
       "  (emb_pgint): Embedding(4, 128)\n",
       "  (emb_expint): Embedding(26, 128)\n",
       ")"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:56.112349Z",
     "start_time": "2019-08-22T17:58:56.100015Z"
    }
   },
   "outputs": [],
   "source": [
    "xb = (torch.tensor(ct2int['HEPG2']),\n",
    "      torch.tensor(fn2pgint['train/HEPG2-01/Plate1/B03_s1']),\n",
    "      torch.tensor(exp2int['train/HEPG2-01/Plate1/B03_s1'.split('/')[1]])\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:56.310761Z",
     "start_time": "2019-08-22T17:58:56.294686Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(0), tensor(0))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:56.749911Z",
     "start_time": "2019-08-22T17:58:56.732691Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([384])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctf(xb[0], xb[1], xb[2]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:57.909841Z",
     "start_time": "2019-08-22T17:58:57.892507Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [2]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(4, (2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:58:58.333173Z",
     "start_time": "2019-08-22T17:58:58.315774Z"
    }
   },
   "outputs": [],
   "source": [
    "xb = (torch.tensor((1,3)), torch.tensor((1,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T18:11:47.654654Z",
     "start_time": "2019-08-14T18:11:47.611253Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 3]), tensor([1, 3]))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T04:24:58.744059Z",
     "start_time": "2019-08-14T04:24:58.699579Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 256])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctf(xb[0], xb[1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T04:24:59.500580Z",
     "start_time": "2019-08-14T04:24:59.483272Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(fn2pgint['train/RPE-01/Plate1/B03_s1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T04:25:00.238601Z",
     "start_time": "2019-08-14T04:25:00.225479Z"
    }
   },
   "outputs": [],
   "source": [
    "xb = ((torch.tensor(ct2int['HEPG2']), torch.tensor(ct2int['RPE']), 0.9),\n",
    "      (torch.tensor(fn2pgint['train/HEPG2-01/Plate1/B03_s1']),\n",
    "       torch.tensor(fn2pgint['train/RPE-01/Plate1/B03_s1']), 0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T05:00:05.693678Z",
     "start_time": "2019-08-19T05:00:05.594542Z"
    }
   },
   "outputs": [],
   "source": [
    "ctf(xb[0], xb[1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T05:00:06.454832Z",
     "start_time": "2019-08-19T05:00:06.439038Z"
    }
   },
   "outputs": [],
   "source": [
    "#class CellTypeFeatures(nn.Module):\n",
    "#    '''CellType Feature Extractor.'''\n",
    "#    def __init__(self, cell_types=4, emb_sz=128, lin_ftrs:Optional[Collection[int]]=None, nc=128):\n",
    "#        super(AdaCosNet, self).__init__()\n",
    "#        self.emb = nn.Embedding(cell_types, emb_sz)\n",
    "#        \n",
    "#        self.lin_ftrs = [emb_sz, 512, 512] if lin_ftrs is None else [emb_sz] + lin_ftrs + [nc]\n",
    "#\n",
    "#        \n",
    "#    def forward(self, xb, yb=None): # yb=None for training in non-AdaCos mode!\n",
    "#\n",
    "#        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaCos-Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:59:01.818002Z",
     "start_time": "2019-08-22T17:59:01.802992Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_adacos_head(nf:int, lin_ftrs:Optional[Collection[int]]=None, ps:Floats=0.5,\n",
    "                bn_final:bool=False): # concat_pool:bool=True, \n",
    "    #nc:int, \n",
    "    \"Model head that takes `nf` features, runs through `lin_ftrs`, and about `nc` classes.\"\n",
    "    \n",
    "    # ADDED TWO MORE 512 LAYERS !!!\n",
    "    lin_ftrs = [nf, 512, 512, 512, 512] if lin_ftrs is None else [nf] + lin_ftrs + [nc]\n",
    "    # remove last 512 fc layer to reduce MODEL SIZE ??? ???\n",
    "    \n",
    "    ps = listify(ps)\n",
    "    if len(ps) == 1: ps = [ps[0]/2] * (len(lin_ftrs)-2) + ps\n",
    "    actns = [nn.ReLU(inplace=True)] * (len(lin_ftrs)-2) + [None]\n",
    "    #pool = AdaptiveConcatPool2d() if concat_pool else nn.AdaptiveAvgPool2d(1)\n",
    "    #layers = [pool, Flatten()]\n",
    "    layers = []\n",
    "    for ni,no,p,actn in zip(lin_ftrs[:-1], lin_ftrs[1:], ps, actns):\n",
    "        layers += bn_drop_lin(ni, no, True, p, actn)\n",
    "    if bn_final: layers.append(nn.BatchNorm1d(lin_ftrs[-1], momentum=0.01))\n",
    "    #layers.append(AdaCos(lin_ftrs[-1], nc))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:59:02.053977Z",
     "start_time": "2019-08-22T17:59:02.024011Z"
    }
   },
   "outputs": [],
   "source": [
    "#adacos_head = create_adacos_head(nf=2048+1) \n",
    "adacos_head = create_adacos_head(nf=1536*2+128*3)\n",
    "# se_xresnet50f: 2048*2=4096, ctf: 128*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:59:02.373805Z",
     "start_time": "2019-08-22T17:59:02.330359Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): BatchNorm1d(3456, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (1): Dropout(p=0.25)\n",
       "  (2): Linear(in_features=3456, out_features=512, bias=True)\n",
       "  (3): ReLU(inplace)\n",
       "  (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (5): Dropout(p=0.25)\n",
       "  (6): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (7): ReLU(inplace)\n",
       "  (8): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (9): Dropout(p=0.25)\n",
       "  (10): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (11): ReLU(inplace)\n",
       "  (12): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (13): Dropout(p=0.5)\n",
       "  (14): Linear(in_features=512, out_features=512, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adacos_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:59:02.786345Z",
     "start_time": "2019-08-22T17:59:02.770773Z"
    }
   },
   "outputs": [],
   "source": [
    "#adacos_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:59:03.020151Z",
     "start_time": "2019-08-22T17:59:02.973201Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 512])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adacos_head(torch.randn(2, 1536*2+128*3)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:59:03.263591Z",
     "start_time": "2019-08-22T17:59:03.246296Z"
    }
   },
   "outputs": [],
   "source": [
    "# from https://github.com/4uiiurz1/pytorch-adacos/blob/master/metrics.py\n",
    "class AdaCos(nn.Module):\n",
    "    def __init__(self, num_features, num_classes, m=0.50):\n",
    "        super(AdaCos, self).__init__()\n",
    "        self.num_features = num_features\n",
    "        self.n_classes = num_classes\n",
    "        self.s = math.sqrt(2) * math.log(num_classes - 1)\n",
    "        self.m = m\n",
    "        self.W = nn.Parameter(torch.FloatTensor(num_classes, num_features))\n",
    "        nn.init.xavier_uniform_(self.W)\n",
    "\n",
    "    def forward(self, xb, yb):\n",
    "        \n",
    "        #print(yb.shape)\n",
    "        #pdb.set_trace()\n",
    "        \n",
    "        # normalize features\n",
    "        x = F.normalize(xb)\n",
    "        # normalize weights\n",
    "        W = F.normalize(self.W)\n",
    "        # dot product\n",
    "        logits = F.linear(x, W)\n",
    "        \n",
    "        # for training in non-AdaCos mode (= no yb date in the forward pass):\n",
    "        if yb is None:\n",
    "            print('yb = None')\n",
    "            return logits\n",
    "        \n",
    "        # feature re-scale\n",
    "        theta = torch.acos(torch.clamp(logits, -1.0 + 1e-7, 1.0 - 1e-7))\n",
    "        one_hot = torch.zeros_like(logits)\n",
    "        \n",
    "        # ORIGINAL\n",
    "        #one_hot.scatter_(1, yb.view(-1, 1).long(), 1)\n",
    "        #with torch.no_grad():\n",
    "        #    B_avg = torch.where(one_hot < 1, torch.exp(self.s * logits), torch.zeros_like(logits))\n",
    "        #    B_avg = torch.sum(B_avg) / xb.size(0)\n",
    "        #    #print(B_avg)\n",
    "        #    theta_med = torch.median(theta[one_hot == 1])\n",
    "        #    self.s = torch.log(B_avg) / torch.cos(torch.min(math.pi/4 * torch.ones_like(theta_med), theta_med))\n",
    "        #    #print(self.s)\n",
    "            \n",
    "        # ADAPTED FOR CUTMIX TO GET MIXED SCALE PARAMETER\n",
    "        with torch.no_grad():\n",
    "            # FROM nb_new_data_augmentation_adacos2.py LINE 888\n",
    "            # AND https://github.com/fastai/fastai/blob/master/fastai/callbacks/mixup.py#L40\n",
    "            if yb.ndim == 2:# and target.shape[-1] >1:\n",
    "                n_mod_patches = (yb.shape[-1] - 1) // 2\n",
    "                #c_ = yb[:, 1:n_mod_patches + 1]\n",
    "                c_ = yb[:, 0:n_mod_patches + 1]\n",
    "                W_ = yb[:, n_mod_patches + 1:]\n",
    "                self.s_scaled = []\n",
    "                \n",
    "                # this loop is only realdy needed when we have different probabilities inside a batch\n",
    "                # which we do not have (right now)! So this could be cleaned up, but we leave until\n",
    "                # we know we will not need the case with different probabilities in a batch.\n",
    "                for k in range(n_mod_patches+1):\n",
    "                    yb_new = c_[:, k].long()\n",
    "                    #pdb.set_trace()\n",
    "                    \n",
    "                    one_hot.scatter_(1, yb_new.view(-1,1).long(), 1)\n",
    "                    \n",
    "                    B_avg = torch.where(one_hot < 1, torch.exp(self.s * logits), torch.zeros_like(logits))\n",
    "                    B_avg = torch.sum(B_avg) / xb.size(0)\n",
    "                    theta_med = torch.median(theta[one_hot == 1])\n",
    "                    self.s = torch.log(B_avg) / torch.cos(torch.min(math.pi/4 * torch.ones_like(theta_med), theta_med))\n",
    "                    \n",
    "                    if k+1 == len(range(n_mod_patches+1)):\n",
    "                        #self.s_scaled.append((1-W_[:, k-1]) * self.s)\n",
    "                        self.s_scaled.append((1-W_[0, k-1]) * self.s)\n",
    "                        # For more than two the sum of W_[:, :k] has to be used!!!\n",
    "                    else:\n",
    "                        #self.s_scaled.append(W_[:, k] * self.s)\n",
    "                        self.s_scaled.append(W_[0, k] * self.s)\n",
    "                    # Mixed B_avg & self.s and single are not really far off, but now we have it coded\n",
    "                    # se we keep it (until it breaks something later).\n",
    "                self.s = torch.add(*self.s_scaled)\n",
    "                # Clean up, self.s_scaled is just a vector with the same entry multiple times\n",
    "                # when it is not indexed above with W_[0,... !\n",
    "            else:\n",
    "                one_hot.scatter_(1, yb.view(-1,1).long(), 1)\n",
    "                B_avg = torch.where(one_hot < 1, torch.exp(self.s * logits), torch.zeros_like(logits))\n",
    "                B_avg = torch.sum(B_avg) / xb.size(0)\n",
    "                theta_med = torch.median(theta[one_hot == 1])\n",
    "                self.s = torch.log(B_avg) / torch.cos(torch.min(math.pi/4 * torch.ones_like(theta_med), theta_med))\n",
    "        \n",
    "        output = self.s * logits\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:59:03.847511Z",
     "start_time": "2019-08-22T17:59:03.833988Z"
    }
   },
   "outputs": [],
   "source": [
    "class AdaCosNet(nn.Module):\n",
    "    '''Simple AdaCosNet connecter to run xb through the feature extractor head\n",
    "    and then feed xb and yb into the AdaCos layer.'''\n",
    "    def __init__(self, body1, body2, head):\n",
    "        super(AdaCosNet, self).__init__()\n",
    "        self.body1 = body1\n",
    "        self.body2 = body2\n",
    "        self.head = head\n",
    "        self.adacos = AdaCos(512, 1108)\n",
    "        \n",
    "    def forward(self, xb, yb=None): # yb=None for training in non-AdaCos mode!\n",
    "        xb_img, xb_ctint, xb_pgint, xb_expint = xb\n",
    "        resnet_features = self.body1(xb_img)\n",
    "        int_features = self.body2(xb_ctint, xb_pgint, xb_expint)\n",
    "        features = torch.cat((resnet_features, int_features), dim=-1)\n",
    "        out = self.head(features)\n",
    "        #print('xb.shape: ', xb.shape,', yb.shape: ', yb.shape)\n",
    "        out = self.adacos(out, yb)\n",
    "        #print('out: ',out.shape)\n",
    "        #pdb.set_trace()\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:59:04.068312Z",
     "start_time": "2019-08-22T17:59:04.049186Z"
    }
   },
   "outputs": [],
   "source": [
    "adacos_efficientnet = AdaCosNet(efficientnet_fph, ctf, adacos_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:59:04.298481Z",
     "start_time": "2019-08-22T17:59:04.245480Z"
    }
   },
   "outputs": [],
   "source": [
    "xb = (torch.randn(2,6,sz,sz),\n",
    "      #(torch.randint(4, (2,1)),  torch.randint(4, (2,1)))\n",
    "      torch.tensor((1,3)), torch.tensor((1,3)), torch.tensor((1,3))\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:59:04.863551Z",
     "start_time": "2019-08-22T17:59:04.636442Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yb = None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1108])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adacos_efficientnet(xb).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:59:05.478757Z",
     "start_time": "2019-08-22T17:59:05.169208Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1108])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adacos_efficientnet(xb, torch.tensor([513, 1])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:59:05.490970Z",
     "start_time": "2019-08-22T17:59:05.480528Z"
    }
   },
   "outputs": [],
   "source": [
    "test_target = torch.tensor(\n",
    "    [[2.4700e+02, 3.3900e+02, 7.8362e-01],\n",
    "     [2.3300e+02, 7.7400e+02, 7.8362e-01],\n",
    "     [7.7400e+02, 1.3400e+02, 7.8362e-01],\n",
    "     [6.9800e+02, 8.4700e+02, 7.8362e-01]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:59:06.038916Z",
     "start_time": "2019-08-22T17:59:05.620304Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1108])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adacos_efficientnet((torch.randn(4,6,sz,sz), \n",
    "                     torch.tensor((1,3,0,2)), torch.tensor((1,3,0,2)), torch.tensor((1,3,0,2))),\n",
    "                    test_target).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:59:06.089160Z",
     "start_time": "2019-08-22T17:59:06.077760Z"
    }
   },
   "outputs": [],
   "source": [
    "# Based on https://forums.fast.ai/t/teacher-forcing/29415/4\n",
    "# https://forums.fast.ai/t/on-batch-begin-callback/35201/3\n",
    "@dataclass\n",
    "class AppendBatchTargs(Callback):\n",
    "    learn:Learner\n",
    "    def __init__(self, learn):\n",
    "        super().__init__()\n",
    "    def on_batch_begin(self, last_input, last_target, **kwargs):\n",
    "        return {'last_input':(last_input, last_target), 'last_target':last_target}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:59:06.649671Z",
     "start_time": "2019-08-22T17:59:06.633723Z"
    }
   },
   "outputs": [],
   "source": [
    "#batch = next(iter(data.train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T04:34:27.806044Z",
     "start_time": "2019-08-19T04:34:27.789991Z"
    }
   },
   "outputs": [],
   "source": [
    "#batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T20:35:24.577196Z",
     "start_time": "2019-08-12T20:35:24.561509Z"
    }
   },
   "outputs": [],
   "source": [
    "#batch[0][0].shape, batch[0][1].shape, batch[0][2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T20:35:25.000294Z",
     "start_time": "2019-08-12T20:35:24.985776Z"
    }
   },
   "outputs": [],
   "source": [
    "#batch[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T20:35:25.198099Z",
     "start_time": "2019-08-12T20:35:25.183200Z"
    }
   },
   "outputs": [],
   "source": [
    "#batch[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T20:35:25.645845Z",
     "start_time": "2019-08-12T20:35:25.629617Z"
    }
   },
   "outputs": [],
   "source": [
    "#adacos_se_xresnet50c.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-12T20:35:20.033217Z",
     "start_time": "2019-08-12T20:35:20.017655Z"
    }
   },
   "outputs": [],
   "source": [
    "#adacos_se_xresnet50c(batch[0]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:59:13.233051Z",
     "start_time": "2019-08-22T17:59:11.424951Z"
    }
   },
   "outputs": [],
   "source": [
    "learn = Learner(data, adacos_efficientnet, metrics=[accuracy],\n",
    "                callback_fns=[CSVLogger, AppendBatchTargs])#.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T04:51:14.888822Z",
     "start_time": "2019-08-15T04:51:14.877176Z"
    }
   },
   "outputs": [],
   "source": [
    "#adacos_efficientnet_b4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T04:51:16.981718Z",
     "start_time": "2019-08-15T04:51:16.970113Z"
    }
   },
   "outputs": [],
   "source": [
    "#adacos_efficientnet_b4.body1[0]._blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T04:51:19.441568Z",
     "start_time": "2019-08-15T04:51:19.430502Z"
    }
   },
   "outputs": [],
   "source": [
    "#[adacos_efficientnet_b4.body1[0]._blocks for i in range(31)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T04:51:21.689410Z",
     "start_time": "2019-08-15T04:51:21.677873Z"
    }
   },
   "outputs": [],
   "source": [
    "#adacos_efficientnet_b4.body1[0]._conv_stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T04:51:23.706104Z",
     "start_time": "2019-08-15T04:51:23.694690Z"
    }
   },
   "outputs": [],
   "source": [
    "#adacos_efficientnet_b4.body1[0]._conv_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T04:51:26.164300Z",
     "start_time": "2019-08-15T04:51:26.153003Z"
    }
   },
   "outputs": [],
   "source": [
    "#adacos_efficientnet_b4.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T04:51:29.300614Z",
     "start_time": "2019-08-15T04:51:29.288336Z"
    }
   },
   "outputs": [],
   "source": [
    "#adacos_efficientnet_b4.adacos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate layer groups for discriminative layer training\n",
    "# https://docs.fast.ai/basic_train.html#Discriminative-layer-training\n",
    "#learn.split((adacos_efficientnet_b4.body1[0]._conv_stem,\n",
    "#             #adacos_efficientnet_b3.body._blocks, # all blocks as a layer group\n",
    "#             *[adacos_efficientnet_b4.body1[0]._blocks[i] for i in range(31)], # put in each block\n",
    "#             adacos_efficientnet_b4.body1[0]._conv_head,\n",
    "#             adacos_efficientnet_b4.head,\n",
    "#             adacos_efficientnet_b4.adacos\n",
    "#            ));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T17:53:15.097224Z",
     "start_time": "2019-08-08T17:53:15.082545Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://github.com/pytorch/pytorch/issues/7455\n",
    "class LabelSmoothingLoss(nn.Module):\n",
    "    def __init__(self, classes, smoothing=0.0, dim=-1):\n",
    "        super(LabelSmoothingLoss, self).__init__()\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.cls = classes\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        pred = pred.log_softmax(dim=self.dim)\n",
    "        with torch.no_grad():\n",
    "            # true_dist = pred.data.clone()\n",
    "            true_dist = torch.zeros_like(pred)\n",
    "            true_dist.fill_(self.smoothing / (self.cls - 1))\n",
    "            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T17:53:16.922648Z",
     "start_time": "2019-08-08T17:53:16.905917Z"
    }
   },
   "outputs": [],
   "source": [
    "#labsmooth_loss = LabelSmoothingLoss(1108, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T17:53:17.615744Z",
     "start_time": "2019-08-08T17:53:17.596652Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.3397, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#input = torch.randn(3, 5, requires_grad=True)\n",
    "#target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "#labsmooth_loss(input, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T17:24:08.141099Z",
     "start_time": "2019-08-15T17:24:08.123967Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FlattenedLoss of CrossEntropyLoss()"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.loss_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T17:24:09.339313Z",
     "start_time": "2019-08-15T17:24:09.323349Z"
    }
   },
   "outputs": [],
   "source": [
    "#learn.loss_func = labsmooth_loss\n",
    "#learn.loss_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T17:24:09.707872Z",
     "start_time": "2019-08-15T17:24:09.665195Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.opt_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T17:35:46.796502Z",
     "start_time": "2019-08-08T17:35:46.753676Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://docs.fast.ai/callbacks.fp16.html\n",
    "#learn.to_fp16(loss_scale=512, clip=1e3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T17:35:48.775018Z",
     "start_time": "2019-08-08T17:35:48.756940Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99), eps=0.0001)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make Adam FP16 proof:\n",
    "# https://forums.fast.ai/t/mixed-precision-training/29601/21\n",
    "# https://discuss.pytorch.org/t/adam-half-precision-nans/1765\n",
    "# https://vxlabs.com/2019/02/04/improving-fastais-mixed-precision-support-with-nvidias-automatic-mixed-precision/\n",
    "#learn.opt_func = partial(learn.opt_func, eps=1e-4)\n",
    "#learn.opt_func\n",
    "#\n",
    "### ADD CLIP PARAMETER TOO???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-08T17:31:46.981195Z",
     "start_time": "2019-08-08T17:31:46.965718Z"
    }
   },
   "outputs": [],
   "source": [
    "#learn.layer_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:59:17.640868Z",
     "start_time": "2019-08-22T17:59:17.627091Z"
    }
   },
   "outputs": [],
   "source": [
    "def check_rg(model=learn.model):\n",
    "    layer_rg = [(n, p.requires_grad) for n,p in model.named_parameters()]\n",
    "    for i in range(len(layer_rg)):\n",
    "        print(f'{layer_rg[i][0]}\\t{layer_rg[i][1]}'.expandtabs(45))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:59:17.934267Z",
     "start_time": "2019-08-22T17:59:17.918737Z"
    }
   },
   "outputs": [],
   "source": [
    "# unfreeze network\n",
    "#learn.unfreeze()\n",
    "#set_rg(learn.model.body, option=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:59:18.188364Z",
     "start_time": "2019-08-22T17:59:18.122334Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "body1.0._conv_stem.weight                    False\n",
      "body1.0._bn0.weight                          False\n",
      "body1.0._bn0.bias                            False\n",
      "body1.0._blocks.0._depthwise_conv.weight     False\n",
      "body1.0._blocks.0._bn1.weight                False\n",
      "body1.0._blocks.0._bn1.bias                  False\n",
      "body1.0._blocks.0._se_reduce.weight          False\n",
      "body1.0._blocks.0._se_reduce.bias            False\n",
      "body1.0._blocks.0._se_expand.weight          False\n",
      "body1.0._blocks.0._se_expand.bias            False\n",
      "body1.0._blocks.0._project_conv.weight       False\n",
      "body1.0._blocks.0._bn2.weight                False\n",
      "body1.0._blocks.0._bn2.bias                  False\n",
      "body1.0._blocks.1._depthwise_conv.weight     False\n",
      "body1.0._blocks.1._bn1.weight                False\n",
      "body1.0._blocks.1._bn1.bias                  False\n",
      "body1.0._blocks.1._se_reduce.weight          False\n",
      "body1.0._blocks.1._se_reduce.bias            False\n",
      "body1.0._blocks.1._se_expand.weight          False\n",
      "body1.0._blocks.1._se_expand.bias            False\n",
      "body1.0._blocks.1._project_conv.weight       False\n",
      "body1.0._blocks.1._bn2.weight                False\n",
      "body1.0._blocks.1._bn2.bias                  False\n",
      "body1.0._blocks.2._expand_conv.weight        False\n",
      "body1.0._blocks.2._bn0.weight                False\n",
      "body1.0._blocks.2._bn0.bias                  False\n",
      "body1.0._blocks.2._depthwise_conv.weight     False\n",
      "body1.0._blocks.2._bn1.weight                False\n",
      "body1.0._blocks.2._bn1.bias                  False\n",
      "body1.0._blocks.2._se_reduce.weight          False\n",
      "body1.0._blocks.2._se_reduce.bias            False\n",
      "body1.0._blocks.2._se_expand.weight          False\n",
      "body1.0._blocks.2._se_expand.bias            False\n",
      "body1.0._blocks.2._project_conv.weight       False\n",
      "body1.0._blocks.2._bn2.weight                False\n",
      "body1.0._blocks.2._bn2.bias                  False\n",
      "body1.0._blocks.3._expand_conv.weight        False\n",
      "body1.0._blocks.3._bn0.weight                False\n",
      "body1.0._blocks.3._bn0.bias                  False\n",
      "body1.0._blocks.3._depthwise_conv.weight     False\n",
      "body1.0._blocks.3._bn1.weight                False\n",
      "body1.0._blocks.3._bn1.bias                  False\n",
      "body1.0._blocks.3._se_reduce.weight          False\n",
      "body1.0._blocks.3._se_reduce.bias            False\n",
      "body1.0._blocks.3._se_expand.weight          False\n",
      "body1.0._blocks.3._se_expand.bias            False\n",
      "body1.0._blocks.3._project_conv.weight       False\n",
      "body1.0._blocks.3._bn2.weight                False\n",
      "body1.0._blocks.3._bn2.bias                  False\n",
      "body1.0._blocks.4._expand_conv.weight        False\n",
      "body1.0._blocks.4._bn0.weight                False\n",
      "body1.0._blocks.4._bn0.bias                  False\n",
      "body1.0._blocks.4._depthwise_conv.weight     False\n",
      "body1.0._blocks.4._bn1.weight                False\n",
      "body1.0._blocks.4._bn1.bias                  False\n",
      "body1.0._blocks.4._se_reduce.weight          False\n",
      "body1.0._blocks.4._se_reduce.bias            False\n",
      "body1.0._blocks.4._se_expand.weight          False\n",
      "body1.0._blocks.4._se_expand.bias            False\n",
      "body1.0._blocks.4._project_conv.weight       False\n",
      "body1.0._blocks.4._bn2.weight                False\n",
      "body1.0._blocks.4._bn2.bias                  False\n",
      "body1.0._blocks.5._expand_conv.weight        False\n",
      "body1.0._blocks.5._bn0.weight                False\n",
      "body1.0._blocks.5._bn0.bias                  False\n",
      "body1.0._blocks.5._depthwise_conv.weight     False\n",
      "body1.0._blocks.5._bn1.weight                False\n",
      "body1.0._blocks.5._bn1.bias                  False\n",
      "body1.0._blocks.5._se_reduce.weight          False\n",
      "body1.0._blocks.5._se_reduce.bias            False\n",
      "body1.0._blocks.5._se_expand.weight          False\n",
      "body1.0._blocks.5._se_expand.bias            False\n",
      "body1.0._blocks.5._project_conv.weight       False\n",
      "body1.0._blocks.5._bn2.weight                False\n",
      "body1.0._blocks.5._bn2.bias                  False\n",
      "body1.0._blocks.6._expand_conv.weight        False\n",
      "body1.0._blocks.6._bn0.weight                False\n",
      "body1.0._blocks.6._bn0.bias                  False\n",
      "body1.0._blocks.6._depthwise_conv.weight     False\n",
      "body1.0._blocks.6._bn1.weight                False\n",
      "body1.0._blocks.6._bn1.bias                  False\n",
      "body1.0._blocks.6._se_reduce.weight          False\n",
      "body1.0._blocks.6._se_reduce.bias            False\n",
      "body1.0._blocks.6._se_expand.weight          False\n",
      "body1.0._blocks.6._se_expand.bias            False\n",
      "body1.0._blocks.6._project_conv.weight       False\n",
      "body1.0._blocks.6._bn2.weight                False\n",
      "body1.0._blocks.6._bn2.bias                  False\n",
      "body1.0._blocks.7._expand_conv.weight        False\n",
      "body1.0._blocks.7._bn0.weight                False\n",
      "body1.0._blocks.7._bn0.bias                  False\n",
      "body1.0._blocks.7._depthwise_conv.weight     False\n",
      "body1.0._blocks.7._bn1.weight                False\n",
      "body1.0._blocks.7._bn1.bias                  False\n",
      "body1.0._blocks.7._se_reduce.weight          False\n",
      "body1.0._blocks.7._se_reduce.bias            False\n",
      "body1.0._blocks.7._se_expand.weight          False\n",
      "body1.0._blocks.7._se_expand.bias            False\n",
      "body1.0._blocks.7._project_conv.weight       False\n",
      "body1.0._blocks.7._bn2.weight                False\n",
      "body1.0._blocks.7._bn2.bias                  False\n",
      "body1.0._blocks.8._expand_conv.weight        False\n",
      "body1.0._blocks.8._bn0.weight                False\n",
      "body1.0._blocks.8._bn0.bias                  False\n",
      "body1.0._blocks.8._depthwise_conv.weight     False\n",
      "body1.0._blocks.8._bn1.weight                False\n",
      "body1.0._blocks.8._bn1.bias                  False\n",
      "body1.0._blocks.8._se_reduce.weight          False\n",
      "body1.0._blocks.8._se_reduce.bias            False\n",
      "body1.0._blocks.8._se_expand.weight          False\n",
      "body1.0._blocks.8._se_expand.bias            False\n",
      "body1.0._blocks.8._project_conv.weight       False\n",
      "body1.0._blocks.8._bn2.weight                False\n",
      "body1.0._blocks.8._bn2.bias                  False\n",
      "body1.0._blocks.9._expand_conv.weight        False\n",
      "body1.0._blocks.9._bn0.weight                False\n",
      "body1.0._blocks.9._bn0.bias                  False\n",
      "body1.0._blocks.9._depthwise_conv.weight     False\n",
      "body1.0._blocks.9._bn1.weight                False\n",
      "body1.0._blocks.9._bn1.bias                  False\n",
      "body1.0._blocks.9._se_reduce.weight          False\n",
      "body1.0._blocks.9._se_reduce.bias            False\n",
      "body1.0._blocks.9._se_expand.weight          False\n",
      "body1.0._blocks.9._se_expand.bias            False\n",
      "body1.0._blocks.9._project_conv.weight       False\n",
      "body1.0._blocks.9._bn2.weight                False\n",
      "body1.0._blocks.9._bn2.bias                  False\n",
      "body1.0._blocks.10._expand_conv.weight       False\n",
      "body1.0._blocks.10._bn0.weight               False\n",
      "body1.0._blocks.10._bn0.bias                 False\n",
      "body1.0._blocks.10._depthwise_conv.weight    False\n",
      "body1.0._blocks.10._bn1.weight               False\n",
      "body1.0._blocks.10._bn1.bias                 False\n",
      "body1.0._blocks.10._se_reduce.weight         False\n",
      "body1.0._blocks.10._se_reduce.bias           False\n",
      "body1.0._blocks.10._se_expand.weight         False\n",
      "body1.0._blocks.10._se_expand.bias           False\n",
      "body1.0._blocks.10._project_conv.weight      False\n",
      "body1.0._blocks.10._bn2.weight               False\n",
      "body1.0._blocks.10._bn2.bias                 False\n",
      "body1.0._blocks.11._expand_conv.weight       False\n",
      "body1.0._blocks.11._bn0.weight               False\n",
      "body1.0._blocks.11._bn0.bias                 False\n",
      "body1.0._blocks.11._depthwise_conv.weight    False\n",
      "body1.0._blocks.11._bn1.weight               False\n",
      "body1.0._blocks.11._bn1.bias                 False\n",
      "body1.0._blocks.11._se_reduce.weight         False\n",
      "body1.0._blocks.11._se_reduce.bias           False\n",
      "body1.0._blocks.11._se_expand.weight         False\n",
      "body1.0._blocks.11._se_expand.bias           False\n",
      "body1.0._blocks.11._project_conv.weight      False\n",
      "body1.0._blocks.11._bn2.weight               False\n",
      "body1.0._blocks.11._bn2.bias                 False\n",
      "body1.0._blocks.12._expand_conv.weight       False\n",
      "body1.0._blocks.12._bn0.weight               False\n",
      "body1.0._blocks.12._bn0.bias                 False\n",
      "body1.0._blocks.12._depthwise_conv.weight    False\n",
      "body1.0._blocks.12._bn1.weight               False\n",
      "body1.0._blocks.12._bn1.bias                 False\n",
      "body1.0._blocks.12._se_reduce.weight         False\n",
      "body1.0._blocks.12._se_reduce.bias           False\n",
      "body1.0._blocks.12._se_expand.weight         False\n",
      "body1.0._blocks.12._se_expand.bias           False\n",
      "body1.0._blocks.12._project_conv.weight      False\n",
      "body1.0._blocks.12._bn2.weight               False\n",
      "body1.0._blocks.12._bn2.bias                 False\n",
      "body1.0._blocks.13._expand_conv.weight       False\n",
      "body1.0._blocks.13._bn0.weight               False\n",
      "body1.0._blocks.13._bn0.bias                 False\n",
      "body1.0._blocks.13._depthwise_conv.weight    False\n",
      "body1.0._blocks.13._bn1.weight               False\n",
      "body1.0._blocks.13._bn1.bias                 False\n",
      "body1.0._blocks.13._se_reduce.weight         False\n",
      "body1.0._blocks.13._se_reduce.bias           False\n",
      "body1.0._blocks.13._se_expand.weight         False\n",
      "body1.0._blocks.13._se_expand.bias           False\n",
      "body1.0._blocks.13._project_conv.weight      False\n",
      "body1.0._blocks.13._bn2.weight               False\n",
      "body1.0._blocks.13._bn2.bias                 False\n",
      "body1.0._blocks.14._expand_conv.weight       False\n",
      "body1.0._blocks.14._bn0.weight               False\n",
      "body1.0._blocks.14._bn0.bias                 False\n",
      "body1.0._blocks.14._depthwise_conv.weight    False\n",
      "body1.0._blocks.14._bn1.weight               False\n",
      "body1.0._blocks.14._bn1.bias                 False\n",
      "body1.0._blocks.14._se_reduce.weight         False\n",
      "body1.0._blocks.14._se_reduce.bias           False\n",
      "body1.0._blocks.14._se_expand.weight         False\n",
      "body1.0._blocks.14._se_expand.bias           False\n",
      "body1.0._blocks.14._project_conv.weight      False\n",
      "body1.0._blocks.14._bn2.weight               False\n",
      "body1.0._blocks.14._bn2.bias                 False\n",
      "body1.0._blocks.15._expand_conv.weight       False\n",
      "body1.0._blocks.15._bn0.weight               False\n",
      "body1.0._blocks.15._bn0.bias                 False\n",
      "body1.0._blocks.15._depthwise_conv.weight    False\n",
      "body1.0._blocks.15._bn1.weight               False\n",
      "body1.0._blocks.15._bn1.bias                 False\n",
      "body1.0._blocks.15._se_reduce.weight         False\n",
      "body1.0._blocks.15._se_reduce.bias           False\n",
      "body1.0._blocks.15._se_expand.weight         False\n",
      "body1.0._blocks.15._se_expand.bias           False\n",
      "body1.0._blocks.15._project_conv.weight      False\n",
      "body1.0._blocks.15._bn2.weight               False\n",
      "body1.0._blocks.15._bn2.bias                 False\n",
      "body1.0._blocks.16._expand_conv.weight       False\n",
      "body1.0._blocks.16._bn0.weight               False\n",
      "body1.0._blocks.16._bn0.bias                 False\n",
      "body1.0._blocks.16._depthwise_conv.weight    False\n",
      "body1.0._blocks.16._bn1.weight               False\n",
      "body1.0._blocks.16._bn1.bias                 False\n",
      "body1.0._blocks.16._se_reduce.weight         False\n",
      "body1.0._blocks.16._se_reduce.bias           False\n",
      "body1.0._blocks.16._se_expand.weight         False\n",
      "body1.0._blocks.16._se_expand.bias           False\n",
      "body1.0._blocks.16._project_conv.weight      False\n",
      "body1.0._blocks.16._bn2.weight               False\n",
      "body1.0._blocks.16._bn2.bias                 False\n",
      "body1.0._blocks.17._expand_conv.weight       False\n",
      "body1.0._blocks.17._bn0.weight               False\n",
      "body1.0._blocks.17._bn0.bias                 False\n",
      "body1.0._blocks.17._depthwise_conv.weight    False\n",
      "body1.0._blocks.17._bn1.weight               False\n",
      "body1.0._blocks.17._bn1.bias                 False\n",
      "body1.0._blocks.17._se_reduce.weight         False\n",
      "body1.0._blocks.17._se_reduce.bias           False\n",
      "body1.0._blocks.17._se_expand.weight         False\n",
      "body1.0._blocks.17._se_expand.bias           False\n",
      "body1.0._blocks.17._project_conv.weight      False\n",
      "body1.0._blocks.17._bn2.weight               False\n",
      "body1.0._blocks.17._bn2.bias                 False\n",
      "body1.0._blocks.18._expand_conv.weight       False\n",
      "body1.0._blocks.18._bn0.weight               False\n",
      "body1.0._blocks.18._bn0.bias                 False\n",
      "body1.0._blocks.18._depthwise_conv.weight    False\n",
      "body1.0._blocks.18._bn1.weight               False\n",
      "body1.0._blocks.18._bn1.bias                 False\n",
      "body1.0._blocks.18._se_reduce.weight         False\n",
      "body1.0._blocks.18._se_reduce.bias           False\n",
      "body1.0._blocks.18._se_expand.weight         False\n",
      "body1.0._blocks.18._se_expand.bias           False\n",
      "body1.0._blocks.18._project_conv.weight      False\n",
      "body1.0._blocks.18._bn2.weight               False\n",
      "body1.0._blocks.18._bn2.bias                 False\n",
      "body1.0._blocks.19._expand_conv.weight       False\n",
      "body1.0._blocks.19._bn0.weight               False\n",
      "body1.0._blocks.19._bn0.bias                 False\n",
      "body1.0._blocks.19._depthwise_conv.weight    False\n",
      "body1.0._blocks.19._bn1.weight               False\n",
      "body1.0._blocks.19._bn1.bias                 False\n",
      "body1.0._blocks.19._se_reduce.weight         False\n",
      "body1.0._blocks.19._se_reduce.bias           False\n",
      "body1.0._blocks.19._se_expand.weight         False\n",
      "body1.0._blocks.19._se_expand.bias           False\n",
      "body1.0._blocks.19._project_conv.weight      False\n",
      "body1.0._blocks.19._bn2.weight               False\n",
      "body1.0._blocks.19._bn2.bias                 False\n",
      "body1.0._blocks.20._expand_conv.weight       False\n",
      "body1.0._blocks.20._bn0.weight               False\n",
      "body1.0._blocks.20._bn0.bias                 False\n",
      "body1.0._blocks.20._depthwise_conv.weight    False\n",
      "body1.0._blocks.20._bn1.weight               False\n",
      "body1.0._blocks.20._bn1.bias                 False\n",
      "body1.0._blocks.20._se_reduce.weight         False\n",
      "body1.0._blocks.20._se_reduce.bias           False\n",
      "body1.0._blocks.20._se_expand.weight         False\n",
      "body1.0._blocks.20._se_expand.bias           False\n",
      "body1.0._blocks.20._project_conv.weight      False\n",
      "body1.0._blocks.20._bn2.weight               False\n",
      "body1.0._blocks.20._bn2.bias                 False\n",
      "body1.0._blocks.21._expand_conv.weight       False\n",
      "body1.0._blocks.21._bn0.weight               False\n",
      "body1.0._blocks.21._bn0.bias                 False\n",
      "body1.0._blocks.21._depthwise_conv.weight    False\n",
      "body1.0._blocks.21._bn1.weight               False\n",
      "body1.0._blocks.21._bn1.bias                 False\n",
      "body1.0._blocks.21._se_reduce.weight         False\n",
      "body1.0._blocks.21._se_reduce.bias           False\n",
      "body1.0._blocks.21._se_expand.weight         False\n",
      "body1.0._blocks.21._se_expand.bias           False\n",
      "body1.0._blocks.21._project_conv.weight      False\n",
      "body1.0._blocks.21._bn2.weight               False\n",
      "body1.0._blocks.21._bn2.bias                 False\n",
      "body1.0._blocks.22._expand_conv.weight       False\n",
      "body1.0._blocks.22._bn0.weight               False\n",
      "body1.0._blocks.22._bn0.bias                 False\n",
      "body1.0._blocks.22._depthwise_conv.weight    False\n",
      "body1.0._blocks.22._bn1.weight               False\n",
      "body1.0._blocks.22._bn1.bias                 False\n",
      "body1.0._blocks.22._se_reduce.weight         False\n",
      "body1.0._blocks.22._se_reduce.bias           False\n",
      "body1.0._blocks.22._se_expand.weight         False\n",
      "body1.0._blocks.22._se_expand.bias           False\n",
      "body1.0._blocks.22._project_conv.weight      False\n",
      "body1.0._blocks.22._bn2.weight               False\n",
      "body1.0._blocks.22._bn2.bias                 False\n",
      "body1.0._blocks.23._expand_conv.weight       False\n",
      "body1.0._blocks.23._bn0.weight               False\n",
      "body1.0._blocks.23._bn0.bias                 False\n",
      "body1.0._blocks.23._depthwise_conv.weight    False\n",
      "body1.0._blocks.23._bn1.weight               False\n",
      "body1.0._blocks.23._bn1.bias                 False\n",
      "body1.0._blocks.23._se_reduce.weight         False\n",
      "body1.0._blocks.23._se_reduce.bias           False\n",
      "body1.0._blocks.23._se_expand.weight         False\n",
      "body1.0._blocks.23._se_expand.bias           False\n",
      "body1.0._blocks.23._project_conv.weight      False\n",
      "body1.0._blocks.23._bn2.weight               False\n",
      "body1.0._blocks.23._bn2.bias                 False\n",
      "body1.0._blocks.24._expand_conv.weight       False\n",
      "body1.0._blocks.24._bn0.weight               False\n",
      "body1.0._blocks.24._bn0.bias                 False\n",
      "body1.0._blocks.24._depthwise_conv.weight    False\n",
      "body1.0._blocks.24._bn1.weight               False\n",
      "body1.0._blocks.24._bn1.bias                 False\n",
      "body1.0._blocks.24._se_reduce.weight         False\n",
      "body1.0._blocks.24._se_reduce.bias           False\n",
      "body1.0._blocks.24._se_expand.weight         False\n",
      "body1.0._blocks.24._se_expand.bias           False\n",
      "body1.0._blocks.24._project_conv.weight      False\n",
      "body1.0._blocks.24._bn2.weight               False\n",
      "body1.0._blocks.24._bn2.bias                 False\n",
      "body1.0._blocks.25._expand_conv.weight       False\n",
      "body1.0._blocks.25._bn0.weight               False\n",
      "body1.0._blocks.25._bn0.bias                 False\n",
      "body1.0._blocks.25._depthwise_conv.weight    False\n",
      "body1.0._blocks.25._bn1.weight               False\n",
      "body1.0._blocks.25._bn1.bias                 False\n",
      "body1.0._blocks.25._se_reduce.weight         False\n",
      "body1.0._blocks.25._se_reduce.bias           False\n",
      "body1.0._blocks.25._se_expand.weight         False\n",
      "body1.0._blocks.25._se_expand.bias           False\n",
      "body1.0._blocks.25._project_conv.weight      False\n",
      "body1.0._blocks.25._bn2.weight               False\n",
      "body1.0._blocks.25._bn2.bias                 False\n",
      "body1.0._conv_head.weight                    False\n",
      "body1.0._bn1.weight                          False\n",
      "body1.0._bn1.bias                            False\n",
      "body2.emb_ctint.weight                       True\n",
      "body2.emb_pgint.weight                       True\n",
      "body2.emb_expint.weight                      True\n",
      "head.0.weight                                True\n",
      "head.0.bias                                  True\n",
      "head.2.weight                                True\n",
      "head.2.bias                                  True\n",
      "head.4.weight                                True\n",
      "head.4.bias                                  True\n",
      "head.6.weight                                True\n",
      "head.6.bias                                  True\n",
      "head.8.weight                                True\n",
      "head.8.bias                                  True\n",
      "head.10.weight                               True\n",
      "head.10.bias                                 True\n",
      "head.12.weight                               True\n",
      "head.12.bias                                 True\n",
      "head.14.weight                               True\n",
      "head.14.bias                                 True\n",
      "adacos.W                                     True\n"
     ]
    }
   ],
   "source": [
    "check_rg() # check where trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T05:00:33.658143Z",
     "start_time": "2019-08-19T05:00:33.641819Z"
    }
   },
   "outputs": [],
   "source": [
    "#learn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:59:22.729276Z",
     "start_time": "2019-08-22T17:59:22.646868Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://discuss.pytorch.org/t/how-to-load-part-of-pre-trained-model/1113/3?u=micpie\n",
    "pretrained_dict = torch.load('train/models/effnet/adacos_efficientnet_b3_e080CM185-230_190807_best.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:41:55.517757Z",
     "start_time": "2019-08-22T17:41:55.499739Z"
    }
   },
   "outputs": [],
   "source": [
    "#model_dict = learn.model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:49:50.389690Z",
     "start_time": "2019-08-22T17:49:50.373715Z"
    }
   },
   "outputs": [],
   "source": [
    "#[k for k, v in model_dict.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:49:46.960948Z",
     "start_time": "2019-08-22T17:49:46.945009Z"
    }
   },
   "outputs": [],
   "source": [
    "#[k for k, v in pretrained_dict['model'].items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:59:24.694740Z",
     "start_time": "2019-08-22T17:59:24.677962Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'body1.0._blocks.12._bn0.bias'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'body._blocks.12._bn0.bias'.replace('body', 'body1.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:59:25.107409Z",
     "start_time": "2019-08-22T17:59:25.091976Z"
    }
   },
   "outputs": [],
   "source": [
    "#[k.replace('body', 'body1') for k, v in pretrained_dict['model'].items() if k.find('body') != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:59:25.682064Z",
     "start_time": "2019-08-22T17:59:25.669140Z"
    }
   },
   "outputs": [],
   "source": [
    "effnet_weights = {k.replace('body', 'body1.0'): v for k, v in pretrained_dict['model'].items()\n",
    "                  if k.find('body') != -1}\n",
    "\n",
    "#effnet_weights = OrderedDict(k.replace('body', 'body1'): v for k, v in pretrained_dict['model'].items()\n",
    "#                  if k.find('body') != -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:59:26.290990Z",
     "start_time": "2019-08-22T17:59:26.221092Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(effnet_weights, 'train/models/effnet/adacos_efficientnet_b3_e080CM185-230_190807_best_body1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:53:28.137831Z",
     "start_time": "2019-08-22T17:53:28.120573Z"
    }
   },
   "outputs": [],
   "source": [
    "# 1. filter out unnecessary keys\n",
    "#pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:53:31.719566Z",
     "start_time": "2019-08-22T17:53:31.702984Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2. overwrite entries in the existing state dict\n",
    "#model_dict.update(pretrained_dict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:54:33.467500Z",
     "start_time": "2019-08-22T17:54:33.451776Z"
    }
   },
   "outputs": [],
   "source": [
    "# 3. load the new state dict\n",
    "#learn.model.load_state_dict(pretrained_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:59:29.258454Z",
     "start_time": "2019-08-22T17:59:29.125898Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAAD3CAYAAAC+eIeLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAIl0lEQVR4nO3cX+jddR3H8dfb/YamTqMLFROSYvafhl0oRuVFMBSyIBDLwIQg1F2IE/RCLzJhFwpdiCWC0JgRBJkRBoJFYF5EgX/AMEWZSikVpG3+Wdv8dPH7CSFuZDu/92ceHw84sN857MeL35fzPN/fOd+txhgBoMcxswcAvJeILkAj0QVoJLoAjUQXoJHoAjQSXYBGSxvdqvpAVf28ql6pqmer6huzN3HkqmpbVf2xqvZV1Y9m72ExqurYqrpr7bm6p6oerqoLZu9aDyuzB6yj25P8O8mpSbYkua+qHh1jPD53Fkfor0luTrI1yfsmb2FxVpI8n+SLSZ5LcmGSn1bVp8cYu2cOW7Raxn+RVlUnJPlnkk+NMZ5cu29Xkr+MMa6fOo6FqKqbk5wxxvjW7C2sj6p6LMl3xxg/m71lkZb17YWzkhx8M7hrHk3yyUl7gHegqk7N6vN46X4zXdbonpjk5bfc93KSTRO2AO9AVW1M8uMkO8cYT8zes2jLGt29SU56y30nJdkzYQvwP6qqY5LsyurnMdsmz1kXyxrdJ5OsVNXm/7rvM1nCX1VgWVRVJbkrqx9+f22MsX/ypHWxlNEdY7yS5J4kN1XVCVX1uSRfyeorKO9iVbVSVccl2ZBkQ1UdV1XLfBXOe8kPk3w8yZfHGK/NHrNeljK6a67M6iVFf0vykyRXuFxsKdyQ5LUk1yf55tqfb5i6iCNWVR9K8p2sXt75YlXtXbtdOnnawi3lJWMAR6tlPtMFOOqILkAj0QVoJLoAjUQXoNFhr2/c/sjF0y9teOzs6RPy9K3nzp6QZ67ZXov6Xm+8uHn6D3Xr6VtmT8hTt50ze0J2X3Xtwo5rklz04Lbpx3b/ZcfOnpA/3XjK7Al59vLr3vbYOtMFaCS6AI1EF6CR6AI0El2ARqIL0Eh0ARqJLkAj0QVoJLoAjUQXoJHoAjQSXYBGogvQSHQBGokuQCPRBWgkugCNRBegkegCNBJdgEaiC9BIdAEaiS5AI9EFaCS6AI1EF6CR6AI0El2ARqIL0Eh0ARqtHO7BW057uGvHIV1w/HmzJ2TjnuV6bXrhwN7ZE3LMpk2zJ6QO1OwJC3fv5vtnT8jW3VtmT8iGl06fPeGQlqsmAEc50QVoJLoAjUQXoJHoAjQSXYBGogvQSHQBGokuQCPRBWgkugCNRBegkegCNBJdgEaiC9BIdAEaiS5AI9EFaCS6AI1EF6CR6AI0El2ARqIL0Eh0ARqJLkAj0QVoJLoAjUQXoJHoAjQSXYBGogvQSHQBGq0c7sGzdl7RtePQbpg9IDlw8sHZExbqvAeunj0htWPD7AkZG5fruCbJ5l3zn7O1Y/aC5ODJ+2dPOCRnugCNRBegkegCNBJdgEaiC9BIdAEaiS5AI9EFaCS6AI1EF6CR6AI0El2ARqIL0Eh0ARqJLkAj0QVoJLoAjUQXoJHoAjQSXYBGogvQSHQBGokuQCPRBWgkugCNRBegkegCNBJdgEaiC9BIdAEaiS5AI9EFaFRjjNkbAN4znOkCNBJdgEaiC9BIdAEaiS5Ao6WNblXdXVUvVNW/qurJqvr27E0sTlVtrqrXq+ru2VtYjKr67dox3bt2+/PsTethaaObZEeSM8cYJyW5KMnNVfXZyZtYnNuT/GH2CBZu2xjjxLXbR2ePWQ9LG90xxuNjjH1vfrl2+8jESSxIVV2S5KUkv569Bd6ppY1uklTVD6rq1SRPJHkhya8mT+IIVdVJSW5Ksn32FtbFjqr6R1U9VFXnzx6zHpY6umOMK5NsSvL5JPck2Xf4v8G7wPeS3DXGeH72EBbuuiQfTvLBJHcm+WVVLd1vp0sd3SQZYxwcY/wuyRlJrpi9h/9fVW1J8qUk35+9hcUbY/x+jLFnjLFvjLEzyUNJLpy9a9FWZg9otBLv6b7bnZ/kzCTPVVWSnJhkQ1V9Yoxx9sRdrI+RpGaPWLSlPNOtqlOq6pKqOrGqNlTV1iRfT/Kb2ds4Indm9YVzy9rtjiT3Jdk6cxRHrqreX1Vbq+q4qlqpqkuTfCHJ/bO3LdqynumOrL6VcEdWX1ieTXL1GOMXU1dxRMYYryZ59c2vq2pvktfHGH+ft4oF2Zjk5iQfS3Iwqx9+f3WMsXTX6vqvHQEaLeXbCwBHK9EFaCS6AI1EF6DRYa9e2P7IxdM/ZXvs7OkT8vSt586ekGeu2b6w6xXfeHHz9B/q1tO3zJ6Qp247Z/aE7L7q2oVeh3rRg9umH9v9lx07e0L+dOMpsyfk2cuve9tj60wXoJHoAjQSXYBGogvQSHQBGokuQCPRBWgkugCNRBegkegCNBJdgEaiC9BIdAEaiS5AI9EFaCS6AI1EF6CR6AI0El2ARqIL0Eh0ARqJLkAj0QVoJLoAjUQXoJHoAjQSXYBGogvQSHQBGokuQCPRBWgkugCNVg734C2nPdy145AuOP682ROycc9yvTa9cGDv7Ak5ZtOm2RNSB2r2hIW7d/P9sydk6+4tsydkw0unz55wSMtVE4CjnOgCNBJdgEaiC9BIdAEaiS5AI9EFaCS6AI1EF6CR6AI0El2ARqIL0Eh0ARqJLkAj0QVoJLoAjUQXoJHoAjQSXYBGogvQSHQBGokuQCPRBWgkugCNRBegkegCNBJdgEaiC9BIdAEaiS5AI9EFaCS6AI1WDvfgWTuv6NpxaDfMHpAcOPng7AkLdd4DV8+ekNqxYfaEjI3LdVyTZPOu+c/Z2jF7QXLw5P2zJxySM12ARqIL0Eh0ARqJLkAj0QVoJLoAjUQXoJHoAjQSXYBGogvQSHQBGokuQCPRBWgkugCNRBegkegCNBJdgEaiC9BIdAEaiS5AI9EFaCS6AI1EF6CR6AI0El2ARqIL0Eh0ARqJLkAj0QVoJLoAjUQXoJHoAjSqMcbsDQDvGc50ARqJLkAj0QVoJLoAjUQXoJHoAjT6DxbeQ7//GfZgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compare initialized input stage to pretrain input stage\n",
    "show_input_stage_weights(new_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:59:32.630320Z",
     "start_time": "2019-08-22T17:59:32.504571Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.load('effnet/adacos_efficientnet_b3_e080CM185-230_190807_best_body1', strict=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:59:33.244746Z",
     "start_time": "2019-08-22T17:59:33.117966Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_input_stage_weights(learn.model.body1[0]._conv_stem.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:59:40.325419Z",
     "start_time": "2019-08-22T17:59:40.293667Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "body1.0._conv_stem.weight                    False\n",
      "body1.0._bn0.weight                          False\n",
      "body1.0._bn0.bias                            False\n",
      "body1.0._blocks.0._depthwise_conv.weight     False\n",
      "body1.0._blocks.0._bn1.weight                False\n",
      "body1.0._blocks.0._bn1.bias                  False\n",
      "body1.0._blocks.0._se_reduce.weight          False\n",
      "body1.0._blocks.0._se_reduce.bias            False\n",
      "body1.0._blocks.0._se_expand.weight          False\n",
      "body1.0._blocks.0._se_expand.bias            False\n",
      "body1.0._blocks.0._project_conv.weight       False\n",
      "body1.0._blocks.0._bn2.weight                False\n",
      "body1.0._blocks.0._bn2.bias                  False\n",
      "body1.0._blocks.1._depthwise_conv.weight     False\n",
      "body1.0._blocks.1._bn1.weight                False\n",
      "body1.0._blocks.1._bn1.bias                  False\n",
      "body1.0._blocks.1._se_reduce.weight          False\n",
      "body1.0._blocks.1._se_reduce.bias            False\n",
      "body1.0._blocks.1._se_expand.weight          False\n",
      "body1.0._blocks.1._se_expand.bias            False\n",
      "body1.0._blocks.1._project_conv.weight       False\n",
      "body1.0._blocks.1._bn2.weight                False\n",
      "body1.0._blocks.1._bn2.bias                  False\n",
      "body1.0._blocks.2._expand_conv.weight        False\n",
      "body1.0._blocks.2._bn0.weight                False\n",
      "body1.0._blocks.2._bn0.bias                  False\n",
      "body1.0._blocks.2._depthwise_conv.weight     False\n",
      "body1.0._blocks.2._bn1.weight                False\n",
      "body1.0._blocks.2._bn1.bias                  False\n",
      "body1.0._blocks.2._se_reduce.weight          False\n",
      "body1.0._blocks.2._se_reduce.bias            False\n",
      "body1.0._blocks.2._se_expand.weight          False\n",
      "body1.0._blocks.2._se_expand.bias            False\n",
      "body1.0._blocks.2._project_conv.weight       False\n",
      "body1.0._blocks.2._bn2.weight                False\n",
      "body1.0._blocks.2._bn2.bias                  False\n",
      "body1.0._blocks.3._expand_conv.weight        False\n",
      "body1.0._blocks.3._bn0.weight                False\n",
      "body1.0._blocks.3._bn0.bias                  False\n",
      "body1.0._blocks.3._depthwise_conv.weight     False\n",
      "body1.0._blocks.3._bn1.weight                False\n",
      "body1.0._blocks.3._bn1.bias                  False\n",
      "body1.0._blocks.3._se_reduce.weight          False\n",
      "body1.0._blocks.3._se_reduce.bias            False\n",
      "body1.0._blocks.3._se_expand.weight          False\n",
      "body1.0._blocks.3._se_expand.bias            False\n",
      "body1.0._blocks.3._project_conv.weight       False\n",
      "body1.0._blocks.3._bn2.weight                False\n",
      "body1.0._blocks.3._bn2.bias                  False\n",
      "body1.0._blocks.4._expand_conv.weight        False\n",
      "body1.0._blocks.4._bn0.weight                False\n",
      "body1.0._blocks.4._bn0.bias                  False\n",
      "body1.0._blocks.4._depthwise_conv.weight     False\n",
      "body1.0._blocks.4._bn1.weight                False\n",
      "body1.0._blocks.4._bn1.bias                  False\n",
      "body1.0._blocks.4._se_reduce.weight          False\n",
      "body1.0._blocks.4._se_reduce.bias            False\n",
      "body1.0._blocks.4._se_expand.weight          False\n",
      "body1.0._blocks.4._se_expand.bias            False\n",
      "body1.0._blocks.4._project_conv.weight       False\n",
      "body1.0._blocks.4._bn2.weight                False\n",
      "body1.0._blocks.4._bn2.bias                  False\n",
      "body1.0._blocks.5._expand_conv.weight        False\n",
      "body1.0._blocks.5._bn0.weight                False\n",
      "body1.0._blocks.5._bn0.bias                  False\n",
      "body1.0._blocks.5._depthwise_conv.weight     False\n",
      "body1.0._blocks.5._bn1.weight                False\n",
      "body1.0._blocks.5._bn1.bias                  False\n",
      "body1.0._blocks.5._se_reduce.weight          False\n",
      "body1.0._blocks.5._se_reduce.bias            False\n",
      "body1.0._blocks.5._se_expand.weight          False\n",
      "body1.0._blocks.5._se_expand.bias            False\n",
      "body1.0._blocks.5._project_conv.weight       False\n",
      "body1.0._blocks.5._bn2.weight                False\n",
      "body1.0._blocks.5._bn2.bias                  False\n",
      "body1.0._blocks.6._expand_conv.weight        False\n",
      "body1.0._blocks.6._bn0.weight                False\n",
      "body1.0._blocks.6._bn0.bias                  False\n",
      "body1.0._blocks.6._depthwise_conv.weight     False\n",
      "body1.0._blocks.6._bn1.weight                False\n",
      "body1.0._blocks.6._bn1.bias                  False\n",
      "body1.0._blocks.6._se_reduce.weight          False\n",
      "body1.0._blocks.6._se_reduce.bias            False\n",
      "body1.0._blocks.6._se_expand.weight          False\n",
      "body1.0._blocks.6._se_expand.bias            False\n",
      "body1.0._blocks.6._project_conv.weight       False\n",
      "body1.0._blocks.6._bn2.weight                False\n",
      "body1.0._blocks.6._bn2.bias                  False\n",
      "body1.0._blocks.7._expand_conv.weight        False\n",
      "body1.0._blocks.7._bn0.weight                False\n",
      "body1.0._blocks.7._bn0.bias                  False\n",
      "body1.0._blocks.7._depthwise_conv.weight     False\n",
      "body1.0._blocks.7._bn1.weight                False\n",
      "body1.0._blocks.7._bn1.bias                  False\n",
      "body1.0._blocks.7._se_reduce.weight          False\n",
      "body1.0._blocks.7._se_reduce.bias            False\n",
      "body1.0._blocks.7._se_expand.weight          False\n",
      "body1.0._blocks.7._se_expand.bias            False\n",
      "body1.0._blocks.7._project_conv.weight       False\n",
      "body1.0._blocks.7._bn2.weight                False\n",
      "body1.0._blocks.7._bn2.bias                  False\n",
      "body1.0._blocks.8._expand_conv.weight        False\n",
      "body1.0._blocks.8._bn0.weight                False\n",
      "body1.0._blocks.8._bn0.bias                  False\n",
      "body1.0._blocks.8._depthwise_conv.weight     False\n",
      "body1.0._blocks.8._bn1.weight                False\n",
      "body1.0._blocks.8._bn1.bias                  False\n",
      "body1.0._blocks.8._se_reduce.weight          False\n",
      "body1.0._blocks.8._se_reduce.bias            False\n",
      "body1.0._blocks.8._se_expand.weight          False\n",
      "body1.0._blocks.8._se_expand.bias            False\n",
      "body1.0._blocks.8._project_conv.weight       False\n",
      "body1.0._blocks.8._bn2.weight                False\n",
      "body1.0._blocks.8._bn2.bias                  False\n",
      "body1.0._blocks.9._expand_conv.weight        False\n",
      "body1.0._blocks.9._bn0.weight                False\n",
      "body1.0._blocks.9._bn0.bias                  False\n",
      "body1.0._blocks.9._depthwise_conv.weight     False\n",
      "body1.0._blocks.9._bn1.weight                False\n",
      "body1.0._blocks.9._bn1.bias                  False\n",
      "body1.0._blocks.9._se_reduce.weight          False\n",
      "body1.0._blocks.9._se_reduce.bias            False\n",
      "body1.0._blocks.9._se_expand.weight          False\n",
      "body1.0._blocks.9._se_expand.bias            False\n",
      "body1.0._blocks.9._project_conv.weight       False\n",
      "body1.0._blocks.9._bn2.weight                False\n",
      "body1.0._blocks.9._bn2.bias                  False\n",
      "body1.0._blocks.10._expand_conv.weight       False\n",
      "body1.0._blocks.10._bn0.weight               False\n",
      "body1.0._blocks.10._bn0.bias                 False\n",
      "body1.0._blocks.10._depthwise_conv.weight    False\n",
      "body1.0._blocks.10._bn1.weight               False\n",
      "body1.0._blocks.10._bn1.bias                 False\n",
      "body1.0._blocks.10._se_reduce.weight         False\n",
      "body1.0._blocks.10._se_reduce.bias           False\n",
      "body1.0._blocks.10._se_expand.weight         False\n",
      "body1.0._blocks.10._se_expand.bias           False\n",
      "body1.0._blocks.10._project_conv.weight      False\n",
      "body1.0._blocks.10._bn2.weight               False\n",
      "body1.0._blocks.10._bn2.bias                 False\n",
      "body1.0._blocks.11._expand_conv.weight       False\n",
      "body1.0._blocks.11._bn0.weight               False\n",
      "body1.0._blocks.11._bn0.bias                 False\n",
      "body1.0._blocks.11._depthwise_conv.weight    False\n",
      "body1.0._blocks.11._bn1.weight               False\n",
      "body1.0._blocks.11._bn1.bias                 False\n",
      "body1.0._blocks.11._se_reduce.weight         False\n",
      "body1.0._blocks.11._se_reduce.bias           False\n",
      "body1.0._blocks.11._se_expand.weight         False\n",
      "body1.0._blocks.11._se_expand.bias           False\n",
      "body1.0._blocks.11._project_conv.weight      False\n",
      "body1.0._blocks.11._bn2.weight               False\n",
      "body1.0._blocks.11._bn2.bias                 False\n",
      "body1.0._blocks.12._expand_conv.weight       False\n",
      "body1.0._blocks.12._bn0.weight               False\n",
      "body1.0._blocks.12._bn0.bias                 False\n",
      "body1.0._blocks.12._depthwise_conv.weight    False\n",
      "body1.0._blocks.12._bn1.weight               False\n",
      "body1.0._blocks.12._bn1.bias                 False\n",
      "body1.0._blocks.12._se_reduce.weight         False\n",
      "body1.0._blocks.12._se_reduce.bias           False\n",
      "body1.0._blocks.12._se_expand.weight         False\n",
      "body1.0._blocks.12._se_expand.bias           False\n",
      "body1.0._blocks.12._project_conv.weight      False\n",
      "body1.0._blocks.12._bn2.weight               False\n",
      "body1.0._blocks.12._bn2.bias                 False\n",
      "body1.0._blocks.13._expand_conv.weight       False\n",
      "body1.0._blocks.13._bn0.weight               False\n",
      "body1.0._blocks.13._bn0.bias                 False\n",
      "body1.0._blocks.13._depthwise_conv.weight    False\n",
      "body1.0._blocks.13._bn1.weight               False\n",
      "body1.0._blocks.13._bn1.bias                 False\n",
      "body1.0._blocks.13._se_reduce.weight         False\n",
      "body1.0._blocks.13._se_reduce.bias           False\n",
      "body1.0._blocks.13._se_expand.weight         False\n",
      "body1.0._blocks.13._se_expand.bias           False\n",
      "body1.0._blocks.13._project_conv.weight      False\n",
      "body1.0._blocks.13._bn2.weight               False\n",
      "body1.0._blocks.13._bn2.bias                 False\n",
      "body1.0._blocks.14._expand_conv.weight       False\n",
      "body1.0._blocks.14._bn0.weight               False\n",
      "body1.0._blocks.14._bn0.bias                 False\n",
      "body1.0._blocks.14._depthwise_conv.weight    False\n",
      "body1.0._blocks.14._bn1.weight               False\n",
      "body1.0._blocks.14._bn1.bias                 False\n",
      "body1.0._blocks.14._se_reduce.weight         False\n",
      "body1.0._blocks.14._se_reduce.bias           False\n",
      "body1.0._blocks.14._se_expand.weight         False\n",
      "body1.0._blocks.14._se_expand.bias           False\n",
      "body1.0._blocks.14._project_conv.weight      False\n",
      "body1.0._blocks.14._bn2.weight               False\n",
      "body1.0._blocks.14._bn2.bias                 False\n",
      "body1.0._blocks.15._expand_conv.weight       False\n",
      "body1.0._blocks.15._bn0.weight               False\n",
      "body1.0._blocks.15._bn0.bias                 False\n",
      "body1.0._blocks.15._depthwise_conv.weight    False\n",
      "body1.0._blocks.15._bn1.weight               False\n",
      "body1.0._blocks.15._bn1.bias                 False\n",
      "body1.0._blocks.15._se_reduce.weight         False\n",
      "body1.0._blocks.15._se_reduce.bias           False\n",
      "body1.0._blocks.15._se_expand.weight         False\n",
      "body1.0._blocks.15._se_expand.bias           False\n",
      "body1.0._blocks.15._project_conv.weight      False\n",
      "body1.0._blocks.15._bn2.weight               False\n",
      "body1.0._blocks.15._bn2.bias                 False\n",
      "body1.0._blocks.16._expand_conv.weight       False\n",
      "body1.0._blocks.16._bn0.weight               False\n",
      "body1.0._blocks.16._bn0.bias                 False\n",
      "body1.0._blocks.16._depthwise_conv.weight    False\n",
      "body1.0._blocks.16._bn1.weight               False\n",
      "body1.0._blocks.16._bn1.bias                 False\n",
      "body1.0._blocks.16._se_reduce.weight         False\n",
      "body1.0._blocks.16._se_reduce.bias           False\n",
      "body1.0._blocks.16._se_expand.weight         False\n",
      "body1.0._blocks.16._se_expand.bias           False\n",
      "body1.0._blocks.16._project_conv.weight      False\n",
      "body1.0._blocks.16._bn2.weight               False\n",
      "body1.0._blocks.16._bn2.bias                 False\n",
      "body1.0._blocks.17._expand_conv.weight       False\n",
      "body1.0._blocks.17._bn0.weight               False\n",
      "body1.0._blocks.17._bn0.bias                 False\n",
      "body1.0._blocks.17._depthwise_conv.weight    False\n",
      "body1.0._blocks.17._bn1.weight               False\n",
      "body1.0._blocks.17._bn1.bias                 False\n",
      "body1.0._blocks.17._se_reduce.weight         False\n",
      "body1.0._blocks.17._se_reduce.bias           False\n",
      "body1.0._blocks.17._se_expand.weight         False\n",
      "body1.0._blocks.17._se_expand.bias           False\n",
      "body1.0._blocks.17._project_conv.weight      False\n",
      "body1.0._blocks.17._bn2.weight               False\n",
      "body1.0._blocks.17._bn2.bias                 False\n",
      "body1.0._blocks.18._expand_conv.weight       False\n",
      "body1.0._blocks.18._bn0.weight               False\n",
      "body1.0._blocks.18._bn0.bias                 False\n",
      "body1.0._blocks.18._depthwise_conv.weight    False\n",
      "body1.0._blocks.18._bn1.weight               False\n",
      "body1.0._blocks.18._bn1.bias                 False\n",
      "body1.0._blocks.18._se_reduce.weight         False\n",
      "body1.0._blocks.18._se_reduce.bias           False\n",
      "body1.0._blocks.18._se_expand.weight         False\n",
      "body1.0._blocks.18._se_expand.bias           False\n",
      "body1.0._blocks.18._project_conv.weight      False\n",
      "body1.0._blocks.18._bn2.weight               False\n",
      "body1.0._blocks.18._bn2.bias                 False\n",
      "body1.0._blocks.19._expand_conv.weight       False\n",
      "body1.0._blocks.19._bn0.weight               False\n",
      "body1.0._blocks.19._bn0.bias                 False\n",
      "body1.0._blocks.19._depthwise_conv.weight    False\n",
      "body1.0._blocks.19._bn1.weight               False\n",
      "body1.0._blocks.19._bn1.bias                 False\n",
      "body1.0._blocks.19._se_reduce.weight         False\n",
      "body1.0._blocks.19._se_reduce.bias           False\n",
      "body1.0._blocks.19._se_expand.weight         False\n",
      "body1.0._blocks.19._se_expand.bias           False\n",
      "body1.0._blocks.19._project_conv.weight      False\n",
      "body1.0._blocks.19._bn2.weight               False\n",
      "body1.0._blocks.19._bn2.bias                 False\n",
      "body1.0._blocks.20._expand_conv.weight       False\n",
      "body1.0._blocks.20._bn0.weight               False\n",
      "body1.0._blocks.20._bn0.bias                 False\n",
      "body1.0._blocks.20._depthwise_conv.weight    False\n",
      "body1.0._blocks.20._bn1.weight               False\n",
      "body1.0._blocks.20._bn1.bias                 False\n",
      "body1.0._blocks.20._se_reduce.weight         False\n",
      "body1.0._blocks.20._se_reduce.bias           False\n",
      "body1.0._blocks.20._se_expand.weight         False\n",
      "body1.0._blocks.20._se_expand.bias           False\n",
      "body1.0._blocks.20._project_conv.weight      False\n",
      "body1.0._blocks.20._bn2.weight               False\n",
      "body1.0._blocks.20._bn2.bias                 False\n",
      "body1.0._blocks.21._expand_conv.weight       False\n",
      "body1.0._blocks.21._bn0.weight               False\n",
      "body1.0._blocks.21._bn0.bias                 False\n",
      "body1.0._blocks.21._depthwise_conv.weight    False\n",
      "body1.0._blocks.21._bn1.weight               False\n",
      "body1.0._blocks.21._bn1.bias                 False\n",
      "body1.0._blocks.21._se_reduce.weight         False\n",
      "body1.0._blocks.21._se_reduce.bias           False\n",
      "body1.0._blocks.21._se_expand.weight         False\n",
      "body1.0._blocks.21._se_expand.bias           False\n",
      "body1.0._blocks.21._project_conv.weight      False\n",
      "body1.0._blocks.21._bn2.weight               False\n",
      "body1.0._blocks.21._bn2.bias                 False\n",
      "body1.0._blocks.22._expand_conv.weight       False\n",
      "body1.0._blocks.22._bn0.weight               False\n",
      "body1.0._blocks.22._bn0.bias                 False\n",
      "body1.0._blocks.22._depthwise_conv.weight    False\n",
      "body1.0._blocks.22._bn1.weight               False\n",
      "body1.0._blocks.22._bn1.bias                 False\n",
      "body1.0._blocks.22._se_reduce.weight         False\n",
      "body1.0._blocks.22._se_reduce.bias           False\n",
      "body1.0._blocks.22._se_expand.weight         False\n",
      "body1.0._blocks.22._se_expand.bias           False\n",
      "body1.0._blocks.22._project_conv.weight      False\n",
      "body1.0._blocks.22._bn2.weight               False\n",
      "body1.0._blocks.22._bn2.bias                 False\n",
      "body1.0._blocks.23._expand_conv.weight       False\n",
      "body1.0._blocks.23._bn0.weight               False\n",
      "body1.0._blocks.23._bn0.bias                 False\n",
      "body1.0._blocks.23._depthwise_conv.weight    False\n",
      "body1.0._blocks.23._bn1.weight               False\n",
      "body1.0._blocks.23._bn1.bias                 False\n",
      "body1.0._blocks.23._se_reduce.weight         False\n",
      "body1.0._blocks.23._se_reduce.bias           False\n",
      "body1.0._blocks.23._se_expand.weight         False\n",
      "body1.0._blocks.23._se_expand.bias           False\n",
      "body1.0._blocks.23._project_conv.weight      False\n",
      "body1.0._blocks.23._bn2.weight               False\n",
      "body1.0._blocks.23._bn2.bias                 False\n",
      "body1.0._blocks.24._expand_conv.weight       False\n",
      "body1.0._blocks.24._bn0.weight               False\n",
      "body1.0._blocks.24._bn0.bias                 False\n",
      "body1.0._blocks.24._depthwise_conv.weight    False\n",
      "body1.0._blocks.24._bn1.weight               False\n",
      "body1.0._blocks.24._bn1.bias                 False\n",
      "body1.0._blocks.24._se_reduce.weight         False\n",
      "body1.0._blocks.24._se_reduce.bias           False\n",
      "body1.0._blocks.24._se_expand.weight         False\n",
      "body1.0._blocks.24._se_expand.bias           False\n",
      "body1.0._blocks.24._project_conv.weight      False\n",
      "body1.0._blocks.24._bn2.weight               False\n",
      "body1.0._blocks.24._bn2.bias                 False\n",
      "body1.0._blocks.25._expand_conv.weight       False\n",
      "body1.0._blocks.25._bn0.weight               False\n",
      "body1.0._blocks.25._bn0.bias                 False\n",
      "body1.0._blocks.25._depthwise_conv.weight    False\n",
      "body1.0._blocks.25._bn1.weight               False\n",
      "body1.0._blocks.25._bn1.bias                 False\n",
      "body1.0._blocks.25._se_reduce.weight         False\n",
      "body1.0._blocks.25._se_reduce.bias           False\n",
      "body1.0._blocks.25._se_expand.weight         False\n",
      "body1.0._blocks.25._se_expand.bias           False\n",
      "body1.0._blocks.25._project_conv.weight      False\n",
      "body1.0._blocks.25._bn2.weight               False\n",
      "body1.0._blocks.25._bn2.bias                 False\n",
      "body1.0._conv_head.weight                    False\n",
      "body1.0._bn1.weight                          False\n",
      "body1.0._bn1.bias                            False\n",
      "body2.emb_ctint.weight                       True\n",
      "body2.emb_pgint.weight                       True\n",
      "body2.emb_expint.weight                      True\n",
      "head.0.weight                                True\n",
      "head.0.bias                                  True\n",
      "head.2.weight                                True\n",
      "head.2.bias                                  True\n",
      "head.4.weight                                True\n",
      "head.4.bias                                  True\n",
      "head.6.weight                                True\n",
      "head.6.bias                                  True\n",
      "head.8.weight                                True\n",
      "head.8.bias                                  True\n",
      "head.10.weight                               True\n",
      "head.10.bias                                 True\n",
      "head.12.weight                               True\n",
      "head.12.bias                                 True\n",
      "head.14.weight                               True\n",
      "head.14.bias                                 True\n",
      "adacos.W                                     True\n"
     ]
    }
   ],
   "source": [
    "check_rg() # check where trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T18:00:00.571763Z",
     "start_time": "2019-08-22T18:00:00.501352Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.save('effnet/adacos_efficientnet_b3_e080CM185-230_190807_best_body1_full');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T18:00:08.756103Z",
     "start_time": "2019-08-22T18:00:08.652933Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.load('effnet/adacos_efficientnet_b3_e080CM185-230_190807_best_body1_full');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T17:56:23.934835Z",
     "start_time": "2019-08-22T17:56:09.444280Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n",
      "Min numerical gradient: 6.31E-07\n",
      "Min loss divided by 10: 2.75E-07\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot(suggestion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T18:10:28.796701Z",
     "start_time": "2019-08-22T18:00:12.786961Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.845868</td>\n",
       "      <td>4.971187</td>\n",
       "      <td>0.085487</td>\n",
       "      <td>10:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(1, lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T18:10:53.802730Z",
     "start_time": "2019-08-22T18:10:53.755573Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "body1.0._conv_stem.weight                    False\n",
      "body1.0._bn0.weight                          False\n",
      "body1.0._bn0.bias                            False\n",
      "body1.0._blocks.0._depthwise_conv.weight     False\n",
      "body1.0._blocks.0._bn1.weight                False\n",
      "body1.0._blocks.0._bn1.bias                  False\n",
      "body1.0._blocks.0._se_reduce.weight          False\n",
      "body1.0._blocks.0._se_reduce.bias            False\n",
      "body1.0._blocks.0._se_expand.weight          False\n",
      "body1.0._blocks.0._se_expand.bias            False\n",
      "body1.0._blocks.0._project_conv.weight       False\n",
      "body1.0._blocks.0._bn2.weight                False\n",
      "body1.0._blocks.0._bn2.bias                  False\n",
      "body1.0._blocks.1._depthwise_conv.weight     False\n",
      "body1.0._blocks.1._bn1.weight                False\n",
      "body1.0._blocks.1._bn1.bias                  False\n",
      "body1.0._blocks.1._se_reduce.weight          False\n",
      "body1.0._blocks.1._se_reduce.bias            False\n",
      "body1.0._blocks.1._se_expand.weight          False\n",
      "body1.0._blocks.1._se_expand.bias            False\n",
      "body1.0._blocks.1._project_conv.weight       False\n",
      "body1.0._blocks.1._bn2.weight                False\n",
      "body1.0._blocks.1._bn2.bias                  False\n",
      "body1.0._blocks.2._expand_conv.weight        False\n",
      "body1.0._blocks.2._bn0.weight                False\n",
      "body1.0._blocks.2._bn0.bias                  False\n",
      "body1.0._blocks.2._depthwise_conv.weight     False\n",
      "body1.0._blocks.2._bn1.weight                False\n",
      "body1.0._blocks.2._bn1.bias                  False\n",
      "body1.0._blocks.2._se_reduce.weight          False\n",
      "body1.0._blocks.2._se_reduce.bias            False\n",
      "body1.0._blocks.2._se_expand.weight          False\n",
      "body1.0._blocks.2._se_expand.bias            False\n",
      "body1.0._blocks.2._project_conv.weight       False\n",
      "body1.0._blocks.2._bn2.weight                False\n",
      "body1.0._blocks.2._bn2.bias                  False\n",
      "body1.0._blocks.3._expand_conv.weight        False\n",
      "body1.0._blocks.3._bn0.weight                False\n",
      "body1.0._blocks.3._bn0.bias                  False\n",
      "body1.0._blocks.3._depthwise_conv.weight     False\n",
      "body1.0._blocks.3._bn1.weight                False\n",
      "body1.0._blocks.3._bn1.bias                  False\n",
      "body1.0._blocks.3._se_reduce.weight          False\n",
      "body1.0._blocks.3._se_reduce.bias            False\n",
      "body1.0._blocks.3._se_expand.weight          False\n",
      "body1.0._blocks.3._se_expand.bias            False\n",
      "body1.0._blocks.3._project_conv.weight       False\n",
      "body1.0._blocks.3._bn2.weight                False\n",
      "body1.0._blocks.3._bn2.bias                  False\n",
      "body1.0._blocks.4._expand_conv.weight        False\n",
      "body1.0._blocks.4._bn0.weight                False\n",
      "body1.0._blocks.4._bn0.bias                  False\n",
      "body1.0._blocks.4._depthwise_conv.weight     False\n",
      "body1.0._blocks.4._bn1.weight                False\n",
      "body1.0._blocks.4._bn1.bias                  False\n",
      "body1.0._blocks.4._se_reduce.weight          False\n",
      "body1.0._blocks.4._se_reduce.bias            False\n",
      "body1.0._blocks.4._se_expand.weight          False\n",
      "body1.0._blocks.4._se_expand.bias            False\n",
      "body1.0._blocks.4._project_conv.weight       False\n",
      "body1.0._blocks.4._bn2.weight                False\n",
      "body1.0._blocks.4._bn2.bias                  False\n",
      "body1.0._blocks.5._expand_conv.weight        False\n",
      "body1.0._blocks.5._bn0.weight                False\n",
      "body1.0._blocks.5._bn0.bias                  False\n",
      "body1.0._blocks.5._depthwise_conv.weight     False\n",
      "body1.0._blocks.5._bn1.weight                False\n",
      "body1.0._blocks.5._bn1.bias                  False\n",
      "body1.0._blocks.5._se_reduce.weight          False\n",
      "body1.0._blocks.5._se_reduce.bias            False\n",
      "body1.0._blocks.5._se_expand.weight          False\n",
      "body1.0._blocks.5._se_expand.bias            False\n",
      "body1.0._blocks.5._project_conv.weight       False\n",
      "body1.0._blocks.5._bn2.weight                False\n",
      "body1.0._blocks.5._bn2.bias                  False\n",
      "body1.0._blocks.6._expand_conv.weight        False\n",
      "body1.0._blocks.6._bn0.weight                False\n",
      "body1.0._blocks.6._bn0.bias                  False\n",
      "body1.0._blocks.6._depthwise_conv.weight     False\n",
      "body1.0._blocks.6._bn1.weight                False\n",
      "body1.0._blocks.6._bn1.bias                  False\n",
      "body1.0._blocks.6._se_reduce.weight          False\n",
      "body1.0._blocks.6._se_reduce.bias            False\n",
      "body1.0._blocks.6._se_expand.weight          False\n",
      "body1.0._blocks.6._se_expand.bias            False\n",
      "body1.0._blocks.6._project_conv.weight       False\n",
      "body1.0._blocks.6._bn2.weight                False\n",
      "body1.0._blocks.6._bn2.bias                  False\n",
      "body1.0._blocks.7._expand_conv.weight        False\n",
      "body1.0._blocks.7._bn0.weight                False\n",
      "body1.0._blocks.7._bn0.bias                  False\n",
      "body1.0._blocks.7._depthwise_conv.weight     False\n",
      "body1.0._blocks.7._bn1.weight                False\n",
      "body1.0._blocks.7._bn1.bias                  False\n",
      "body1.0._blocks.7._se_reduce.weight          False\n",
      "body1.0._blocks.7._se_reduce.bias            False\n",
      "body1.0._blocks.7._se_expand.weight          False\n",
      "body1.0._blocks.7._se_expand.bias            False\n",
      "body1.0._blocks.7._project_conv.weight       False\n",
      "body1.0._blocks.7._bn2.weight                False\n",
      "body1.0._blocks.7._bn2.bias                  False\n",
      "body1.0._blocks.8._expand_conv.weight        False\n",
      "body1.0._blocks.8._bn0.weight                False\n",
      "body1.0._blocks.8._bn0.bias                  False\n",
      "body1.0._blocks.8._depthwise_conv.weight     False\n",
      "body1.0._blocks.8._bn1.weight                False\n",
      "body1.0._blocks.8._bn1.bias                  False\n",
      "body1.0._blocks.8._se_reduce.weight          False\n",
      "body1.0._blocks.8._se_reduce.bias            False\n",
      "body1.0._blocks.8._se_expand.weight          False\n",
      "body1.0._blocks.8._se_expand.bias            False\n",
      "body1.0._blocks.8._project_conv.weight       False\n",
      "body1.0._blocks.8._bn2.weight                False\n",
      "body1.0._blocks.8._bn2.bias                  False\n",
      "body1.0._blocks.9._expand_conv.weight        False\n",
      "body1.0._blocks.9._bn0.weight                False\n",
      "body1.0._blocks.9._bn0.bias                  False\n",
      "body1.0._blocks.9._depthwise_conv.weight     False\n",
      "body1.0._blocks.9._bn1.weight                False\n",
      "body1.0._blocks.9._bn1.bias                  False\n",
      "body1.0._blocks.9._se_reduce.weight          False\n",
      "body1.0._blocks.9._se_reduce.bias            False\n",
      "body1.0._blocks.9._se_expand.weight          False\n",
      "body1.0._blocks.9._se_expand.bias            False\n",
      "body1.0._blocks.9._project_conv.weight       False\n",
      "body1.0._blocks.9._bn2.weight                False\n",
      "body1.0._blocks.9._bn2.bias                  False\n",
      "body1.0._blocks.10._expand_conv.weight       False\n",
      "body1.0._blocks.10._bn0.weight               False\n",
      "body1.0._blocks.10._bn0.bias                 False\n",
      "body1.0._blocks.10._depthwise_conv.weight    False\n",
      "body1.0._blocks.10._bn1.weight               False\n",
      "body1.0._blocks.10._bn1.bias                 False\n",
      "body1.0._blocks.10._se_reduce.weight         False\n",
      "body1.0._blocks.10._se_reduce.bias           False\n",
      "body1.0._blocks.10._se_expand.weight         False\n",
      "body1.0._blocks.10._se_expand.bias           False\n",
      "body1.0._blocks.10._project_conv.weight      False\n",
      "body1.0._blocks.10._bn2.weight               False\n",
      "body1.0._blocks.10._bn2.bias                 False\n",
      "body1.0._blocks.11._expand_conv.weight       False\n",
      "body1.0._blocks.11._bn0.weight               False\n",
      "body1.0._blocks.11._bn0.bias                 False\n",
      "body1.0._blocks.11._depthwise_conv.weight    False\n",
      "body1.0._blocks.11._bn1.weight               False\n",
      "body1.0._blocks.11._bn1.bias                 False\n",
      "body1.0._blocks.11._se_reduce.weight         False\n",
      "body1.0._blocks.11._se_reduce.bias           False\n",
      "body1.0._blocks.11._se_expand.weight         False\n",
      "body1.0._blocks.11._se_expand.bias           False\n",
      "body1.0._blocks.11._project_conv.weight      False\n",
      "body1.0._blocks.11._bn2.weight               False\n",
      "body1.0._blocks.11._bn2.bias                 False\n",
      "body1.0._blocks.12._expand_conv.weight       False\n",
      "body1.0._blocks.12._bn0.weight               False\n",
      "body1.0._blocks.12._bn0.bias                 False\n",
      "body1.0._blocks.12._depthwise_conv.weight    False\n",
      "body1.0._blocks.12._bn1.weight               False\n",
      "body1.0._blocks.12._bn1.bias                 False\n",
      "body1.0._blocks.12._se_reduce.weight         False\n",
      "body1.0._blocks.12._se_reduce.bias           False\n",
      "body1.0._blocks.12._se_expand.weight         False\n",
      "body1.0._blocks.12._se_expand.bias           False\n",
      "body1.0._blocks.12._project_conv.weight      False\n",
      "body1.0._blocks.12._bn2.weight               False\n",
      "body1.0._blocks.12._bn2.bias                 False\n",
      "body1.0._blocks.13._expand_conv.weight       False\n",
      "body1.0._blocks.13._bn0.weight               False\n",
      "body1.0._blocks.13._bn0.bias                 False\n",
      "body1.0._blocks.13._depthwise_conv.weight    False\n",
      "body1.0._blocks.13._bn1.weight               False\n",
      "body1.0._blocks.13._bn1.bias                 False\n",
      "body1.0._blocks.13._se_reduce.weight         False\n",
      "body1.0._blocks.13._se_reduce.bias           False\n",
      "body1.0._blocks.13._se_expand.weight         False\n",
      "body1.0._blocks.13._se_expand.bias           False\n",
      "body1.0._blocks.13._project_conv.weight      False\n",
      "body1.0._blocks.13._bn2.weight               False\n",
      "body1.0._blocks.13._bn2.bias                 False\n",
      "body1.0._blocks.14._expand_conv.weight       False\n",
      "body1.0._blocks.14._bn0.weight               False\n",
      "body1.0._blocks.14._bn0.bias                 False\n",
      "body1.0._blocks.14._depthwise_conv.weight    False\n",
      "body1.0._blocks.14._bn1.weight               False\n",
      "body1.0._blocks.14._bn1.bias                 False\n",
      "body1.0._blocks.14._se_reduce.weight         False\n",
      "body1.0._blocks.14._se_reduce.bias           False\n",
      "body1.0._blocks.14._se_expand.weight         False\n",
      "body1.0._blocks.14._se_expand.bias           False\n",
      "body1.0._blocks.14._project_conv.weight      False\n",
      "body1.0._blocks.14._bn2.weight               False\n",
      "body1.0._blocks.14._bn2.bias                 False\n",
      "body1.0._blocks.15._expand_conv.weight       False\n",
      "body1.0._blocks.15._bn0.weight               False\n",
      "body1.0._blocks.15._bn0.bias                 False\n",
      "body1.0._blocks.15._depthwise_conv.weight    False\n",
      "body1.0._blocks.15._bn1.weight               False\n",
      "body1.0._blocks.15._bn1.bias                 False\n",
      "body1.0._blocks.15._se_reduce.weight         False\n",
      "body1.0._blocks.15._se_reduce.bias           False\n",
      "body1.0._blocks.15._se_expand.weight         False\n",
      "body1.0._blocks.15._se_expand.bias           False\n",
      "body1.0._blocks.15._project_conv.weight      False\n",
      "body1.0._blocks.15._bn2.weight               False\n",
      "body1.0._blocks.15._bn2.bias                 False\n",
      "body1.0._blocks.16._expand_conv.weight       False\n",
      "body1.0._blocks.16._bn0.weight               False\n",
      "body1.0._blocks.16._bn0.bias                 False\n",
      "body1.0._blocks.16._depthwise_conv.weight    False\n",
      "body1.0._blocks.16._bn1.weight               False\n",
      "body1.0._blocks.16._bn1.bias                 False\n",
      "body1.0._blocks.16._se_reduce.weight         False\n",
      "body1.0._blocks.16._se_reduce.bias           False\n",
      "body1.0._blocks.16._se_expand.weight         False\n",
      "body1.0._blocks.16._se_expand.bias           False\n",
      "body1.0._blocks.16._project_conv.weight      False\n",
      "body1.0._blocks.16._bn2.weight               False\n",
      "body1.0._blocks.16._bn2.bias                 False\n",
      "body1.0._blocks.17._expand_conv.weight       False\n",
      "body1.0._blocks.17._bn0.weight               False\n",
      "body1.0._blocks.17._bn0.bias                 False\n",
      "body1.0._blocks.17._depthwise_conv.weight    False\n",
      "body1.0._blocks.17._bn1.weight               False\n",
      "body1.0._blocks.17._bn1.bias                 False\n",
      "body1.0._blocks.17._se_reduce.weight         False\n",
      "body1.0._blocks.17._se_reduce.bias           False\n",
      "body1.0._blocks.17._se_expand.weight         False\n",
      "body1.0._blocks.17._se_expand.bias           False\n",
      "body1.0._blocks.17._project_conv.weight      False\n",
      "body1.0._blocks.17._bn2.weight               False\n",
      "body1.0._blocks.17._bn2.bias                 False\n",
      "body1.0._blocks.18._expand_conv.weight       False\n",
      "body1.0._blocks.18._bn0.weight               False\n",
      "body1.0._blocks.18._bn0.bias                 False\n",
      "body1.0._blocks.18._depthwise_conv.weight    False\n",
      "body1.0._blocks.18._bn1.weight               False\n",
      "body1.0._blocks.18._bn1.bias                 False\n",
      "body1.0._blocks.18._se_reduce.weight         False\n",
      "body1.0._blocks.18._se_reduce.bias           False\n",
      "body1.0._blocks.18._se_expand.weight         False\n",
      "body1.0._blocks.18._se_expand.bias           False\n",
      "body1.0._blocks.18._project_conv.weight      False\n",
      "body1.0._blocks.18._bn2.weight               False\n",
      "body1.0._blocks.18._bn2.bias                 False\n",
      "body1.0._blocks.19._expand_conv.weight       False\n",
      "body1.0._blocks.19._bn0.weight               False\n",
      "body1.0._blocks.19._bn0.bias                 False\n",
      "body1.0._blocks.19._depthwise_conv.weight    False\n",
      "body1.0._blocks.19._bn1.weight               False\n",
      "body1.0._blocks.19._bn1.bias                 False\n",
      "body1.0._blocks.19._se_reduce.weight         False\n",
      "body1.0._blocks.19._se_reduce.bias           False\n",
      "body1.0._blocks.19._se_expand.weight         False\n",
      "body1.0._blocks.19._se_expand.bias           False\n",
      "body1.0._blocks.19._project_conv.weight      False\n",
      "body1.0._blocks.19._bn2.weight               False\n",
      "body1.0._blocks.19._bn2.bias                 False\n",
      "body1.0._blocks.20._expand_conv.weight       False\n",
      "body1.0._blocks.20._bn0.weight               False\n",
      "body1.0._blocks.20._bn0.bias                 False\n",
      "body1.0._blocks.20._depthwise_conv.weight    False\n",
      "body1.0._blocks.20._bn1.weight               False\n",
      "body1.0._blocks.20._bn1.bias                 False\n",
      "body1.0._blocks.20._se_reduce.weight         False\n",
      "body1.0._blocks.20._se_reduce.bias           False\n",
      "body1.0._blocks.20._se_expand.weight         False\n",
      "body1.0._blocks.20._se_expand.bias           False\n",
      "body1.0._blocks.20._project_conv.weight      False\n",
      "body1.0._blocks.20._bn2.weight               False\n",
      "body1.0._blocks.20._bn2.bias                 False\n",
      "body1.0._blocks.21._expand_conv.weight       False\n",
      "body1.0._blocks.21._bn0.weight               False\n",
      "body1.0._blocks.21._bn0.bias                 False\n",
      "body1.0._blocks.21._depthwise_conv.weight    False\n",
      "body1.0._blocks.21._bn1.weight               False\n",
      "body1.0._blocks.21._bn1.bias                 False\n",
      "body1.0._blocks.21._se_reduce.weight         False\n",
      "body1.0._blocks.21._se_reduce.bias           False\n",
      "body1.0._blocks.21._se_expand.weight         False\n",
      "body1.0._blocks.21._se_expand.bias           False\n",
      "body1.0._blocks.21._project_conv.weight      False\n",
      "body1.0._blocks.21._bn2.weight               False\n",
      "body1.0._blocks.21._bn2.bias                 False\n",
      "body1.0._blocks.22._expand_conv.weight       False\n",
      "body1.0._blocks.22._bn0.weight               False\n",
      "body1.0._blocks.22._bn0.bias                 False\n",
      "body1.0._blocks.22._depthwise_conv.weight    False\n",
      "body1.0._blocks.22._bn1.weight               False\n",
      "body1.0._blocks.22._bn1.bias                 False\n",
      "body1.0._blocks.22._se_reduce.weight         False\n",
      "body1.0._blocks.22._se_reduce.bias           False\n",
      "body1.0._blocks.22._se_expand.weight         False\n",
      "body1.0._blocks.22._se_expand.bias           False\n",
      "body1.0._blocks.22._project_conv.weight      False\n",
      "body1.0._blocks.22._bn2.weight               False\n",
      "body1.0._blocks.22._bn2.bias                 False\n",
      "body1.0._blocks.23._expand_conv.weight       False\n",
      "body1.0._blocks.23._bn0.weight               False\n",
      "body1.0._blocks.23._bn0.bias                 False\n",
      "body1.0._blocks.23._depthwise_conv.weight    False\n",
      "body1.0._blocks.23._bn1.weight               False\n",
      "body1.0._blocks.23._bn1.bias                 False\n",
      "body1.0._blocks.23._se_reduce.weight         False\n",
      "body1.0._blocks.23._se_reduce.bias           False\n",
      "body1.0._blocks.23._se_expand.weight         False\n",
      "body1.0._blocks.23._se_expand.bias           False\n",
      "body1.0._blocks.23._project_conv.weight      False\n",
      "body1.0._blocks.23._bn2.weight               False\n",
      "body1.0._blocks.23._bn2.bias                 False\n",
      "body1.0._blocks.24._expand_conv.weight       False\n",
      "body1.0._blocks.24._bn0.weight               False\n",
      "body1.0._blocks.24._bn0.bias                 False\n",
      "body1.0._blocks.24._depthwise_conv.weight    False\n",
      "body1.0._blocks.24._bn1.weight               False\n",
      "body1.0._blocks.24._bn1.bias                 False\n",
      "body1.0._blocks.24._se_reduce.weight         False\n",
      "body1.0._blocks.24._se_reduce.bias           False\n",
      "body1.0._blocks.24._se_expand.weight         False\n",
      "body1.0._blocks.24._se_expand.bias           False\n",
      "body1.0._blocks.24._project_conv.weight      False\n",
      "body1.0._blocks.24._bn2.weight               False\n",
      "body1.0._blocks.24._bn2.bias                 False\n",
      "body1.0._blocks.25._expand_conv.weight       False\n",
      "body1.0._blocks.25._bn0.weight               False\n",
      "body1.0._blocks.25._bn0.bias                 False\n",
      "body1.0._blocks.25._depthwise_conv.weight    False\n",
      "body1.0._blocks.25._bn1.weight               False\n",
      "body1.0._blocks.25._bn1.bias                 False\n",
      "body1.0._blocks.25._se_reduce.weight         False\n",
      "body1.0._blocks.25._se_reduce.bias           False\n",
      "body1.0._blocks.25._se_expand.weight         False\n",
      "body1.0._blocks.25._se_expand.bias           False\n",
      "body1.0._blocks.25._project_conv.weight      False\n",
      "body1.0._blocks.25._bn2.weight               False\n",
      "body1.0._blocks.25._bn2.bias                 False\n",
      "body1.0._conv_head.weight                    False\n",
      "body1.0._bn1.weight                          False\n",
      "body1.0._bn1.bias                            False\n",
      "body2.emb_ctint.weight                       True\n",
      "body2.emb_pgint.weight                       True\n",
      "body2.emb_expint.weight                      True\n",
      "head.0.weight                                True\n",
      "head.0.bias                                  True\n",
      "head.2.weight                                True\n",
      "head.2.bias                                  True\n",
      "head.4.weight                                True\n",
      "head.4.bias                                  True\n",
      "head.6.weight                                True\n",
      "head.6.bias                                  True\n",
      "head.8.weight                                True\n",
      "head.8.bias                                  True\n",
      "head.10.weight                               True\n",
      "head.10.bias                                 True\n",
      "head.12.weight                               True\n",
      "head.12.bias                                 True\n",
      "head.14.weight                               True\n",
      "head.14.bias                                 True\n",
      "adacos.W                                     True\n"
     ]
    }
   ],
   "source": [
    "check_rg() # check where trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-08-22T18:11:03.690Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='9', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/9 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='576' class='' max='3597', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      16.01% [576/3597 01:22<07:13 4.7754]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(9, max_lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T06:49:09.673485Z",
     "start_time": "2019-08-19T06:49:09.367857Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T16:30:17.021138Z",
     "start_time": "2019-08-15T16:30:17.010959Z"
    }
   },
   "outputs": [],
   "source": [
    "#learn.recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T06:49:30.261754Z",
     "start_time": "2019-08-19T06:49:30.040823Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.recorder.plot_lr(show_moms=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T06:49:35.980325Z",
     "start_time": "2019-08-19T06:49:35.871946Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.save('effnet/adacos_efficientnet_b4_ct_pg_exp_e004_190819')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T06:49:36.880936Z",
     "start_time": "2019-08-19T06:49:36.726370Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.load('effnet/adacos_efficientnet_b4_ct_pg_exp_e004_190819');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T06:49:38.147770Z",
     "start_time": "2019-08-19T06:49:38.015929Z"
    }
   },
   "outputs": [],
   "source": [
    "# compare initialized input stage to pretrain input stage\n",
    "show_input_stage_weights(new_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T06:49:39.086185Z",
     "start_time": "2019-08-19T06:49:38.957919Z"
    }
   },
   "outputs": [],
   "source": [
    "show_input_stage_weights(learn.model.body1[0]._conv_stem.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T04:02:10.796823Z",
     "start_time": "2019-08-21T04:02:10.777608Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T04:02:11.784383Z",
     "start_time": "2019-08-21T04:02:11.750270Z"
    }
   },
   "outputs": [],
   "source": [
    "check_rg() # check where trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T06:50:40.885522Z",
     "start_time": "2019-08-19T06:50:11.801553Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot(suggestion=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Training #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T17:24:37.862580Z",
     "start_time": "2019-08-15T17:24:37.634563Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#learn.load('effnet/adacos_efficientnet_b4_ct_pg_exp_e001_190815');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-19T06:52:10.458872Z",
     "start_time": "2019-08-19T06:52:10.442148Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "savem = SaveModelCallback(learn, every='improvement', monitor='accuracy', \n",
    "                          name='effnet/adacos_efficientnet_b4_ct_pg_exp_e004-078_190819_best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T03:56:13.165445Z",
     "start_time": "2019-08-19T06:52:23.937881Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(155, max_lr=1e-4, callbacks=[savem])\n",
    "#learn.fit_one_cycle(155, max_lr=1e-3, div_factor=500, callbacks=[savem])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T03:56:21.328994Z",
     "start_time": "2019-08-21T03:56:19.455210Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T03:56:27.512386Z",
     "start_time": "2019-08-21T03:56:27.397993Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T03:56:32.074932Z",
     "start_time": "2019-08-21T03:56:31.620504Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.recorder.plot_lr(show_moms=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T03:58:49.357528Z",
     "start_time": "2019-08-21T03:58:49.168844Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save('effnet/adacos_efficientnet_b4_ct_pg_exp_e078_190815')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T04:02:26.970309Z",
     "start_time": "2019-08-21T04:02:26.731605Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.load('effnet/adacos_efficientnet_b4_ct_pg_exp_e078_190815');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T04:02:34.270134Z",
     "start_time": "2019-08-21T04:02:34.135253Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# compare initialized input stage to pretrain input stage\n",
    "show_input_stage_weights(new_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T04:02:35.316985Z",
     "start_time": "2019-08-21T04:02:35.188976Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "show_input_stage_weights(learn.model.body1[0]._conv_stem.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T04:03:11.478049Z",
     "start_time": "2019-08-21T04:02:41.585070Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot(suggestion=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Training #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T17:24:37.862580Z",
     "start_time": "2019-08-15T17:24:37.634563Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#learn.load('effnet/adacos_efficientnet_b4_ct_pg_exp_e001_190815');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T04:05:46.931790Z",
     "start_time": "2019-08-21T04:05:46.918885Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "savem = SaveModelCallback(learn, every='improvement', monitor='accuracy', \n",
    "                          name='effnet/adacos_efficientnet_b4_ct_pg_exp_e078-118_190821_best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T16:38:58.180746Z",
     "start_time": "2019-08-21T04:05:49.604193Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(40, max_lr=1e-3, callbacks=[savem])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T16:38:58.183631Z",
     "start_time": "2019-08-21T04:06:31.769Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T16:38:58.184576Z",
     "start_time": "2019-08-21T04:06:33.160Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T16:38:58.185225Z",
     "start_time": "2019-08-21T04:06:33.549Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.recorder.plot_lr(show_moms=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T16:38:58.185932Z",
     "start_time": "2019-08-21T04:06:34.563Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save('effnet/adacos_efficientnet_b4_ct_pg_exp_e118_190821')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-21T16:38:58.186550Z",
     "start_time": "2019-08-21T04:06:35.489Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.load('effnet/adacos_efficientnet_b4_ct_pg_exp_e118_190821');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### CutMix Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T04:28:01.356356Z",
     "start_time": "2019-08-13T04:28:01.339573Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.cutmix();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T04:29:43.607073Z",
     "start_time": "2019-08-13T04:28:07.648896Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot(suggestion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T14:00:11.716671Z",
     "start_time": "2019-08-13T04:29:57.663707Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(90, max_lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T14:00:12.039759Z",
     "start_time": "2019-08-13T14:00:11.719649Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T14:00:12.194476Z",
     "start_time": "2019-08-13T14:00:12.041148Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T14:00:12.411609Z",
     "start_time": "2019-08-13T14:00:12.195653Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.recorder.plot_lr(show_moms=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T14:00:12.616874Z",
     "start_time": "2019-08-13T14:00:12.412784Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.save('resnet50/adacos_se_xresnet50_ct_pg_128e073CM090_190813')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T18:28:20.471903Z",
     "start_time": "2019-08-13T18:28:20.196540Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.load('resnet50/adacos_se_xresnet50_ct_pg_128e073CM090_190813');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T14:01:48.042064Z",
     "start_time": "2019-08-13T14:00:12.810764Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot(suggestion=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Custom Blend CutMix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T19:56:11.757522Z",
     "start_time": "2019-08-07T19:56:11.740738Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "    'size': .05, \n",
    "    'alpha': .2,\n",
    "    'blend_type': 'zero', \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T19:56:12.649451Z",
     "start_time": "2019-08-07T19:56:12.632896Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.blend(**kwargs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T17:58:07.072760Z",
     "start_time": "2019-07-26T17:58:04.469884Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(4, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-26T17:58:24.633769Z",
     "start_time": "2019-07-26T17:58:14.786359Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Define transform function\n",
    "tfm_fn = partial(blend, blend_type='cut', same_size=False)\n",
    "\n",
    "#Define schedule parameters\n",
    "sch_param=['size', 'fixed_proba']\n",
    "sch_val = [(.05, 2), .2 ]  # You can also enter a list of tuples\n",
    "sch_iter = [(0., .3), (0., .7)]  # And a tuple with start and end iteration percentage\n",
    "sch_func = [annealing_cos, partial(cosine_annealing, pct_start=.3)] # options: None = annealing_linear, annealing_cos, cosine_annealing\n",
    "plot = True\n",
    "test = True  # if True this will stop training in the first mini-batch\n",
    "sch_tfm_cb = partial(TfmScheduler, tfm_fn=tfm_fn, sch_param=sch_param, sch_val=sch_val, \n",
    "                      sch_iter=sch_iter, sch_func=sch_func, plot=plot, test=test)\n",
    "learn.callback_fns.append(sch_tfm_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Classifcation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T17:19:05.357210Z",
     "start_time": "2019-07-29T17:19:05.097795Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.load('resnet50/adacos_se_xresnet50c_val-split-v2_128e040-256e106CMe110_20190729');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T15:53:15.569726Z",
     "start_time": "2019-08-05T15:49:04.679301Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get prediction of test dataset\n",
    "preds, _ = learn.get_preds(ds_type=DatasetType.Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T15:53:15.588091Z",
     "start_time": "2019-08-05T15:53:15.570964Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# check length\n",
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T15:53:15.606096Z",
     "start_time": "2019-08-05T15:53:15.589216Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get the categories\n",
    "preds_cat = preds.argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T15:53:15.617278Z",
     "start_time": "2019-08-05T15:53:15.607162Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get the names\n",
    "preds_names = learn.data.test_ds.x.items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T15:53:15.662341Z",
     "start_time": "2019-08-05T15:53:15.618160Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# without site\n",
    "#preds_names = [x.split('/')[1]+'_'+x.split('/')[2][-1]+'_'+x.split('/')[3][:3] for x in preds_names]\n",
    "\n",
    "# with site\n",
    "preds_names = [x.split('/')[1]+'_'+x.split('/')[2][-1]+'_'+x.split('/')[3] for x in preds_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T15:53:15.679656Z",
     "start_time": "2019-08-05T15:53:15.663311Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_preds = pd.DataFrame({'id_code_site': preds_names, 'sirna': preds_cat})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T15:53:15.700072Z",
     "start_time": "2019-08-05T15:53:15.680652Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get id_code without site\n",
    "df_preds['id_code'] = df_preds['id_code_site'].apply(lambda x: x[:-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T15:53:18.270083Z",
     "start_time": "2019-08-05T15:53:15.701461Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get row indices with the same/not the same the prediction for both sites\n",
    "idx = [] # indices with the same prediction\n",
    "idx_notsame = [] # indices with not the same prediction\n",
    "for i, r in enumerate(df_preds.sort_values('id_code').iterrows()):\n",
    "    if i % 2:\n",
    "        # distance from row 2 is \n",
    "        if pred == r[1]['sirna']:\n",
    "            idx.append(r[0])\n",
    "        else:\n",
    "            #idx.append(r[0]) # always append idx until we come up with something better\n",
    "            idx.append(idx_row_before)\n",
    "            idx_notsame.append(idx_row_before) # get the first rows of the pairs that are not the same\n",
    "    else:\n",
    "        # save dist from row 1 for comparison in next iteration\n",
    "        pred = r[1]['sirna']\n",
    "        idx_row_before = r[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T15:53:18.281892Z",
     "start_time": "2019-08-05T15:53:18.271104Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(idx), len(idx_notsame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T15:53:18.293331Z",
     "start_time": "2019-08-05T15:53:18.282869Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "idx[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T15:53:18.340274Z",
     "start_time": "2019-08-05T15:53:18.294170Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_preds.sort_values('id_code').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T15:53:18.350973Z",
     "start_time": "2019-08-05T15:53:18.341152Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#df_preds.loc[idx,['id_code','sirna']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T15:53:18.361693Z",
     "start_time": "2019-08-05T15:53:18.351798Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 'effnet/adacos_efficientnet_b3_e080CM112_190805'\n",
    "model = 'metriclearn_efficientnet_b3_e080CM112_190805'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T15:53:18.452880Z",
     "start_time": "2019-08-05T15:53:18.362621Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_preds.loc[idx,['id_code','sirna']].to_csv('sub/'+model+'.csv.gz', index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T15:53:24.296150Z",
     "start_time": "2019-08-05T15:53:18.453852Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c recursion-cellular-image-classification -f sub/{model}.csv.gz -m \"{model}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosinus similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full single features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/ducha-aiki/whale-identification-2018/blob/master/reproduce_problems.ipynb\n",
    "# And for test-time augmentation I used following random solution: switch train and val transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T16:23:15.104908Z",
     "start_time": "2019-08-05T16:23:15.091887Z"
    }
   },
   "outputs": [],
   "source": [
    "# extended tfms\n",
    "tfms = get_transforms(do_flip=True, flip_vert=True, \n",
    "                      max_rotate=90.0, max_zoom=1.1, \n",
    "                      max_lighting=0.2, max_warp=0.2, \n",
    "                      p_affine=0.75, p_lighting=0.75, \n",
    "                      xtra_tfms=[color_augmentation()])\n",
    "\n",
    "# crop_pad: https://forums.fast.ai/t/misc-issues/35386/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T17:01:59.202508Z",
     "start_time": "2019-08-14T17:01:59.189103Z"
    }
   },
   "outputs": [],
   "source": [
    "# extended tfms w/o color_augmentation !!!\n",
    "tfms = get_transforms(do_flip=True, flip_vert=True, \n",
    "                      max_rotate=90.0, max_zoom=1.1, \n",
    "                      max_lighting=0.2, max_warp=0.2, \n",
    "                      p_affine=0.75, p_lighting=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T17:01:59.872496Z",
     "start_time": "2019-08-14T17:01:59.855027Z"
    }
   },
   "outputs": [],
   "source": [
    "sz, bs = 256, 8*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T17:02:01.619598Z",
     "start_time": "2019-08-14T17:02:00.526863Z"
    }
   },
   "outputs": [],
   "source": [
    "# VALID SPLIT (incl. tfms)\n",
    "data = (ImageList6Dct.from_df(df_train, path='train')\n",
    "        .split_from_df(col=-1) # split_by_rand_pct()\n",
    "        .label_from_df(cols=-3)\n",
    "        .add_test(ImageList6Dct.from_df(df_test, path='test'))\n",
    "        .transform(tfms, size=sz) # remove size so we get the crop size!\n",
    "        .databunch(bs=bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T17:02:01.950898Z",
     "start_time": "2019-08-14T17:02:01.620653Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageDataBunch;\n",
       "\n",
       "Train: LabelList (57554 items)\n",
       "x: ImageList6Dct\n",
       "Image6Dct (6, 256, 256),Image6Dct (6, 256, 256),Image6Dct (6, 256, 256),Image6Dct (6, 256, 256),Image6Dct (6, 256, 256)\n",
       "y: CategoryList\n",
       "513,840,1020,254,144\n",
       "Path: train;\n",
       "\n",
       "Valid: LabelList (15476 items)\n",
       "x: ImageList6Dct\n",
       "Image6Dct (6, 256, 256),Image6Dct (6, 256, 256),Image6Dct (6, 256, 256),Image6Dct (6, 256, 256),Image6Dct (6, 256, 256)\n",
       "y: CategoryList\n",
       "352,361,503,505,70\n",
       "Path: train;\n",
       "\n",
       "Test: LabelList (39794 items)\n",
       "x: ImageList6Dct\n",
       "Image6Dct (6, 256, 256),Image6Dct (6, 256, 256),Image6Dct (6, 256, 256),Image6Dct (6, 256, 256),Image6Dct (6, 256, 256)\n",
       "y: EmptyLabelList\n",
       ",,,,\n",
       "Path: train"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.normalize([stats_mean, stats_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.train_dl.dl.batch_sampler.sampler = torch.utils.data.SequentialSampler(data.train_ds)\n",
    "#data.train_dl.dl.batch_sampler.drop_last = False\n",
    "#\n",
    "#data.valid_dl.dl.batch_sampler.sampler = torch.utils.data.SequentialSampler(data.valid_ds)\n",
    "#data.valid_dl.dl.batch_sampler.drop_last = False\n",
    "#\n",
    "## DOES WORK TOO FOR TEST DL ??? ??? (Or do we need to set the test dataset to the valid dataset?)\n",
    "#data.test_dl.dl.batch_sampler.sampler = torch.utils.data.SequentialSampler(data.test_ds)\n",
    "#data.test_dl.dl.batch_sampler.drop_last = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T17:02:07.204258Z",
     "start_time": "2019-08-14T17:02:07.170141Z"
    }
   },
   "outputs": [],
   "source": [
    "learn = Learner(data, adacos_se_xresnet50c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T17:02:08.190460Z",
     "start_time": "2019-08-14T17:02:07.943931Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.load('resnet50/adacos_se_xresnet50_ct_pg_128e073CM090_256e050CM050_190814');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-11T09:33:24.432818Z",
     "start_time": "2019-08-11T09:33:24.418339Z"
    }
   },
   "outputs": [],
   "source": [
    "#def get_feats(model, dataloader, cycles=1):\n",
    "#    feats = []\n",
    "#    targs = []\n",
    "#    model.eval()\n",
    "#    with torch.no_grad():\n",
    "#        for i in range(cycles): # for TTA\n",
    "#            for xb, yb in dataloader:\n",
    "#                body_out = model.body(xb)\n",
    "#                head_out = model.head(body_out)\n",
    "#                feats.append(head_out.cpu())\n",
    "#                targs.append(yb.cpu())\n",
    "#    return feats, targs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T17:02:10.465476Z",
     "start_time": "2019-08-14T17:02:10.450884Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_feats(model, dataloader, cycles=1):\n",
    "    feats = []\n",
    "    targs = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(cycles): # for TTA\n",
    "            for xb, yb in dataloader:\n",
    "                xb_img, xb_ctint, xb_pgint, xb_expint = xb\n",
    "                resnet_features = model.body1(xb_img)\n",
    "                int_features = model.body2(xb_ctint, xb_pgint, xb_expint)\n",
    "                features = torch.cat((resnet_features, int_features), dim=-1)\n",
    "                out = model.head(features)\n",
    "                feats.append(out.cpu())\n",
    "                targs.append(yb.cpu())\n",
    "    return feats, targs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T17:08:40.365218Z",
     "start_time": "2019-08-14T17:02:12.491408Z"
    }
   },
   "outputs": [],
   "source": [
    "feats, targs = get_feats(learn.model, learn.data.train_dl)#, cycles=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T17:08:40.434153Z",
     "start_time": "2019-08-14T17:08:40.369850Z"
    }
   },
   "outputs": [],
   "source": [
    "feats = torch.cat(feats, dim=0)\n",
    "targs = torch.cat(targs, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T17:08:40.446184Z",
     "start_time": "2019-08-14T17:08:40.435432Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([57520, 512]), torch.Size([57520]))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats.shape, targs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T17:08:40.551410Z",
     "start_time": "2019-08-14T17:08:40.447309Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save('pred/feats_train.npy', feats)\n",
    "np.save('pred/targs_train.npy', targs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T17:10:07.694310Z",
     "start_time": "2019-08-14T17:08:40.553545Z"
    }
   },
   "outputs": [],
   "source": [
    "feats, targs = get_feats(learn.model, learn.data.valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T17:10:07.716101Z",
     "start_time": "2019-08-14T17:10:07.695484Z"
    }
   },
   "outputs": [],
   "source": [
    "feats = torch.cat(feats, dim=0)\n",
    "targs = torch.cat(targs, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T17:10:07.727825Z",
     "start_time": "2019-08-14T17:10:07.717116Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([15476, 512]), torch.Size([15476, 512]), torch.Size([15476]))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats.shape, feats.shape, targs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T17:10:07.761159Z",
     "start_time": "2019-08-14T17:10:07.729095Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save('pred/feats_valid.npy', feats)\n",
    "np.save('pred/targs_valid.npy', targs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T17:13:56.609566Z",
     "start_time": "2019-08-14T17:10:07.762295Z"
    }
   },
   "outputs": [],
   "source": [
    "feats, targs = get_feats(learn.model, learn.data.test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T17:13:56.632685Z",
     "start_time": "2019-08-14T17:13:56.610856Z"
    }
   },
   "outputs": [],
   "source": [
    "del targs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T17:13:56.668593Z",
     "start_time": "2019-08-14T17:13:56.633726Z"
    }
   },
   "outputs": [],
   "source": [
    "feats = torch.cat(feats, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T17:13:56.680342Z",
     "start_time": "2019-08-14T17:13:56.669559Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([39794, 512])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T17:13:56.748670Z",
     "start_time": "2019-08-14T17:13:56.681299Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save('pred/feats_test.npy', feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Multi-crop features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T17:13:56.759635Z",
     "start_time": "2019-08-14T17:13:56.749651Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# https://github.com/ducha-aiki/whale-identification-2018/blob/master/reproduce_problems.ipynb\n",
    "# And for test-time augmentation I used following random solution: switch train and val transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T17:13:56.790542Z",
     "start_time": "2019-08-14T17:13:56.760651Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_train['test'] = 0\n",
    "df_train['path'] = 'train/'+df_train['path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T16:15:00.275696Z",
     "start_time": "2019-08-13T16:14:58.632Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T16:15:00.276332Z",
     "start_time": "2019-08-13T16:14:59.303Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# add dummy columns for test dataset\n",
    "df_test['path'] = 'test/'+df_test['path']\n",
    "df_test['test'] = 1\n",
    "df_test['sirna'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T16:15:00.276957Z",
     "start_time": "2019-08-13T16:15:00.178Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T16:15:01.099348Z",
     "start_time": "2019-08-13T16:15:01.065671Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_train_test = pd.concat((df_train, df_test), axis=0, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T16:15:03.094129Z",
     "start_time": "2019-08-13T16:15:03.065940Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>experiment</th>\n",
       "      <th>sirna</th>\n",
       "      <th>multi</th>\n",
       "      <th>valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19892</th>\n",
       "      <td>U2OS-05/Plate4/O19_s2</td>\n",
       "      <td>U2OS-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19893</th>\n",
       "      <td>U2OS-05/Plate4/O20_s2</td>\n",
       "      <td>U2OS-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19894</th>\n",
       "      <td>U2OS-05/Plate4/O21_s2</td>\n",
       "      <td>U2OS-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19895</th>\n",
       "      <td>U2OS-05/Plate4/O22_s2</td>\n",
       "      <td>U2OS-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19896</th>\n",
       "      <td>U2OS-05/Plate4/O23_s2</td>\n",
       "      <td>U2OS-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        path experiment  sirna multi  valid\n",
       "19892  U2OS-05/Plate4/O19_s2    U2OS-05    NaN   NaN    NaN\n",
       "19893  U2OS-05/Plate4/O20_s2    U2OS-05    NaN   NaN    NaN\n",
       "19894  U2OS-05/Plate4/O21_s2    U2OS-05    NaN   NaN    NaN\n",
       "19895  U2OS-05/Plate4/O22_s2    U2OS-05    NaN   NaN    NaN\n",
       "19896  U2OS-05/Plate4/O23_s2    U2OS-05    NaN   NaN    NaN"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# reload for train and valid ds\n",
    "df_train = pd.read_csv('full_train_dataset_valid-split-ex_v2_20190727.csv', index_col=0)\n",
    "df_test = pd.read_csv('full_test_dataset_v2_20190727.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T17:44:39.974069Z",
     "start_time": "2019-08-05T17:44:39.962352Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T17:44:42.660744Z",
     "start_time": "2019-08-05T17:44:42.148885Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# test tfms switching for test ds\n",
    "#tfms_switched = (tfms[1], tfms[0])\n",
    "#\n",
    "#data = (ImageList6D.from_df(df_train_test, path='.')\n",
    "#                .split_from_df(col=-1)\n",
    "#                .label_from_df(cols=-4)\n",
    "#                .transform(tfms_switched)#, size=sz) # remove size so we get the crop size!\n",
    "#                .databunch(bs=bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T17:44:50.461048Z",
     "start_time": "2019-08-05T17:44:50.334649Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#data.train_ds[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T17:45:06.299037Z",
     "start_time": "2019-08-05T17:45:06.196917Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#data.valid_ds[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T17:59:54.356878Z",
     "start_time": "2019-08-05T17:59:54.341649Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_dataset(row_pct, col_pct, is_test=False):\n",
    "    # extended tfms\n",
    "    tfms = get_transforms(do_flip=True, flip_vert=True, \n",
    "                          max_rotate=90.0, max_zoom=1.1, \n",
    "                          max_lighting=0.2, max_warp=0.2, \n",
    "                          p_affine=0.75, p_lighting=0.75, \n",
    "                          xtra_tfms=[color_augmentation()])\n",
    "    \n",
    "    # change \"crop_pad\" from get_transforms to \"crop\"\n",
    "    tfms[0][0] = crop(size=sz, row_pct=row_pct, col_pct=col_pct)\n",
    "    tfms[1][0] = crop(size=sz, row_pct=row_pct, col_pct=col_pct)\n",
    "    \n",
    "    # VALID SPLIT (incl. tfms)\n",
    "    if is_test:\n",
    "        #switch train with valid (= test) tfms!\n",
    "        tfms_switched = (tfms[1], tfms[0])\n",
    "        \n",
    "        data = (ImageList6D.from_df(df_train_test, path='.')\n",
    "                .split_from_df(col=-1)\n",
    "                .label_from_df(cols=-4)\n",
    "                .transform(tfms_switched)#, size=sz) # remove size so we get the crop size!\n",
    "                .databunch(bs=bs))\n",
    "    else:\n",
    "        data = (ImageList6D.from_df(df_train, path='train')\n",
    "                .split_from_df(col=-1) # split_by_rand_pct()\n",
    "                .label_from_df(cols=-3)\n",
    "                #.add_test(ImageList6D.from_df(df_test, path='test'))\n",
    "                .transform(tfms)#, size=sz) # remove size so we get the crop size!\n",
    "                .databunch(bs=bs))\n",
    "    \n",
    "    data.normalize([tensor([0.0456, 0.0702, 0.0447, 0.0468, 0.0407, 0.0399]),\n",
    "                    tensor([0.0644, 0.0733, 0.0536, 0.0633, 0.0555, 0.0392])]);\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T17:59:55.028968Z",
     "start_time": "2019-08-05T17:59:55.014897Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_feats(model, dataloader, cycles=1):\n",
    "    feats = []\n",
    "    targs = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(cycles): # for TTA\n",
    "            for xb, yb in dataloader:\n",
    "                body_out = model.body(xb)\n",
    "                head_out = model.head(body_out)\n",
    "                feats.append(head_out.cpu())\n",
    "                targs.append(yb.cpu())\n",
    "                \n",
    "    feats = torch.cat(feats, dim=0)\n",
    "    targs = torch.cat(targs, dim=0)\n",
    "    \n",
    "    return feats, targs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T18:24:57.055059Z",
     "start_time": "2019-08-05T18:24:57.042012Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def save_feats(feats, targs, crop, ds='train'):\n",
    "    np.save(f'pred/feats_{ds}_crop{crop}.npy', feats)\n",
    "    np.save(f'pred/targs_{ds}_crop{crop}.npy', targs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T17:54:05.421073Z",
     "start_time": "2019-08-05T17:54:05.404036Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#https://docs.fast.ai/vision.transform.html#_crop\n",
    "crop_pos = [[0.,0.], [0.,1.],[0.5,0.5],[1.,0.], [1.,1.]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T18:44:20.028527Z",
     "start_time": "2019-08-05T18:44:20.011190Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get random crop pos\n",
    "i = 2\n",
    "crop_pos = [[uniform(0,1), uniform(0,1)] for i in range(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T18:44:20.895596Z",
     "start_time": "2019-08-05T18:44:20.878412Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "crop_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get the last three crop positions:\n",
    "crop_pos = [[0.5,0.5],[1.,0.], [1.,1.]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T18:44:51.754386Z",
     "start_time": "2019-08-05T18:44:51.738994Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_crop_feats(model=learn.model, cycles=1, crop_pos=crop_pos):\n",
    "    \n",
    "    for i, (row_pct, col_pct) in enumerate(crop_pos):\n",
    "        \n",
    "        print('== crop#:', i,' of', len(crop_pos), '==')\n",
    "        print('row_pct:', row_pct,', col_pct:', col_pct)\n",
    "    \n",
    "        data = get_dataset(row_pct, col_pct)\n",
    "        \n",
    "        # train\n",
    "        print('= Start train dataset =')\n",
    "        feats, targs = get_feats(model, data.train_dl)\n",
    "        save_feats(feats, targs, i, ds='train')\n",
    "        print('feats:', feats.shape,' targs:', targs.shape)\n",
    "        print('- Finish train dataset -')\n",
    "        \n",
    "        # valid\n",
    "        print('= Start valid dataset =')\n",
    "        feats, targs = get_feats(model, data.valid_dl)\n",
    "        save_feats(feats, targs, i, ds='valid')\n",
    "        print('feats:', feats.shape,' targs:', targs.shape)\n",
    "        print('- Finish valid dataset -')\n",
    "        \n",
    "        # get test ds as valid ds for TTA\n",
    "        data = get_dataset(row_pct, col_pct, is_test=True)\n",
    "        \n",
    "        # test\n",
    "        print('= Start test dataset =')\n",
    "        feats, targs = get_feats(model, data.valid_dl)\n",
    "        save_feats(feats, targs, i, ds='test')\n",
    "        print('feats:', feats.shape,' targs:', targs.shape)\n",
    "        print('- Finish test dataset -')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T18:44:52.441476Z",
     "start_time": "2019-08-05T18:44:52.411673Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn = Learner(data, adacos_efficientnet_b3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T18:44:53.733710Z",
     "start_time": "2019-08-05T18:44:53.521230Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.load('effnet/adacos_efficientnet_b3_e080CM112_190805');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T19:29:50.459716Z",
     "start_time": "2019-08-05T18:44:54.378356Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "get_crop_feats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#data = (ImageList6D.from_df(df_train_test, path='.')\n",
    "#        .split_from_df(col=-1)\n",
    "#        .label_from_df(cols=-4)\n",
    "#        .transform(tfms_switched)#, size=sz) # remove size so we get the crop size!\n",
    "#        .databunch(bs=bs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T17:18:09.266792Z",
     "start_time": "2019-08-14T17:18:09.249959Z"
    }
   },
   "outputs": [],
   "source": [
    "# get the names\n",
    "preds_names = learn.data.test_ds.x.items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T17:18:09.596244Z",
     "start_time": "2019-08-14T17:18:09.512953Z"
    }
   },
   "outputs": [],
   "source": [
    "# without site\n",
    "#preds_names = [x.split('/')[1]+'_'+x.split('/')[2][-1]+'_'+x.split('/')[3][:3] for x in preds_names]\n",
    "\n",
    "# with site\n",
    "preds_names = [x.split('/')[1]+'_'+x.split('/')[2][-1]+'_'+x.split('/')[3] for x in preds_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T17:18:10.364566Z",
     "start_time": "2019-08-14T17:18:10.346765Z"
    }
   },
   "outputs": [],
   "source": [
    "preds_test = np.load('pred/preds_test.npy')\n",
    "dist_test = np.load('pred/dist_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T17:18:12.062867Z",
     "start_time": "2019-08-14T17:18:12.048945Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39794, 39794, 39794)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds_names), len(preds_test), len(dist_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T17:18:12.479838Z",
     "start_time": "2019-08-14T17:18:12.463454Z"
    }
   },
   "outputs": [],
   "source": [
    "#preds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T17:18:12.712943Z",
     "start_time": "2019-08-14T17:18:12.670865Z"
    }
   },
   "outputs": [],
   "source": [
    "#dist_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T17:18:13.072400Z",
     "start_time": "2019-08-14T17:18:13.049090Z"
    }
   },
   "outputs": [],
   "source": [
    "df_preds = pd.DataFrame({'id_code_site': preds_names, 'sirna': preds_test, 'cossim': dist_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T17:18:13.483805Z",
     "start_time": "2019-08-14T17:18:13.460224Z"
    }
   },
   "outputs": [],
   "source": [
    "# get id_code without site\n",
    "df_preds['id_code'] = df_preds['id_code_site'].apply(lambda x: x[:-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T17:18:16.553826Z",
     "start_time": "2019-08-14T17:18:13.807135Z"
    }
   },
   "outputs": [],
   "source": [
    "# get row indices with highest cosine similiarity\n",
    "idx = []\n",
    "for i, r in enumerate(df_preds.sort_values('id_code').iterrows()):\n",
    "    #print(r)\n",
    "    #print('i: ',i)\n",
    "    #print('idx: ',r[0])\n",
    "    #print(r[1]['cossim'])\n",
    "    if i % 2:\n",
    "        # distance from row 2 is \n",
    "        if dist < r[1]['cossim']:\n",
    "            idx.append(r[0])\n",
    "        else:\n",
    "            idx.append(idx_row_before)\n",
    "    else:\n",
    "        # save dist from row 1 for comparison in next iteration\n",
    "        dist = r[1]['cossim']\n",
    "        idx_row_before = r[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T17:18:16.565881Z",
     "start_time": "2019-08-14T17:18:16.555021Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[19897, 19898, 2, 19900, 19901]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T17:18:16.611146Z",
     "start_time": "2019-08-14T17:18:16.566841Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_code_site</th>\n",
       "      <th>sirna</th>\n",
       "      <th>cossim</th>\n",
       "      <th>id_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HEPG2-08_1_B03_s1</td>\n",
       "      <td>904</td>\n",
       "      <td>0.628884</td>\n",
       "      <td>HEPG2-08_1_B03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19897</th>\n",
       "      <td>HEPG2-08_1_B03_s2</td>\n",
       "      <td>240</td>\n",
       "      <td>0.644725</td>\n",
       "      <td>HEPG2-08_1_B03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19898</th>\n",
       "      <td>HEPG2-08_1_B04_s2</td>\n",
       "      <td>31</td>\n",
       "      <td>0.739770</td>\n",
       "      <td>HEPG2-08_1_B04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HEPG2-08_1_B04_s1</td>\n",
       "      <td>31</td>\n",
       "      <td>0.684911</td>\n",
       "      <td>HEPG2-08_1_B04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HEPG2-08_1_B05_s1</td>\n",
       "      <td>199</td>\n",
       "      <td>0.812841</td>\n",
       "      <td>HEPG2-08_1_B05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19899</th>\n",
       "      <td>HEPG2-08_1_B05_s2</td>\n",
       "      <td>137</td>\n",
       "      <td>0.621264</td>\n",
       "      <td>HEPG2-08_1_B05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HEPG2-08_1_B06_s1</td>\n",
       "      <td>1075</td>\n",
       "      <td>0.708103</td>\n",
       "      <td>HEPG2-08_1_B06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19900</th>\n",
       "      <td>HEPG2-08_1_B06_s2</td>\n",
       "      <td>1075</td>\n",
       "      <td>0.842791</td>\n",
       "      <td>HEPG2-08_1_B06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HEPG2-08_1_B07_s1</td>\n",
       "      <td>756</td>\n",
       "      <td>0.746316</td>\n",
       "      <td>HEPG2-08_1_B07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19901</th>\n",
       "      <td>HEPG2-08_1_B07_s2</td>\n",
       "      <td>728</td>\n",
       "      <td>0.793391</td>\n",
       "      <td>HEPG2-08_1_B07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id_code_site  sirna    cossim         id_code\n",
       "0      HEPG2-08_1_B03_s1    904  0.628884  HEPG2-08_1_B03\n",
       "19897  HEPG2-08_1_B03_s2    240  0.644725  HEPG2-08_1_B03\n",
       "19898  HEPG2-08_1_B04_s2     31  0.739770  HEPG2-08_1_B04\n",
       "1      HEPG2-08_1_B04_s1     31  0.684911  HEPG2-08_1_B04\n",
       "2      HEPG2-08_1_B05_s1    199  0.812841  HEPG2-08_1_B05\n",
       "19899  HEPG2-08_1_B05_s2    137  0.621264  HEPG2-08_1_B05\n",
       "3      HEPG2-08_1_B06_s1   1075  0.708103  HEPG2-08_1_B06\n",
       "19900  HEPG2-08_1_B06_s2   1075  0.842791  HEPG2-08_1_B06\n",
       "4      HEPG2-08_1_B07_s1    756  0.746316  HEPG2-08_1_B07\n",
       "19901  HEPG2-08_1_B07_s2    728  0.793391  HEPG2-08_1_B07"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preds.sort_values('id_code').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T17:18:16.642842Z",
     "start_time": "2019-08-14T17:18:16.632772Z"
    }
   },
   "outputs": [],
   "source": [
    "#df_preds.loc[idx,['id_code','sirna']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T17:18:18.457584Z",
     "start_time": "2019-08-14T17:18:18.441166Z"
    }
   },
   "outputs": [],
   "source": [
    "# 'resnet50/adacos_se_xresnet50_ct_pg_128e073CM090_256e050CM050_190814'\n",
    "model = 'metriclearn_se_xresnet50_ct_pg_128e073CM090_256e050CM050_190814'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T17:18:19.411008Z",
     "start_time": "2019-08-14T17:18:19.309605Z"
    }
   },
   "outputs": [],
   "source": [
    "df_preds.loc[idx,['id_code','sirna']].to_csv('sub/'+model+'.csv.gz', index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-14T17:18:26.387064Z",
     "start_time": "2019-08-14T17:18:19.962230Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 82.4k/82.4k [00:04<00:00, 18.5kB/s]\n",
      "Successfully submitted to Recursion Cellular Image Classification"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c recursion-cellular-image-classification -f sub/{model}.csv.gz -m \"{model}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "preds_correct = np.load('preds_valid_correct.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_erros = pd.DataFrame({'id_code': preds_names, 'correct': preds_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_erros[df_errors['correct'] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ERROR ANALYSIS !!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "488px",
    "width": "305px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "206px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
