{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:07.203460Z",
     "start_time": "2019-09-04T18:23:07.006738Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:07.841085Z",
     "start_time": "2019-09-04T18:23:07.204608Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from fastai.vision import *\n",
    "from fastai.vision.models.xresnet import *\n",
    "\n",
    "# for datablock API\n",
    "from fastai.vision.image import _resolve_tfms, _get_crop_target, _round_multiple, _get_resize_target, _affine_grid, _grid_sample, _affine_mult\n",
    "\n",
    "# for XResNet\n",
    "#from fastai.vision.models.xresnet import act_fn, init_cnn, conv, noop, conv_layer, ResBlock, filt_sz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:07.852404Z",
     "start_time": "2019-09-04T18:23:07.842494Z"
    }
   },
   "outputs": [],
   "source": [
    "from fastai.callbacks import CSVLogger, ReduceLROnPlateauCallback, SaveModelCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:07.864593Z",
     "start_time": "2019-09-04T18:23:07.853520Z"
    }
   },
   "outputs": [],
   "source": [
    "from efficientnet_pytorch import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:07.876092Z",
     "start_time": "2019-09-04T18:23:07.865618Z"
    }
   },
   "outputs": [],
   "source": [
    "from nb_new_data_augmentation_adacos_celltype_plategroup_exp import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:07.886676Z",
     "start_time": "2019-09-04T18:23:07.877119Z"
    }
   },
   "outputs": [],
   "source": [
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:07.898091Z",
     "start_time": "2019-09-04T18:23:07.887572Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.55'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6D image with celltype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:07.911933Z",
     "start_time": "2019-09-04T18:23:07.899434Z"
    }
   },
   "outputs": [],
   "source": [
    "class Image6Dct(Image):\n",
    "    \"Support applying transforms to image data in `px`.\"\n",
    "    def __init__(self, px:Tensor, ctint, pgint, expint): # ct\n",
    "        self._px = px\n",
    "        self._logit_px=None\n",
    "        #self.ct = ct\n",
    "        self.ctint = ctint\n",
    "        self.pgint = pgint\n",
    "        self.expint = expint\n",
    "        self._flow=None\n",
    "        self._affine_mat=None\n",
    "        self.sample_kwargs = {}\n",
    "    \n",
    "    def _repr_image_format(self, format_str):\n",
    "        with BytesIO() as str_buffer:\n",
    "            #plt.imsave(str_buffer, image2np(self.px[:3]), format=format_str)\n",
    "            plt.imsave(str_buffer, \n",
    "                       np.concatenate((image2np(self.px[:3]), \n",
    "                                       image2np(self.px[3:])), axis=1),\n",
    "                       format=format_str)\n",
    "            return str_buffer.getvalue()\n",
    "        \n",
    "    def clone(self):\n",
    "        \"Mimic the behavior of torch.clone for `Image` objects.\"\n",
    "        return self.__class__(self.px.clone(), self.ctint.clone(), self.pgint.clone(), self.expint.clone()) # self.ct.clone(), \n",
    "\n",
    "    @property\n",
    "    def data(self)->TensorImage:\n",
    "        \"Return this images pixels as a tensor.\"\n",
    "        return self.px, self.ctint, self.pgint, self.expint\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:07.925492Z",
     "start_time": "2019-09-04T18:23:07.913246Z"
    }
   },
   "outputs": [],
   "source": [
    "def open_image_6Dct(fn:PathOrStr, div:bool=True, convert_mode:str='L', cls:type=Image6Dct,\n",
    "        after_open:Callable=None)->Image:\n",
    "    \"Return `Image` object created from image in file `fn`.\"\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", UserWarning) # EXIF warning from TiffPlugin\n",
    "        \n",
    "        x = []\n",
    "        for i in range(6):\n",
    "            c = PIL.Image.open(fn+'_w'+str(i+1)+'.png').convert(convert_mode)\n",
    "            if after_open: c = after_open(c)\n",
    "            c = np.asarray(c)\n",
    "            c = torch.from_numpy(c.astype(np.float32, copy=False))\n",
    "            x.append(c)\n",
    "    ct = fn.split('/')[1].split('-')[0] # get cell type\n",
    "    ctint = torch.tensor(ct2int[ct])\n",
    "    pgint = torch.tensor(fn2pgint[fn])\n",
    "    exp = fn.split('/')[1] # get experiment\n",
    "    expint = torch.tensor(exp2int[exp])\n",
    "    x = torch.stack(x)\n",
    "    if div: x.div_(255)\n",
    "    return cls(x, ctint, pgint, expint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:07.938441Z",
     "start_time": "2019-09-04T18:23:07.926504Z"
    }
   },
   "outputs": [],
   "source": [
    "# number experiments so that cell types do not overlap\n",
    "# and the valid and test dataset do have a embedding they can use!\n",
    "exp2int = {'HEPG2-01': 0,\n",
    "           'HEPG2-02': 1,\n",
    "           'HEPG2-03': 2,\n",
    "           'HEPG2-04': 3,\n",
    "           'HEPG2-05': 4,\n",
    "           # valid\n",
    "           'HEPG2-06': 0,\n",
    "           'HEPG2-07': 1,\n",
    "           # test\n",
    "           'HEPG2-08': 0,\n",
    "           'HEPG2-09': 1,\n",
    "           'HEPG2-10': 2,\n",
    "           'HEPG2-11': 3,           \n",
    "             \n",
    "           # train\n",
    "           'HUVEC-01': 5,\n",
    "           'HUVEC-02': 6,\n",
    "           'HUVEC-03': 7,\n",
    "           'HUVEC-04': 8,\n",
    "           'HUVEC-05': 9,\n",
    "           'HUVEC-06': 10,\n",
    "           'HUVEC-07': 11, \n",
    "           'HUVEC-08': 12,\n",
    "           'HUVEC-09': 13,\n",
    "           'HUVEC-10': 14,\n",
    "           'HUVEC-11': 15,\n",
    "           'HUVEC-12': 16,\n",
    "           'HUVEC-13': 17,\n",
    "           'HUVEC-14': 18, \n",
    "           # valid\n",
    "           'HUVEC-15': 5,\n",
    "           'HUVEC-16': 6, \n",
    "           # test\n",
    "           'HUVEC-17': 5,\n",
    "           'HUVEC-18': 6,\n",
    "           'HUVEC-19': 7,\n",
    "           'HUVEC-20': 8,\n",
    "           'HUVEC-21': 9,\n",
    "           'HUVEC-22': 10,\n",
    "           'HUVEC-23': 11,\n",
    "           'HUVEC-24': 12,\n",
    "             \n",
    "           # train\n",
    "           'RPE-01': 19,\n",
    "           'RPE-02': 20,\n",
    "           'RPE-03': 21,\n",
    "           'RPE-04': 22,\n",
    "           'RPE-05': 23,\n",
    "           # valid\n",
    "           'RPE-06': 19,\n",
    "           'RPE-07': 20,\n",
    "           # test\n",
    "           'RPE-08': 19,\n",
    "           'RPE-09': 20,\n",
    "           'RPE-10': 21,\n",
    "           'RPE-11': 22,\n",
    "             \n",
    "           # train\n",
    "           'U2OS-01': 24,\n",
    "           'U2OS-02': 25,\n",
    "           # valid\n",
    "           'U2OS-03': 24,\n",
    "           # test\n",
    "           'U2OS-04': 24,\n",
    "           'U2OS-05': 25\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:07.949127Z",
     "start_time": "2019-09-04T18:23:07.939470Z"
    }
   },
   "outputs": [],
   "source": [
    "#exp2int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:08.022112Z",
     "start_time": "2019-09-04T18:23:07.950104Z"
    }
   },
   "outputs": [],
   "source": [
    "df_full_plate_pattern = pd.read_csv('full_dataset_v2_path_plate_groups_only_20190812.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:08.037810Z",
     "start_time": "2019-09-04T18:23:08.023077Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>plate_pattern</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train/HEPG2-01/Plate1/B03_s1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train/HEPG2-01/Plate1/B04_s1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train/HEPG2-01/Plate1/B05_s1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train/HEPG2-01/Plate1/B06_s1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train/HEPG2-01/Plate1/B07_s1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           path  plate_pattern\n",
       "0  train/HEPG2-01/Plate1/B03_s1              0\n",
       "1  train/HEPG2-01/Plate1/B04_s1              0\n",
       "2  train/HEPG2-01/Plate1/B05_s1              0\n",
       "3  train/HEPG2-01/Plate1/B06_s1              0\n",
       "4  train/HEPG2-01/Plate1/B07_s1              0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full_plate_pattern.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:08.064102Z",
     "start_time": "2019-09-04T18:23:08.038783Z"
    }
   },
   "outputs": [],
   "source": [
    "fn2pgint = dict(zip(df_full_plate_pattern.path.values, \n",
    "                              df_full_plate_pattern.plate_pattern.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:08.075904Z",
     "start_time": "2019-09-04T18:23:08.065115Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn2pgint['train/HEPG2-01/Plate1/B03_s1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:08.087865Z",
     "start_time": "2019-09-04T18:23:08.076867Z"
    }
   },
   "outputs": [],
   "source": [
    "# cell types from rcic_v10_inspect_image_data.ipynb \"pixel stats\"\n",
    "cts = ['HEPG2', 'HUVEC', 'RPE', 'U2OS']\n",
    "int2ct = {i: ct for i, ct in enumerate(cts)}\n",
    "ct2int = {ct: i for i, ct in int2ct.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:08.099294Z",
     "start_time": "2019-09-04T18:23:08.088861Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'HEPG2', 1: 'HUVEC', 2: 'RPE', 3: 'U2OS'}\n",
      "{'HEPG2': 0, 'HUVEC': 1, 'RPE': 2, 'U2OS': 3}\n"
     ]
    }
   ],
   "source": [
    "print(int2ct)\n",
    "print(ct2int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:08.110855Z",
     "start_time": "2019-09-04T18:23:08.100140Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HEPG2'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct = 'train/HEPG2-01/Plate1/B03_s1'.split('/')[1].split('-')[0]; ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:08.122118Z",
     "start_time": "2019-09-04T18:23:08.111827Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct2int[ct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:08.132807Z",
     "start_time": "2019-09-04T18:23:08.123051Z"
    }
   },
   "outputs": [],
   "source": [
    "PATH_trunc = 'train/HEPG2-01/Plate1/B03_s1' # path is missing suffix \"_w1.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:08.169019Z",
     "start_time": "2019-09-04T18:23:08.133694Z"
    }
   },
   "outputs": [],
   "source": [
    "img = open_image_6Dct(PATH_trunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:08.180640Z",
     "start_time": "2019-09-04T18:23:08.170015Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 512, 512])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.px.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:08.194433Z",
     "start_time": "2019-09-04T18:23:08.182924Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(0), tensor(0))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.ctint, img.pgint, img.expint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:08.206425Z",
     "start_time": "2019-09-04T18:23:08.195828Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Tensor, torch.Tensor, torch.Tensor)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(img.ctint), type(img.pgint), type(img.expint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:08.220384Z",
     "start_time": "2019-09-04T18:23:08.207372Z"
    }
   },
   "outputs": [],
   "source": [
    "class ImageList6Dct(ImageList): #ImageList\n",
    "    def __init__(self, *args, convert_mode='L', after_open:Callable=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.convert_mode,self.after_open = convert_mode,after_open\n",
    "        self.copy_new.append('convert_mode')\n",
    "        self.c,self.sizes = 6,{}\n",
    "        \n",
    "    def open(self, fn):\n",
    "        \"Open image in `fn`, subclass and overwrite for custom behavior.\"\n",
    "        return open_image_6Dct(fn, convert_mode=self.convert_mode, after_open=self.after_open)\n",
    "\n",
    "#    def show(self, img):\n",
    "#        #return torch.cat((img[i][:3], img[i][3:]), dim=1)\n",
    "#        show_image(img)\n",
    "    \n",
    "    # https://docs.fast.ai/tutorial.itemlist.html#Advanced-show-methods\n",
    "    def show_xys(self, xs, ys, figsize:Tuple[int,int]=(15,10), **kwargs):\n",
    "        \"Show the `xs` and `ys` on a figure of `figsize`. `kwargs` are passed to the show method.\"\n",
    "        rows = int(math.sqrt(len(xs)))\n",
    "        fig, axs = plt.subplots(rows,rows,figsize=figsize)\n",
    "        for i, ax in enumerate(axs.flatten() if rows > 1 else [axs]):\n",
    "            #xs[i].show(ax=ax, y=ys[i], **kwargs)\n",
    "            img = Image6D(torch.cat((xs[i].data[:3], xs[i].data[3:]), dim=2)) # works but not elegant?\n",
    "            #img = Image6D(xs[i]) # does not work?\n",
    "            img.show(ax=ax, y=ys[i], **kwargs)\n",
    "        plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:08.230951Z",
     "start_time": "2019-09-04T18:23:08.221320Z"
    }
   },
   "outputs": [],
   "source": [
    "#def show_image(img:Image, ax:plt.Axes=None, figsize:tuple=(3,3), hide_axis:bool=True, cmap:str='binary',\n",
    "#                alpha:float=None, **kwargs)->plt.Axes:\n",
    "#    \"Display `Image` in notebook.\"\n",
    "#    if ax is None: fig,ax = plt.subplots(figsize=figsize)\n",
    "#    pdb.set_trace()\n",
    "#    #ax.imshow(image2np(img.data), cmap=cmap, alpha=alpha, **kwargs)\n",
    "#    ax.imshow(np.concatenate((image2np(self.px[:3]),\n",
    "#                              image2np(self.px[3:])), axis=1),\n",
    "#              cmap=cmap, alpha=alpha, **kwargs)\n",
    "#    if hide_axis: ax.axis('off')\n",
    "#    return ax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset raw files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:08.334621Z",
     "start_time": "2019-09-04T18:23:08.231882Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('full_train_dataset_valid-split-ex_v2_ct_20190824.csv', index_col=0)\n",
    "df_test = pd.read_csv('full_test_dataset_v2_ct_20190824.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:08.346198Z",
     "start_time": "2019-09-04T18:23:08.335686Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73030, 6)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:08.361246Z",
     "start_time": "2019-09-04T18:23:08.347192Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>experiment</th>\n",
       "      <th>sirna</th>\n",
       "      <th>multi</th>\n",
       "      <th>valid</th>\n",
       "      <th>celltype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36510</th>\n",
       "      <td>U2OS-03/Plate4/O19_s2</td>\n",
       "      <td>U2OS-03</td>\n",
       "      <td>103</td>\n",
       "      <td>U2OS-03 103</td>\n",
       "      <td>1</td>\n",
       "      <td>U2OS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36511</th>\n",
       "      <td>U2OS-03/Plate4/O20_s2</td>\n",
       "      <td>U2OS-03</td>\n",
       "      <td>202</td>\n",
       "      <td>U2OS-03 202</td>\n",
       "      <td>1</td>\n",
       "      <td>U2OS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36512</th>\n",
       "      <td>U2OS-03/Plate4/O21_s2</td>\n",
       "      <td>U2OS-03</td>\n",
       "      <td>824</td>\n",
       "      <td>U2OS-03 824</td>\n",
       "      <td>1</td>\n",
       "      <td>U2OS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36513</th>\n",
       "      <td>U2OS-03/Plate4/O22_s2</td>\n",
       "      <td>U2OS-03</td>\n",
       "      <td>328</td>\n",
       "      <td>U2OS-03 328</td>\n",
       "      <td>1</td>\n",
       "      <td>U2OS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36514</th>\n",
       "      <td>U2OS-03/Plate4/O23_s2</td>\n",
       "      <td>U2OS-03</td>\n",
       "      <td>509</td>\n",
       "      <td>U2OS-03 509</td>\n",
       "      <td>1</td>\n",
       "      <td>U2OS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        path experiment  sirna        multi  valid celltype\n",
       "36510  U2OS-03/Plate4/O19_s2    U2OS-03    103  U2OS-03 103      1     U2OS\n",
       "36511  U2OS-03/Plate4/O20_s2    U2OS-03    202  U2OS-03 202      1     U2OS\n",
       "36512  U2OS-03/Plate4/O21_s2    U2OS-03    824  U2OS-03 824      1     U2OS\n",
       "36513  U2OS-03/Plate4/O22_s2    U2OS-03    328  U2OS-03 328      1     U2OS\n",
       "36514  U2OS-03/Plate4/O23_s2    U2OS-03    509  U2OS-03 509      1     U2OS"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:08.375327Z",
     "start_time": "2019-09-04T18:23:08.362257Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>experiment</th>\n",
       "      <th>celltype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19892</th>\n",
       "      <td>U2OS-05/Plate4/O19_s2</td>\n",
       "      <td>U2OS-05</td>\n",
       "      <td>U2OS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19893</th>\n",
       "      <td>U2OS-05/Plate4/O20_s2</td>\n",
       "      <td>U2OS-05</td>\n",
       "      <td>U2OS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19894</th>\n",
       "      <td>U2OS-05/Plate4/O21_s2</td>\n",
       "      <td>U2OS-05</td>\n",
       "      <td>U2OS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19895</th>\n",
       "      <td>U2OS-05/Plate4/O22_s2</td>\n",
       "      <td>U2OS-05</td>\n",
       "      <td>U2OS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19896</th>\n",
       "      <td>U2OS-05/Plate4/O23_s2</td>\n",
       "      <td>U2OS-05</td>\n",
       "      <td>U2OS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        path experiment celltype\n",
       "19892  U2OS-05/Plate4/O19_s2    U2OS-05     U2OS\n",
       "19893  U2OS-05/Plate4/O20_s2    U2OS-05     U2OS\n",
       "19894  U2OS-05/Plate4/O21_s2    U2OS-05     U2OS\n",
       "19895  U2OS-05/Plate4/O22_s2    U2OS-05     U2OS\n",
       "19896  U2OS-05/Plate4/O23_s2    U2OS-05     U2OS"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:08.386206Z",
     "start_time": "2019-09-04T18:23:08.376331Z"
    }
   },
   "outputs": [],
   "source": [
    "cts = ['HEPG2', 'HUVEC', 'RPE', 'U2OS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:08.396535Z",
     "start_time": "2019-09-04T18:23:08.387177Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pick the celltype for the celltype-specific training\n",
    "#ct = cts[3]; ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:08.407029Z",
     "start_time": "2019-09-04T18:23:08.397507Z"
    }
   },
   "outputs": [],
   "source": [
    "#df_train[df_train['celltype'] == ct].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:08.417691Z",
     "start_time": "2019-09-04T18:23:08.408062Z"
    }
   },
   "outputs": [],
   "source": [
    "#df_train[df_train['celltype'] == ct].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:08.428535Z",
     "start_time": "2019-09-04T18:23:08.418894Z"
    }
   },
   "outputs": [],
   "source": [
    "#df_test[df_test['celltype'] == ct].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:08.461102Z",
     "start_time": "2019-09-04T18:23:08.429577Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train['pg'] = df_train['path'].apply(lambda x: fn2pgint['train/'+x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:08.485467Z",
     "start_time": "2019-09-04T18:23:08.462084Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test['pg'] = df_test['path'].apply(lambda x: fn2pgint['test/'+x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:08.496841Z",
     "start_time": "2019-09-04T18:23:08.486607Z"
    }
   },
   "outputs": [],
   "source": [
    "pg = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:08.511460Z",
     "start_time": "2019-09-04T18:23:08.497840Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18252, 7), (9946, 4))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train['pg'] == pg].shape, df_test[df_test['pg'] == pg].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:08.528056Z",
     "start_time": "2019-09-04T18:23:08.512474Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>experiment</th>\n",
       "      <th>sirna</th>\n",
       "      <th>multi</th>\n",
       "      <th>valid</th>\n",
       "      <th>celltype</th>\n",
       "      <th>pg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36510</th>\n",
       "      <td>U2OS-03/Plate4/O19_s2</td>\n",
       "      <td>U2OS-03</td>\n",
       "      <td>103</td>\n",
       "      <td>U2OS-03 103</td>\n",
       "      <td>1</td>\n",
       "      <td>U2OS</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36511</th>\n",
       "      <td>U2OS-03/Plate4/O20_s2</td>\n",
       "      <td>U2OS-03</td>\n",
       "      <td>202</td>\n",
       "      <td>U2OS-03 202</td>\n",
       "      <td>1</td>\n",
       "      <td>U2OS</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36512</th>\n",
       "      <td>U2OS-03/Plate4/O21_s2</td>\n",
       "      <td>U2OS-03</td>\n",
       "      <td>824</td>\n",
       "      <td>U2OS-03 824</td>\n",
       "      <td>1</td>\n",
       "      <td>U2OS</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36513</th>\n",
       "      <td>U2OS-03/Plate4/O22_s2</td>\n",
       "      <td>U2OS-03</td>\n",
       "      <td>328</td>\n",
       "      <td>U2OS-03 328</td>\n",
       "      <td>1</td>\n",
       "      <td>U2OS</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36514</th>\n",
       "      <td>U2OS-03/Plate4/O23_s2</td>\n",
       "      <td>U2OS-03</td>\n",
       "      <td>509</td>\n",
       "      <td>U2OS-03 509</td>\n",
       "      <td>1</td>\n",
       "      <td>U2OS</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        path experiment  sirna        multi  valid celltype  \\\n",
       "36510  U2OS-03/Plate4/O19_s2    U2OS-03    103  U2OS-03 103      1     U2OS   \n",
       "36511  U2OS-03/Plate4/O20_s2    U2OS-03    202  U2OS-03 202      1     U2OS   \n",
       "36512  U2OS-03/Plate4/O21_s2    U2OS-03    824  U2OS-03 824      1     U2OS   \n",
       "36513  U2OS-03/Plate4/O22_s2    U2OS-03    328  U2OS-03 328      1     U2OS   \n",
       "36514  U2OS-03/Plate4/O23_s2    U2OS-03    509  U2OS-03 509      1     U2OS   \n",
       "\n",
       "       pg  \n",
       "36510   3  \n",
       "36511   3  \n",
       "36512   3  \n",
       "36513   3  \n",
       "36514   3  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train['pg'] == pg].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:08.542987Z",
     "start_time": "2019-09-04T18:23:08.529037Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>experiment</th>\n",
       "      <th>celltype</th>\n",
       "      <th>pg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19069</th>\n",
       "      <td>U2OS-05/Plate1/O19_s2</td>\n",
       "      <td>U2OS-05</td>\n",
       "      <td>U2OS</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19070</th>\n",
       "      <td>U2OS-05/Plate1/O20_s2</td>\n",
       "      <td>U2OS-05</td>\n",
       "      <td>U2OS</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19071</th>\n",
       "      <td>U2OS-05/Plate1/O21_s2</td>\n",
       "      <td>U2OS-05</td>\n",
       "      <td>U2OS</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19072</th>\n",
       "      <td>U2OS-05/Plate1/O22_s2</td>\n",
       "      <td>U2OS-05</td>\n",
       "      <td>U2OS</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19073</th>\n",
       "      <td>U2OS-05/Plate1/O23_s2</td>\n",
       "      <td>U2OS-05</td>\n",
       "      <td>U2OS</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        path experiment celltype  pg\n",
       "19069  U2OS-05/Plate1/O19_s2    U2OS-05     U2OS   3\n",
       "19070  U2OS-05/Plate1/O20_s2    U2OS-05     U2OS   3\n",
       "19071  U2OS-05/Plate1/O21_s2    U2OS-05     U2OS   3\n",
       "19072  U2OS-05/Plate1/O22_s2    U2OS-05     U2OS   3\n",
       "19073  U2OS-05/Plate1/O23_s2    U2OS-05     U2OS   3"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[df_test['pg'] == pg].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color augmentation transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Color Augmentation: Color variability can be increased by applying random color transformations to original training samples. We perform color augmentation by transforming every color channels Ic ← ac · Ic + bc, where ac and bc are drawn from uniform distributions ac ∼ U [0.9, 1.1] and bc ∼ U [−10, +10].\" from Domain-adversarial neural networks to address the appearance variability of histopathology images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:08.553552Z",
     "start_time": "2019-09-04T18:23:08.543836Z"
    }
   },
   "outputs": [],
   "source": [
    "# from https://github.com/fastai/fastai/blob/master/fastai/vision/transform.py#L137\n",
    "#def _rgb_randomize(x, channel:int=None, thresh:float=0.3):\n",
    "#    \"Randomize one of the channels of the input image\"\n",
    "#    if channel is None: channel = np.random.randint(0, x.shape[0] - 1)\n",
    "#    x[channel] = torch.rand(x.shape[1:]) * np.random.uniform(0, thresh)\n",
    "#    return x\n",
    "#\n",
    "#rgb_randomize = TfmPixel(_rgb_randomize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:08.564311Z",
     "start_time": "2019-09-04T18:23:08.554518Z"
    }
   },
   "outputs": [],
   "source": [
    "# Scaling factor comes from byte tensor?\n",
    "#10/255 = 0.0392156862745098"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:08.576434Z",
     "start_time": "2019-09-04T18:23:08.565264Z"
    }
   },
   "outputs": [],
   "source": [
    "def _color_augmentation(x):\n",
    "    \"Randomize all channels of the input image\"\n",
    "    channel_count = x.shape[0] - 1\n",
    "    \n",
    "    # by transforming every color channels Ic ← ac · Ic + bc, \n",
    "    # where ac and bc are drawn from uniform distributions \n",
    "    # ac ∼ U [0.9, 1.1] and \n",
    "    # bc ∼ U [−10, +10].\n",
    "    \n",
    "    # x [0,1]\n",
    "    \n",
    "    for c in range(channel_count):\n",
    "        #pdb.set_trace()\n",
    "        #print(x.min(), x.max())\n",
    "        ac = np.random.uniform(0.9, 1.1) #np.random.uniform(0.9, 1.1)\n",
    "        bc = np.random.uniform(-0.1,0.1) #np.random.uniform(-10, 10)\n",
    "        x[c] = x[c] * ac + bc\n",
    "        \n",
    "        # clipping to min 0 and max 1\n",
    "        x[c] = torch.clamp(x[c], 0., 1.)\n",
    "    \n",
    "    return x\n",
    "\n",
    "color_augmentation = TfmPixel(_color_augmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforms setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:08.587478Z",
     "start_time": "2019-09-04T18:23:08.577442Z"
    }
   },
   "outputs": [],
   "source": [
    "## EfficientNet-B3\n",
    "#sz, bs = 300, 8 # 4167MiB /  7952MiB\n",
    "sz, bs = 300, 8*2 # 7942MiB /  7952MiB // FP16: 4397MiB /  7952MiB\n",
    "#sz, bs = 300, 8*4 # FP16: 7805MiB /  7952MiB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:08.599077Z",
     "start_time": "2019-09-04T18:23:08.588557Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 16)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sz, bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:08.609863Z",
     "start_time": "2019-09-04T18:23:08.600016Z"
    }
   },
   "outputs": [],
   "source": [
    "# cutout params\n",
    "#int(sz*0.1), int(sz*0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:08.620583Z",
     "start_time": "2019-09-04T18:23:08.610886Z"
    }
   },
   "outputs": [],
   "source": [
    "# normal tfms\n",
    "#tfms = get_transforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:08.631823Z",
     "start_time": "2019-09-04T18:23:08.621540Z"
    }
   },
   "outputs": [],
   "source": [
    "# extended tfms\n",
    "tfms = get_transforms(do_flip=True, flip_vert=True, \n",
    "                      max_rotate=90.0, max_zoom=1.1, \n",
    "                      max_lighting=0.2, max_warp=0.2, \n",
    "                      p_affine=0.75, p_lighting=0.75, \n",
    "                      xtra_tfms=[color_augmentation()])\n",
    "\n",
    "# crop_pad: https://forums.fast.ai/t/misc-issues/35386/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:08.642301Z",
     "start_time": "2019-09-04T18:23:08.632793Z"
    }
   },
   "outputs": [],
   "source": [
    "# extended tfms\n",
    "#tfms = get_transforms(do_flip=True, flip_vert=True, \n",
    "#                      max_rotate=90.0, max_zoom=1.1, \n",
    "#                      max_lighting=0.2, max_warp=0.2, \n",
    "#                      p_affine=0.75, p_lighting=0.75, \n",
    "#                      xtra_tfms=[color_augmentation(), \n",
    "#                                 cutout(n_holes=(1,4), length=(int(sz*0.1), int(sz*0.5)), p=.5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:08.653668Z",
     "start_time": "2019-09-04T18:23:08.643142Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([RandTransform(tfm=TfmCrop (crop_pad), kwargs={'row_pct': (0, 1), 'col_pct': (0, 1), 'padding_mode': 'reflection'}, p=1.0, resolved={}, do_run=True, is_random=True, use_on_y=True),\n",
       "  RandTransform(tfm=TfmAffine (dihedral_affine), kwargs={}, p=1.0, resolved={}, do_run=True, is_random=True, use_on_y=True),\n",
       "  RandTransform(tfm=TfmCoord (symmetric_warp), kwargs={'magnitude': (-0.2, 0.2)}, p=0.75, resolved={}, do_run=True, is_random=True, use_on_y=True),\n",
       "  RandTransform(tfm=TfmAffine (rotate), kwargs={'degrees': (-90.0, 90.0)}, p=0.75, resolved={}, do_run=True, is_random=True, use_on_y=True),\n",
       "  RandTransform(tfm=TfmAffine (zoom), kwargs={'scale': (1.0, 1.1), 'row_pct': (0, 1), 'col_pct': (0, 1)}, p=0.75, resolved={}, do_run=True, is_random=True, use_on_y=True),\n",
       "  RandTransform(tfm=TfmLighting (brightness), kwargs={'change': (0.4, 0.6)}, p=0.75, resolved={}, do_run=True, is_random=True, use_on_y=True),\n",
       "  RandTransform(tfm=TfmLighting (contrast), kwargs={'scale': (0.8, 1.25)}, p=0.75, resolved={}, do_run=True, is_random=True, use_on_y=True),\n",
       "  RandTransform(tfm=TfmPixel (color_augmentation), kwargs={}, p=1.0, resolved={}, do_run=True, is_random=True, use_on_y=True)],\n",
       " [RandTransform(tfm=TfmCrop (crop_pad), kwargs={}, p=1.0, resolved={}, do_run=True, is_random=True, use_on_y=True)])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:08.664986Z",
     "start_time": "2019-09-04T18:23:08.654497Z"
    }
   },
   "outputs": [],
   "source": [
    "# \"crop_pad\" to sz\n",
    "tfms[0][0] = crop_pad(size=sz, row_pct=[0.,1.], col_pct=[0.,1.])\n",
    "tfms[1][0] = crop_pad(size=sz, row_pct=[0.,1.], col_pct=[0.,1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:08.676635Z",
     "start_time": "2019-09-04T18:23:08.665954Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([RandTransform(tfm=TfmCrop (crop_pad), kwargs={'size': 300, 'row_pct': [0.0, 1.0], 'col_pct': [0.0, 1.0]}, p=1.0, resolved={}, do_run=True, is_random=True, use_on_y=True),\n",
       "  RandTransform(tfm=TfmAffine (dihedral_affine), kwargs={}, p=1.0, resolved={}, do_run=True, is_random=True, use_on_y=True),\n",
       "  RandTransform(tfm=TfmCoord (symmetric_warp), kwargs={'magnitude': (-0.2, 0.2)}, p=0.75, resolved={}, do_run=True, is_random=True, use_on_y=True),\n",
       "  RandTransform(tfm=TfmAffine (rotate), kwargs={'degrees': (-90.0, 90.0)}, p=0.75, resolved={}, do_run=True, is_random=True, use_on_y=True),\n",
       "  RandTransform(tfm=TfmAffine (zoom), kwargs={'scale': (1.0, 1.1), 'row_pct': (0, 1), 'col_pct': (0, 1)}, p=0.75, resolved={}, do_run=True, is_random=True, use_on_y=True),\n",
       "  RandTransform(tfm=TfmLighting (brightness), kwargs={'change': (0.4, 0.6)}, p=0.75, resolved={}, do_run=True, is_random=True, use_on_y=True),\n",
       "  RandTransform(tfm=TfmLighting (contrast), kwargs={'scale': (0.8, 1.25)}, p=0.75, resolved={}, do_run=True, is_random=True, use_on_y=True),\n",
       "  RandTransform(tfm=TfmPixel (color_augmentation), kwargs={}, p=1.0, resolved={}, do_run=True, is_random=True, use_on_y=True)],\n",
       " [RandTransform(tfm=TfmCrop (crop_pad), kwargs={'size': 300, 'row_pct': [0.0, 1.0], 'col_pct': [0.0, 1.0]}, p=1.0, resolved={}, do_run=True, is_random=True, use_on_y=True)])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:08.687122Z",
     "start_time": "2019-09-04T18:23:08.677610Z"
    }
   },
   "outputs": [],
   "source": [
    "### CHANGED LINE 65 to:\n",
    "# nano ~/anaconda3/envs/fastai/lib/python3.6/site-packages/fastai/vision/data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T10:36:41.864055Z",
     "start_time": "2019-08-10T10:36:41.846780Z"
    }
   },
   "source": [
    "```\n",
    "~/anaconda3/envs/fastai/lib/python3.6/site-packages/fastai/vision/data.py in _normalize_batch(b, mean, std, do_x, do_y)\n",
    "     64     \"`b` = `x`,`y` - normalize `x` array of imgs and `do_y` optionally `y`.\"\n",
    "     65     x,y = b\n",
    "---> 66     mean,std = mean.to(x.device),std.to(x.device)\n",
    "     67     if do_x: x = normalize(x,mean,std)\n",
    "     68     if do_y and len(y.shape) == 4: y = normalize(y,mean,std)\n",
    "\n",
    "AttributeError: 'list' object has no attribute 'device'\n",
    "```\n",
    "CHANGED TO:\n",
    "```\n",
    "def _normalize_batch(b:Tuple[Tensor,Tensor], mean:FloatTensor, std:FloatTensor, do_x:bool$\n",
    "    \"`b` = `x`,`y` - normalize `x` array of imgs and `do_y` optionally `y`.\"\n",
    "    (x,cint,pgint,expint),y = b\n",
    "    mean,std = mean.to(x.device),std.to(x.device)\n",
    "    if do_x: x = normalize(x,mean,std)\n",
    "    if do_y and len(y.shape) == 4: y = normalize(y,mean,std)\n",
    "    return (x,cint,pgint,expint),y\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:08.697648Z",
     "start_time": "2019-09-04T18:23:08.688072Z"
    }
   },
   "outputs": [],
   "source": [
    "#data.batch_stats() # DOES NOT WORK?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:08.709203Z",
     "start_time": "2019-09-04T18:23:08.698608Z"
    }
   },
   "outputs": [],
   "source": [
    "# From https://github.com/recursionpharma/rxrx1-utils/blob/master/rxrx/main.py\n",
    "# The mean and stds for each of the channels\n",
    "GLOBAL_PIXEL_STATS = (np.array([6.74696984, 14.74640167, 10.51260864,\n",
    "                                10.45369445,  5.49959796, 9.81545561]),\n",
    "                       np.array([7.95876312, 12.17305868, 5.86172946,\n",
    "                                 7.83451711, 4.701167, 5.43130431]))\n",
    "\n",
    "stats_mean = torch.tensor(GLOBAL_PIXEL_STATS[0]/255).float()\n",
    "stats_var = torch.tensor(GLOBAL_PIXEL_STATS[1]/255).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:08.719641Z",
     "start_time": "2019-09-04T18:23:08.710145Z"
    }
   },
   "outputs": [],
   "source": [
    "#stats_mean, stats_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:08.730155Z",
     "start_time": "2019-09-04T18:23:08.720556Z"
    }
   },
   "outputs": [],
   "source": [
    "# 3d to 6d from old/rcic_multicat_v9_resnet50-pretrained_colaug.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:08.741100Z",
     "start_time": "2019-09-04T18:23:08.731100Z"
    }
   },
   "outputs": [],
   "source": [
    "from efficientnet_pytorch.utils import get_same_padding_conv2d, round_filters, round_repeats, relu_fn\n",
    "from efficientnet_pytorch.model import MBConvBlock, load_pretrained_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:08.760074Z",
     "start_time": "2019-09-04T18:23:08.742115Z"
    }
   },
   "outputs": [],
   "source": [
    "# put feature extractor into forward method\n",
    "class EfficientNet(nn.Module):\n",
    "    \"\"\"\n",
    "    An EfficientNet model. Most easily loaded with the .from_name or .from_pretrained methods\n",
    "    Args:\n",
    "        blocks_args (list): A list of BlockArgs to construct blocks\n",
    "        global_params (namedtuple): A set of GlobalParams shared between blocks\n",
    "    Example:\n",
    "        model = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, blocks_args=None, global_params=None):\n",
    "        super().__init__()\n",
    "        assert isinstance(blocks_args, list), 'blocks_args should be a list'\n",
    "        assert len(blocks_args) > 0, 'block args must be greater than 0'\n",
    "        self._global_params = global_params\n",
    "        self._blocks_args = blocks_args\n",
    "\n",
    "        # Get static or dynamic convolution depending on image size\n",
    "        Conv2d = get_same_padding_conv2d(image_size=global_params.image_size)\n",
    "\n",
    "        # Batch norm parameters\n",
    "        bn_mom = 1 - self._global_params.batch_norm_momentum\n",
    "        bn_eps = self._global_params.batch_norm_epsilon\n",
    "\n",
    "        # Stem\n",
    "        in_channels = 3  # rgb\n",
    "        out_channels = round_filters(32, self._global_params)  # number of output channels\n",
    "        self._conv_stem = Conv2d(in_channels, out_channels, kernel_size=3, stride=2, bias=False)\n",
    "        self._bn0 = nn.BatchNorm2d(num_features=out_channels, momentum=bn_mom, eps=bn_eps)\n",
    "\n",
    "        # Build blocks\n",
    "        self._blocks = nn.ModuleList([])\n",
    "        for block_args in self._blocks_args:\n",
    "\n",
    "            # Update block input and output filters based on depth multiplier.\n",
    "            block_args = block_args._replace(\n",
    "                input_filters=round_filters(block_args.input_filters, self._global_params),\n",
    "                output_filters=round_filters(block_args.output_filters, self._global_params),\n",
    "                num_repeat=round_repeats(block_args.num_repeat, self._global_params)\n",
    "            )\n",
    "\n",
    "            # The first block needs to take care of stride and filter size increase.\n",
    "            self._blocks.append(MBConvBlock(block_args, self._global_params))\n",
    "            if block_args.num_repeat > 1:\n",
    "                block_args = block_args._replace(input_filters=block_args.output_filters, stride=1)\n",
    "            for _ in range(block_args.num_repeat - 1):\n",
    "                self._blocks.append(MBConvBlock(block_args, self._global_params))\n",
    "\n",
    "        # Head\n",
    "        in_channels = block_args.output_filters  # output of final block\n",
    "        out_channels = round_filters(1280, self._global_params)\n",
    "        self._conv_head = Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self._bn1 = nn.BatchNorm2d(num_features=out_channels, momentum=bn_mom, eps=bn_eps)\n",
    "\n",
    "        # Final linear layer\n",
    "        #self._dropout = self._global_params.dropout_rate\n",
    "        #self._fc = nn.Linear(out_channels, self._global_params.num_classes)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\" Returns output of the final convolution layer \"\"\"\n",
    "\n",
    "        # Stem\n",
    "        x = relu_fn(self._bn0(self._conv_stem(inputs)))\n",
    "\n",
    "        # Blocks\n",
    "        for idx, block in enumerate(self._blocks):\n",
    "            drop_connect_rate = self._global_params.drop_connect_rate\n",
    "            if drop_connect_rate:\n",
    "                drop_connect_rate *= float(idx) / len(self._blocks)\n",
    "            x = block(x, drop_connect_rate=drop_connect_rate)\n",
    "\n",
    "        # Head\n",
    "        x = relu_fn(self._bn1(self._conv_head(x)))\n",
    "\n",
    "        return x\n",
    "\n",
    "    #def forward(self, inputs):\n",
    "    #    \"\"\" Calls extract_features to extract features, applies final linear layer, and returns logits. \"\"\"\n",
    "    #\n",
    "    #    # Convolution layers\n",
    "    #    x = self.extract_features(inputs)\n",
    "    #\n",
    "    #    # Pooling and final linear layer\n",
    "    #    x = F.adaptive_avg_pool2d(x, 1).squeeze(-1).squeeze(-1)\n",
    "    #    if self._dropout:\n",
    "    #        x = F.dropout(x, p=self._dropout, training=self.training)\n",
    "    #    x = self._fc(x)\n",
    "    #    return x\n",
    "\n",
    "    @classmethod\n",
    "    def from_name(cls, model_name, override_params=None):\n",
    "        cls._check_model_name_is_valid(model_name)\n",
    "        blocks_args, global_params = get_model_params(model_name, override_params)\n",
    "        return EfficientNet(blocks_args, global_params)\n",
    "\n",
    "    @classmethod\n",
    "    def from_pretrained(cls, model_name, num_classes=1000):\n",
    "        model = EfficientNet.from_name(model_name, override_params={'num_classes': num_classes})\n",
    "        load_pretrained_weights(model, model_name, load_fc=(num_classes == 1000))\n",
    "        return model\n",
    "\n",
    "    @classmethod\n",
    "    def get_image_size(cls, model_name):\n",
    "        cls._check_model_name_is_valid(model_name)\n",
    "        _, _, res, _ = efficientnet_params(model_name)\n",
    "        return res\n",
    "\n",
    "    @classmethod\n",
    "    def _check_model_name_is_valid(cls, model_name, also_need_pretrained_weights=False):\n",
    "        \"\"\" Validates model name. None that pretrained weights are only available for\n",
    "        the first four models (efficientnet-b{i} for i in 0,1,2,3) at the moment. \"\"\"\n",
    "        num_models = 4 if also_need_pretrained_weights else 8\n",
    "        valid_models = ['efficientnet_b'+str(i) for i in range(num_models)]\n",
    "        if model_name.replace('-','_') not in valid_models:\n",
    "            raise ValueError('model_name should be one of: ' + ', '.join(valid_models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:08.771042Z",
     "start_time": "2019-09-04T18:23:08.761030Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils import model_zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:08.781936Z",
     "start_time": "2019-09-04T18:23:08.771992Z"
    }
   },
   "outputs": [],
   "source": [
    "url_map = {\n",
    "    'efficientnet-b0': 'http://storage.googleapis.com/public-models/efficientnet/efficientnet-b0-355c32eb.pth',\n",
    "    'efficientnet-b1': 'http://storage.googleapis.com/public-models/efficientnet/efficientnet-b1-f1951068.pth',\n",
    "    'efficientnet-b2': 'http://storage.googleapis.com/public-models/efficientnet/efficientnet-b2-8bb594d6.pth',\n",
    "    'efficientnet-b3': 'http://storage.googleapis.com/public-models/efficientnet/efficientnet-b3-5fb5a3c3.pth',\n",
    "    'efficientnet-b4': 'http://storage.googleapis.com/public-models/efficientnet/efficientnet-b4-6ed6700e.pth',\n",
    "    'efficientnet-b5': 'http://storage.googleapis.com/public-models/efficientnet/efficientnet-b5-b6417697.pth',\n",
    "    'efficientnet-b6': 'http://storage.googleapis.com/public-models/efficientnet/efficientnet-b6-c76e70fd.pth',\n",
    "    'efficientnet-b7': 'http://storage.googleapis.com/public-models/efficientnet/efficientnet-b7-dcc49843.pth',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:08.793460Z",
     "start_time": "2019-09-04T18:23:08.782928Z"
    }
   },
   "outputs": [],
   "source": [
    "# adapt load function to only load weights for feature extractor stage\n",
    "def load_pretrained_weights(model, model_name, load_fc=True):\n",
    "    \"\"\" Loads pretrained weights, and downloads if loading for the first time. \"\"\"\n",
    "    state_dict = model_zoo.load_url(url_map[model_name])\n",
    "    #if load_fc:\n",
    "    #    model.load_state_dict(state_dict)\n",
    "    #else:\n",
    "    state_dict.pop('_fc.weight')\n",
    "    state_dict.pop('_fc.bias')\n",
    "    res = model.load_state_dict(state_dict, strict=False)\n",
    "        #assert str(res.missing_keys) == str(['_fc.weight', '_fc.bias']), 'issue loading pretrained weights'\n",
    "    print('Loaded pretrained weights for {}'.format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:08.931843Z",
     "start_time": "2019-09-04T18:23:08.794487Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b3\n"
     ]
    }
   ],
   "source": [
    "# b3: input size = 300\n",
    "#efficientnet_b3 = EfficientNet.from_name('efficientnet-b3')\n",
    "efficientnet_f = EfficientNet.from_pretrained('efficientnet-b3')\n",
    "#efficientnet_b4f = EfficientNet.from_pretrained('efficientnet-b4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:08.942691Z",
     "start_time": "2019-09-04T18:23:08.932753Z"
    }
   },
   "outputs": [],
   "source": [
    "#efficientnet_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:08.954355Z",
     "start_time": "2019-09-04T18:23:08.943640Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Conv2dStaticSamePadding(\n",
       "   3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "   (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       " ), efficientnet_pytorch.utils.Conv2dStaticSamePadding)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficientnet_f._conv_stem, type(efficientnet_f._conv_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:08.969829Z",
     "start_time": "2019-09-04T18:23:08.956400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2dStaticSamePadding(\n",
       "  6, 40, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "  (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       ")"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.Conv2dStaticSamePadding(6, 40, kernel_size=(3, 3), stride=(2, 2), bias=False, image_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:08.988255Z",
     "start_time": "2019-09-04T18:23:08.976709Z"
    }
   },
   "outputs": [],
   "source": [
    "p_dict = {pn: p for pn, p in efficientnet_f._conv_stem.named_parameters()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:09.004472Z",
     "start_time": "2019-09-04T18:23:08.992351Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['weight'])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:09.019474Z",
     "start_time": "2019-09-04T18:23:09.007620Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([40, 3, 3, 3]), True)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_dict['weight'].shape, p_dict['weight'].requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:09.033137Z",
     "start_time": "2019-09-04T18:23:09.022293Z"
    }
   },
   "outputs": [],
   "source": [
    "old_weight = p_dict['weight'].detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:09.048208Z",
     "start_time": "2019-09-04T18:23:09.035972Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([40, 3, 3, 3]), False)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_weight.shape, old_weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:09.062350Z",
     "start_time": "2019-09-04T18:23:09.051345Z"
    }
   },
   "outputs": [],
   "source": [
    "new_weight = torch.cat((old_weight, old_weight), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:09.077612Z",
     "start_time": "2019-09-04T18:23:09.065449Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([40, 6, 3, 3]), False)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_weight.shape, new_weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:09.092881Z",
     "start_time": "2019-09-04T18:23:09.080430Z"
    }
   },
   "outputs": [],
   "source": [
    "def show_input_stage_weights(weight=None, nrows=2, ncols=3):\n",
    "    fig, ax = plt.subplots(nrows=nrows, ncols=ncols)\n",
    "    k = 0\n",
    "    for i in range(nrows):\n",
    "        for j in range(ncols):\n",
    "            if nrows > 1:\n",
    "                ax[i,j].set_title(k)\n",
    "                ax[i,j].imshow(weight[0][k])\n",
    "                ax[i,j].axis(\"off\")\n",
    "            else:\n",
    "                ax[j].set_title(k)\n",
    "                ax[j].imshow(weight[0][k])\n",
    "                ax[j].axis(\"off\")\n",
    "            k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:09.106317Z",
     "start_time": "2019-09-04T18:23:09.095652Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot old_weight\n",
    "#show_input_stage_weights(old_weight, nrows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:09.119717Z",
     "start_time": "2019-09-04T18:23:09.109081Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot new_weight\n",
    "#show_input_stage_weights(new_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:09.133768Z",
     "start_time": "2019-09-04T18:23:09.122825Z"
    }
   },
   "outputs": [],
   "source": [
    "# replace first conv layer with a 6-channel version\n",
    "efficientnet_f._conv_stem = utils.Conv2dStaticSamePadding(6, 40, kernel_size=(3, 3),\n",
    "                                                          stride=(2, 2), bias=False, image_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:09.144857Z",
     "start_time": "2019-09-04T18:23:09.134721Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2dStaticSamePadding(\n",
       "  6, 40, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "  (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       ")"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficientnet_f._conv_stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:09.156365Z",
     "start_time": "2019-09-04T18:23:09.145846Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 6, 3, 3])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficientnet_f._conv_stem.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:09.166735Z",
     "start_time": "2019-09-04T18:23:09.157240Z"
    }
   },
   "outputs": [],
   "source": [
    "# set new_weights to nn.Parameter and overwrite it in the conv layer\n",
    "efficientnet_f._conv_stem.weight = nn.Parameter(new_weight) # hand over requires_grad False?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:09.177521Z",
     "start_time": "2019-09-04T18:23:09.167613Z"
    }
   },
   "outputs": [],
   "source": [
    "# check if weight was loaded properly\n",
    "assert torch.allclose(new_weight, efficientnet_f._conv_stem.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:09.189231Z",
     "start_time": "2019-09-04T18:23:09.178462Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([40, 6, 3, 3]), True)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficientnet_f._conv_stem.weight.shape, efficientnet_f._conv_stem.weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:09.199850Z",
     "start_time": "2019-09-04T18:23:09.190154Z"
    }
   },
   "outputs": [],
   "source": [
    "# network is in full train mode!\n",
    "#[p.requires_grad for p in efficientnet_b3f.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:09.210785Z",
     "start_time": "2019-09-04T18:23:09.200847Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_rg(model=efficientnet_f, option=False):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:09.222287Z",
     "start_time": "2019-09-04T18:23:09.211964Z"
    }
   },
   "outputs": [],
   "source": [
    "# set requires grad for the efficientnet to false (to later only set it true for the input)\n",
    "# WE WILL NOT DO THIS, because it should be not necessary!\n",
    "set_rg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:09.232567Z",
     "start_time": "2019-09-04T18:23:09.223184Z"
    }
   },
   "outputs": [],
   "source": [
    "# network is frozen\n",
    "#[p.requires_grad for p in efficientnet_b4f.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:09.243789Z",
     "start_time": "2019-09-04T18:23:09.233534Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficientnet_f._conv_stem.weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:09.254320Z",
     "start_time": "2019-09-04T18:23:09.244717Z"
    }
   },
   "outputs": [],
   "source": [
    "# set input stage to trainable\n",
    "#efficientnet_f._conv_stem.weight.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:09.264965Z",
     "start_time": "2019-09-04T18:23:09.255351Z"
    }
   },
   "outputs": [],
   "source": [
    "#efficientnet_f._conv_stem.weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:09.395862Z",
     "start_time": "2019-09-04T18:23:09.265884Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1536, 9, 9])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficientnet_f(torch.randn(1,6,sz,sz)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EfficientNet Pre-Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:09.407333Z",
     "start_time": "2019-09-04T18:23:09.396774Z"
    }
   },
   "outputs": [],
   "source": [
    "def resnet_pre_head(concat_pool:bool=True):\n",
    "    pool = AdaptiveConcatPool2d() if concat_pool else nn.AdaptiveAvgPool2d(1)\n",
    "    layers = [pool, Flatten()]\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:09.418295Z",
     "start_time": "2019-09-04T18:23:09.408288Z"
    }
   },
   "outputs": [],
   "source": [
    "efficientnet_f_prehead = resnet_pre_head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:09.429540Z",
     "start_time": "2019-09-04T18:23:09.419262Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): AdaptiveConcatPool2d(\n",
       "    (ap): AdaptiveAvgPool2d(output_size=1)\n",
       "    (mp): AdaptiveMaxPool2d(output_size=1)\n",
       "  )\n",
       "  (1): Flatten()\n",
       ")"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficientnet_f_prehead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:09.442888Z",
     "start_time": "2019-09-04T18:23:09.430486Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3072])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficientnet_f_prehead(torch.randn(2, 1536, 9, 9)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:09.453936Z",
     "start_time": "2019-09-04T18:23:09.443914Z"
    }
   },
   "outputs": [],
   "source": [
    "efficientnet_fph = nn.Sequential(efficientnet_f, efficientnet_f_prehead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:09.586083Z",
     "start_time": "2019-09-04T18:23:09.454906Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3072])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficientnet_fph(torch.randn(1,6,sz,sz)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CellType & Plate Group Feature Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:09.597907Z",
     "start_time": "2019-09-04T18:23:09.587086Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exps = len(set([exp2int[i] for i in exp2int])); exps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:09.612873Z",
     "start_time": "2019-09-04T18:23:09.598904Z"
    }
   },
   "outputs": [],
   "source": [
    "class CellTypePlateGroupFeatures(nn.Module):\n",
    "    '''CellType Feature Extractor.'''\n",
    "    def __init__(self, cell_types=4, plate_groups=4, exps=exps, emb_sz=128):\n",
    "        super(CellTypePlateGroupFeatures, self).__init__()\n",
    "        self.emb_ctint = nn.Embedding(cell_types, emb_sz)\n",
    "        self.emb_pgint = nn.Embedding(plate_groups, emb_sz)\n",
    "        self.emb_expint = nn.Embedding(exps, emb_sz)\n",
    "        \n",
    "    def forward(self, xb_ctint, xb_pgint, xb_expint, yb=None): # yb=None for training in non-AdaCos mode!\n",
    "        \n",
    "        ### CTINT\n",
    "        # check if we are in CutMix mode:\n",
    "        if isinstance(xb_ctint, tuple):\n",
    "            x1, x2, λ = xb_ctint\n",
    "            out1 = self.emb_ctint(x1)\n",
    "            out2 = self.emb_ctint(x2)\n",
    "            out_ctint = out1 * λ + out2 * (1-λ)\n",
    "        else: # if not CutMix, then normal mode\n",
    "            out_ctint = self.emb_ctint(xb_ctint)\n",
    "        \n",
    "        ## PGINT\n",
    "        # check if we are in CutMix mode:\n",
    "        if isinstance(xb_pgint, tuple):\n",
    "            x1, x2, λ = xb_pgint\n",
    "            out1 = self.emb_pgint(x1)\n",
    "            out2 = self.emb_pgint(x2)\n",
    "            out_pgint = out1 * λ + out2 * (1-λ)\n",
    "        else: # if not CutMix, then normal mode\n",
    "            out_pgint = self.emb_pgint(xb_pgint)\n",
    "            \n",
    "        ## EXPINT\n",
    "        # check if we are in CutMix mode:\n",
    "        if isinstance(xb_expint, tuple):\n",
    "            x1, x2, λ = xb_expint\n",
    "            out1 = self.emb_expint(x1)\n",
    "            out2 = self.emb_expint(x2)\n",
    "            out_expint = out1 * λ + out2 * (1-λ)\n",
    "        else: # if not CutMix, then normal mode\n",
    "            out_expint = self.emb_expint(xb_expint)\n",
    "        \n",
    "        out = torch.cat((out_ctint, out_pgint,  out_expint), dim=-1)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:09.623904Z",
     "start_time": "2019-09-04T18:23:09.613833Z"
    }
   },
   "outputs": [],
   "source": [
    "ctf = CellTypePlateGroupFeatures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:09.635181Z",
     "start_time": "2019-09-04T18:23:09.624857Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CellTypePlateGroupFeatures(\n",
       "  (emb_ctint): Embedding(4, 128)\n",
       "  (emb_pgint): Embedding(4, 128)\n",
       "  (emb_expint): Embedding(26, 128)\n",
       ")"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:09.646485Z",
     "start_time": "2019-09-04T18:23:09.636129Z"
    }
   },
   "outputs": [],
   "source": [
    "xb = (torch.tensor(ct2int['HEPG2']),\n",
    "      torch.tensor(fn2pgint['train/HEPG2-01/Plate1/B03_s1']),\n",
    "      torch.tensor(exp2int['train/HEPG2-01/Plate1/B03_s1'.split('/')[1]])\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:09.658009Z",
     "start_time": "2019-09-04T18:23:09.647460Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(0), tensor(0))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:09.670595Z",
     "start_time": "2019-09-04T18:23:09.659049Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([384])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctf(xb[0], xb[1], xb[2]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:09.681741Z",
     "start_time": "2019-09-04T18:23:09.671548Z"
    }
   },
   "outputs": [],
   "source": [
    "xb = (torch.tensor((1,3)), torch.tensor((1,3)), torch.tensor((1,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:09.693203Z",
     "start_time": "2019-09-04T18:23:09.682688Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 3]), tensor([1, 3]), tensor([1, 3]))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:09.704934Z",
     "start_time": "2019-09-04T18:23:09.694127Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 384])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctf(xb[0], xb[1], xb[2]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:09.716453Z",
     "start_time": "2019-09-04T18:23:09.705884Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 2)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct2int['HEPG2'], ct2int['RPE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:09.727925Z",
     "start_time": "2019-09-04T18:23:09.717394Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn2pgint['train/HEPG2-01/Plate1/B03_s1'], fn2pgint['train/RPE-01/Plate1/B03_s1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:09.739367Z",
     "start_time": "2019-09-04T18:23:09.728866Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 19)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp2int['HEPG2-01'], exp2int['RPE-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:09.750940Z",
     "start_time": "2019-09-04T18:23:09.740307Z"
    }
   },
   "outputs": [],
   "source": [
    "xb = ((torch.tensor(ct2int['HEPG2']), torch.tensor(ct2int['RPE']), 0.9),\n",
    "      (torch.tensor(fn2pgint['train/HEPG2-01/Plate1/B03_s1']),\n",
    "       torch.tensor(fn2pgint['train/RPE-01/Plate1/B03_s1']), 0.9),\n",
    "      (torch.tensor(exp2int['HEPG2-01']),\n",
    "       torch.tensor(exp2int['RPE-01']), 0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:09.762644Z",
     "start_time": "2019-09-04T18:23:09.751872Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([384])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctf(xb[0], xb[1], xb[2]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:09.773485Z",
     "start_time": "2019-09-04T18:23:09.763668Z"
    }
   },
   "outputs": [],
   "source": [
    "#class CellTypeFeatures(nn.Module):\n",
    "#    '''CellType Feature Extractor.'''\n",
    "#    def __init__(self, cell_types=4, emb_sz=128, lin_ftrs:Optional[Collection[int]]=None, nc=128):\n",
    "#        super(AdaCosNet, self).__init__()\n",
    "#        self.emb = nn.Embedding(cell_types, emb_sz)\n",
    "#        \n",
    "#        self.lin_ftrs = [emb_sz, 512, 512] if lin_ftrs is None else [emb_sz] + lin_ftrs + [nc]\n",
    "#\n",
    "#        \n",
    "#    def forward(self, xb, yb=None): # yb=None for training in non-AdaCos mode!\n",
    "#\n",
    "#        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaCos-Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:09.786855Z",
     "start_time": "2019-09-04T18:23:09.774438Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_adacos_head(nf:int, lin_ftrs:Optional[Collection[int]]=None, ps:Floats=0.5,\n",
    "                bn_final:bool=False): # concat_pool:bool=True, nc:int,\n",
    "    \"Model head that takes `nf` features, runs through `lin_ftrs`, and about `nc` classes.\"\n",
    "    \n",
    "    # ADDED TWO MORE 512 LAYERS !!!\n",
    "    lin_ftrs = [nf, 512, 512, 512, 512] if lin_ftrs is None else [nf] + lin_ftrs + [nc]\n",
    "    # remove last 512 fc layer to reduce MODEL SIZE ??? ???\n",
    "    \n",
    "    ps = listify(ps)\n",
    "    if len(ps) == 1: ps = [ps[0]/2] * (len(lin_ftrs)-2) + ps\n",
    "    actns = [nn.ReLU(inplace=True)] * (len(lin_ftrs)-2) + [None]\n",
    "    #pool = AdaptiveConcatPool2d() if concat_pool else nn.AdaptiveAvgPool2d(1)\n",
    "    #layers = [pool, Flatten()]\n",
    "    layers = []\n",
    "    for ni,no,p,actn in zip(lin_ftrs[:-1], lin_ftrs[1:], ps, actns):\n",
    "        layers += bn_drop_lin(ni, no, True, p, actn)\n",
    "    if bn_final: layers.append(nn.BatchNorm1d(lin_ftrs[-1], momentum=0.01))\n",
    "    #layers.append(AdaCos(lin_ftrs[-1], nc))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:09.810961Z",
     "start_time": "2019-09-04T18:23:09.787770Z"
    }
   },
   "outputs": [],
   "source": [
    "#adacos_head = create_adacos_head(nf=2048+1) \n",
    "adacos_head = create_adacos_head(nf=1536*2+128*3)\n",
    "# se_xresnet50f: 2048*2=4096, ctf: 128*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:09.822093Z",
     "start_time": "2019-09-04T18:23:09.811891Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): BatchNorm1d(3456, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (1): Dropout(p=0.25)\n",
       "  (2): Linear(in_features=3456, out_features=512, bias=True)\n",
       "  (3): ReLU(inplace)\n",
       "  (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (5): Dropout(p=0.25)\n",
       "  (6): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (7): ReLU(inplace)\n",
       "  (8): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (9): Dropout(p=0.25)\n",
       "  (10): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (11): ReLU(inplace)\n",
       "  (12): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (13): Dropout(p=0.5)\n",
       "  (14): Linear(in_features=512, out_features=512, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adacos_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:09.832684Z",
     "start_time": "2019-09-04T18:23:09.823053Z"
    }
   },
   "outputs": [],
   "source": [
    "#adacos_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:09.847866Z",
     "start_time": "2019-09-04T18:23:09.833681Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 512])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adacos_head(torch.randn(2, 1536*2+128*3)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:09.867110Z",
     "start_time": "2019-09-04T18:23:09.849754Z"
    }
   },
   "outputs": [],
   "source": [
    "# from https://github.com/4uiiurz1/pytorch-adacos/blob/master/metrics.py\n",
    "class AdaCos(nn.Module):\n",
    "    def __init__(self, num_features, num_classes, m=0.50):\n",
    "        super(AdaCos, self).__init__()\n",
    "        self.num_features = num_features\n",
    "        self.n_classes = num_classes\n",
    "        self.s = math.sqrt(2) * math.log(num_classes - 1)\n",
    "        self.m = m\n",
    "        self.We = nn.Parameter(torch.FloatTensor(num_classes, num_features))\n",
    "        nn.init.xavier_uniform_(self.We)\n",
    "\n",
    "    def forward(self, xb, yb):\n",
    "        \n",
    "        #print(yb.shape)\n",
    "        #pdb.set_trace()\n",
    "        \n",
    "        # normalize features\n",
    "        x = F.normalize(xb)\n",
    "        # normalize weights\n",
    "        W = F.normalize(self.We)\n",
    "        # dot product\n",
    "        logits = F.linear(x, W)\n",
    "        \n",
    "        # for training in non-AdaCos mode (= no yb date in the forward pass):\n",
    "        if yb is None:\n",
    "            print('yb = None')\n",
    "            return logits\n",
    "        \n",
    "        # feature re-scale\n",
    "        theta = torch.acos(torch.clamp(logits, -1.0 + 1e-7, 1.0 - 1e-7))\n",
    "        one_hot = torch.zeros_like(logits)\n",
    "        \n",
    "        # ORIGINAL\n",
    "        #one_hot.scatter_(1, yb.view(-1, 1).long(), 1)\n",
    "        #with torch.no_grad():\n",
    "        #    B_avg = torch.where(one_hot < 1, torch.exp(self.s * logits), torch.zeros_like(logits))\n",
    "        #    B_avg = torch.sum(B_avg) / xb.size(0)\n",
    "        #    #print(B_avg)\n",
    "        #    theta_med = torch.median(theta[one_hot == 1])\n",
    "        #    self.s = torch.log(B_avg) / torch.cos(torch.min(math.pi/4 * torch.ones_like(theta_med), theta_med))\n",
    "        #    #print(self.s)\n",
    "            \n",
    "        # ADAPTED FOR CUTMIX TO GET MIXED SCALE PARAMETER\n",
    "        with torch.no_grad():\n",
    "            # FROM nb_new_data_augmentation_adacos2.py LINE 888\n",
    "            # AND https://github.com/fastai/fastai/blob/master/fastai/callbacks/mixup.py#L40\n",
    "            if yb.ndim == 2:# and target.shape[-1] >1:\n",
    "                n_mod_patches = (yb.shape[-1] - 1) // 2\n",
    "                #c_ = yb[:, 1:n_mod_patches + 1]\n",
    "                c_ = yb[:, 0:n_mod_patches + 1]\n",
    "                W_ = yb[:, n_mod_patches + 1:]\n",
    "                self.s_scaled = []\n",
    "                \n",
    "                # this loop is only realdy needed when we have different probabilities inside a batch\n",
    "                # which we do not have (right now)! So this could be cleaned up, but we leave until\n",
    "                # we know we will not need the case with different probabilities in a batch.\n",
    "                for k in range(n_mod_patches+1):\n",
    "                    yb_new = c_[:, k].long()\n",
    "                    #pdb.set_trace()\n",
    "                    \n",
    "                    one_hot.scatter_(1, yb_new.view(-1,1).long(), 1)\n",
    "                    \n",
    "                    B_avg = torch.where(one_hot < 1, torch.exp(self.s * logits), torch.zeros_like(logits))\n",
    "                    B_avg = torch.sum(B_avg) / xb.size(0)\n",
    "                    theta_med = torch.median(theta[one_hot == 1])\n",
    "                    self.s = torch.log(B_avg) / torch.cos(torch.min(math.pi/4 * torch.ones_like(theta_med), theta_med))\n",
    "                    \n",
    "                    if k+1 == len(range(n_mod_patches+1)):\n",
    "                        #self.s_scaled.append((1-W_[:, k-1]) * self.s)\n",
    "                        self.s_scaled.append((1-W_[0, k-1]) * self.s)\n",
    "                        # For more than two the sum of W_[:, :k] has to be used!!!\n",
    "                    else:\n",
    "                        #self.s_scaled.append(W_[:, k] * self.s)\n",
    "                        self.s_scaled.append(W_[0, k] * self.s)\n",
    "                    # Mixed B_avg & self.s and single are not really far off, but now we have it coded\n",
    "                    # se we keep it (until it breaks something later).\n",
    "                self.s = torch.add(*self.s_scaled)\n",
    "                # Clean up, self.s_scaled is just a vector with the same entry multiple times\n",
    "                # when it is not indexed above with W_[0,... !\n",
    "            else:\n",
    "                one_hot.scatter_(1, yb.view(-1,1).long(), 1)\n",
    "                B_avg = torch.where(one_hot < 1, torch.exp(self.s * logits), torch.zeros_like(logits))\n",
    "                B_avg = torch.sum(B_avg) / xb.size(0)\n",
    "                theta_med = torch.median(theta[one_hot == 1])\n",
    "                self.s = torch.log(B_avg) / torch.cos(torch.min(math.pi/4 * torch.ones_like(theta_med), theta_med))\n",
    "        \n",
    "        output = self.s * logits\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:09.879954Z",
     "start_time": "2019-09-04T18:23:09.868043Z"
    }
   },
   "outputs": [],
   "source": [
    "class AdaCosNet(nn.Module):\n",
    "    '''Simple AdaCosNet connecter to run xb through the feature extractor head\n",
    "    and then feed xb and yb into the AdaCos layer.'''\n",
    "    def __init__(self, body1, body2, head):\n",
    "        super(AdaCosNet, self).__init__()\n",
    "        self.body1 = body1\n",
    "        self.body2 = body2\n",
    "        self.head = head\n",
    "        self.adacos = AdaCos(512, 277) # was 1108 !!!\n",
    "        \n",
    "    def forward(self, xb, yb=None): # yb=None for training in non-AdaCos mode!\n",
    "        xb_img, xb_ctint, xb_pgint, xb_expint = xb\n",
    "        resnet_features = self.body1(xb_img)\n",
    "        int_features = self.body2(xb_ctint, xb_pgint, xb_expint)\n",
    "        features = torch.cat((resnet_features, int_features), dim=-1)\n",
    "        out = self.head(features)\n",
    "        #print('xb.shape: ', xb.shape,', yb.shape: ', yb.shape)\n",
    "        out = self.adacos(out, yb)\n",
    "        #print('out: ',out.shape)\n",
    "        #pdb.set_trace()\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:09.891644Z",
     "start_time": "2019-09-04T18:23:09.880900Z"
    }
   },
   "outputs": [],
   "source": [
    "adacos_efficientnet = AdaCosNet(efficientnet_fph, ctf, adacos_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:09.908691Z",
     "start_time": "2019-09-04T18:23:09.892523Z"
    }
   },
   "outputs": [],
   "source": [
    "xb = (torch.randn(2,6,sz,sz),\n",
    "      #(torch.randint(4, (2,1)),  torch.randint(4, (2,1)))\n",
    "      torch.tensor((1,3)), torch.tensor((1,3)), torch.tensor((1,3))\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.127688Z",
     "start_time": "2019-09-04T18:23:09.909613Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yb = None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 277])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adacos_efficientnet(xb).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.343469Z",
     "start_time": "2019-09-04T18:23:10.128675Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 277])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adacos_efficientnet(xb, torch.tensor([276, 1])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.354769Z",
     "start_time": "2019-09-04T18:23:10.344466Z"
    }
   },
   "outputs": [],
   "source": [
    "test_target = torch.tensor(\n",
    "    [[2.4700e+02, 2.3900e+02, 7.8362e-01],\n",
    "     [2.3300e+02, 1.7400e+02, 7.8362e-01],\n",
    "     [1.7400e+02, 1.3400e+02, 7.8362e-01],\n",
    "     [1.9800e+02, 1.4700e+02, 7.8362e-01]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.768730Z",
     "start_time": "2019-09-04T18:23:10.355705Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 277])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adacos_efficientnet((torch.randn(4,6,sz,sz), \n",
    "                     torch.tensor((1,3,0,2)), torch.tensor((1,3,0,2)), torch.tensor((1,3,0,2))),\n",
    "                    test_target).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.780644Z",
     "start_time": "2019-09-04T18:23:10.769743Z"
    }
   },
   "outputs": [],
   "source": [
    "# Based on https://forums.fast.ai/t/teacher-forcing/29415/4\n",
    "# https://forums.fast.ai/t/on-batch-begin-callback/35201/3\n",
    "@dataclass\n",
    "class AppendBatchTargs(Callback):\n",
    "    learn:Learner\n",
    "    def __init__(self, learn):\n",
    "        super().__init__()\n",
    "    def on_batch_begin(self, last_input, last_target, **kwargs):\n",
    "        return {'last_input':(last_input, last_target), 'last_target':last_target}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.791258Z",
     "start_time": "2019-09-04T18:23:10.781587Z"
    }
   },
   "outputs": [],
   "source": [
    "#def check_rg(model=learn.model):\n",
    "#    layer_rg = [(n, p.requires_grad) for n,p in model.named_parameters()]\n",
    "#    for i in range(len(layer_rg)):\n",
    "#        print(f'{layer_rg[i][0]}\\t{layer_rg[i][1]}'.expandtabs(45))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.885955Z",
     "start_time": "2019-09-04T18:23:10.792216Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-129-ce3af7760f12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'xx' is not defined"
     ]
    }
   ],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:26:25.416112Z",
     "start_time": "2019-09-04T18:26:25.399266Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HEPG2', 'HUVEC', 'RPE', 'U2OS']"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:26:26.798579Z",
     "start_time": "2019-09-04T18:26:26.782772Z"
    }
   },
   "outputs": [],
   "source": [
    "# pg0 for 'HEPG2', 'HUVEC', 'RPE ==> OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T20:20:09.052143Z",
     "start_time": "2019-09-04T18:26:27.082320Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ===  0  ===  HEPG2  === \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.944188</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.340387</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.593521</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.136306</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.851307</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.733919</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.679979</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.537638</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.489200</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.458598</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.385166</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.379500</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.333297</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.343238</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.318213</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.269921</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.254736</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.217763</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.225165</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.236275</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.217514</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.171394</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.197320</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1.143994</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.194944</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ===  0  ===  HUVEC  === \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.178672</td>\n",
       "      <td>#na#</td>\n",
       "      <td>02:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.128585</td>\n",
       "      <td>#na#</td>\n",
       "      <td>02:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.081310</td>\n",
       "      <td>#na#</td>\n",
       "      <td>02:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.051461</td>\n",
       "      <td>#na#</td>\n",
       "      <td>02:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.056105</td>\n",
       "      <td>#na#</td>\n",
       "      <td>02:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.044141</td>\n",
       "      <td>#na#</td>\n",
       "      <td>02:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.005963</td>\n",
       "      <td>#na#</td>\n",
       "      <td>02:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.053622</td>\n",
       "      <td>#na#</td>\n",
       "      <td>02:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.003583</td>\n",
       "      <td>#na#</td>\n",
       "      <td>02:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.990753</td>\n",
       "      <td>#na#</td>\n",
       "      <td>02:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.982893</td>\n",
       "      <td>#na#</td>\n",
       "      <td>02:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.974156</td>\n",
       "      <td>#na#</td>\n",
       "      <td>02:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.969672</td>\n",
       "      <td>#na#</td>\n",
       "      <td>02:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.963696</td>\n",
       "      <td>#na#</td>\n",
       "      <td>02:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.947000</td>\n",
       "      <td>#na#</td>\n",
       "      <td>02:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.938041</td>\n",
       "      <td>#na#</td>\n",
       "      <td>02:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.966872</td>\n",
       "      <td>#na#</td>\n",
       "      <td>02:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.897810</td>\n",
       "      <td>#na#</td>\n",
       "      <td>02:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.919714</td>\n",
       "      <td>#na#</td>\n",
       "      <td>02:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.915541</td>\n",
       "      <td>#na#</td>\n",
       "      <td>02:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.921538</td>\n",
       "      <td>#na#</td>\n",
       "      <td>02:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.929760</td>\n",
       "      <td>#na#</td>\n",
       "      <td>02:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.917652</td>\n",
       "      <td>#na#</td>\n",
       "      <td>02:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.891943</td>\n",
       "      <td>#na#</td>\n",
       "      <td>02:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.906703</td>\n",
       "      <td>#na#</td>\n",
       "      <td>02:25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ===  0  ===  RPE  === \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.199312</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.659583</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.041506</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.722279</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.544840</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.399979</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.356227</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.321491</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.319601</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.268589</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.208600</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.190684</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.170229</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.145859</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.144356</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.119259</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.140692</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.130990</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.109197</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.109071</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.066612</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.069292</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.047864</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1.098053</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.067609</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ===  0  ===  U2OS  === \n"
     ]
    }
   ],
   "source": [
    "for pg in range(1):\n",
    "    for ct in cts:\n",
    "        print(' === ', pg ,' === ', ct , ' === ')\n",
    "        if ct == 'U2OS': continue \n",
    "        # U2OS training is super instable, therefore, we train it later alone!\n",
    "        \n",
    "        #if pg == 0 or ct == 'U2OS': continue\n",
    "\n",
    "        # VALID SPLIT (incl. tfms)\n",
    "        data = (ImageList6Dct.from_df(df_train[(df_train['pg'] == pg) & (df_train['celltype'] == ct)], path='train')\n",
    "        .split_none() # !!!\n",
    "        .label_from_df(cols=-5)\n",
    "        #.add_test(ImageList6Dct.from_df(df_test[(df_test['pg'] == pg) & (df_test['celltype'] == ct)], path='test'))\n",
    "        .transform(tfms, size=sz)\n",
    "        .databunch(bs=bs))\n",
    "        \n",
    "        data.normalize([stats_mean, stats_var]);\n",
    "        \n",
    "        learn = Learner(data, adacos_efficientnet, metrics=[accuracy], callback_fns=[CSVLogger, AppendBatchTargs])\n",
    "        learn.load('effnet/adacos_efficientnet_b3_ct_pg_exp_Pre060e050pg'+str(pg)+'e100_190901');\n",
    "        learn.unfreeze()\n",
    "        learn.fit_one_cycle(25, max_lr=1e-4)\n",
    "        learn.save('effnet/adacos_efficientnet_b3_ct_pg_exp_Pre060e050pg'+str(pg)+'e100'+ct+'_FULL_025_190903');\n",
    "        \n",
    "        print('')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.889803Z",
     "start_time": "2019-09-04T18:23:08.248Z"
    }
   },
   "outputs": [],
   "source": [
    "for pg in range(4):\n",
    "    for ct in cts:\n",
    "        print(' === ', pg ,' === ', ct , ' === ')\n",
    "        print('train: ', df_train[(df_train['pg'] == pg) & (df_train['celltype'] == ct)].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train pg & ct #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.890520Z",
     "start_time": "2019-09-04T18:23:08.261Z"
    }
   },
   "outputs": [],
   "source": [
    "for pg in range(4):\n",
    "    for ct in cts:\n",
    "        print(' === ', pg ,' === ', ct , ' === ')\n",
    "\n",
    "        # VALID SPLIT (incl. tfms)\n",
    "        data = (ImageList6Dct.from_df(df_train[(df_train['pg'] == pg) & (df_train['celltype'] == ct)], path='train')\n",
    "        .split_from_df(col=-3) # FULL: .split_none() # !!!\n",
    "        .label_from_df(cols=-5)\n",
    "        #.add_test(ImageList6Dct.from_df(df_test[(df_test['pg'] == pg) & (df_test['celltype'] == ct)], path='test'))\n",
    "        .transform(tfms, size=sz)\n",
    "        .databunch(bs=bs))\n",
    "        \n",
    "        data.normalize([stats_mean, stats_var]);\n",
    "        \n",
    "        learn = Learner(data, adacos_efficientnet, metrics=[accuracy], callback_fns=[CSVLogger, AppendBatchTargs])\n",
    "        learn.load('effnet/adacos_efficientnet_b3_ct_pg_exp_Pre060e050pg'+str(pg)+'e100_190901');\n",
    "        learn.unfreeze()\n",
    "        learn.fit_one_cycle(25, max_lr=1e-4)\n",
    "        learn.save('effnet/adacos_efficientnet_b3_ct_pg_exp_Pre060e050pg'+str(pg)+'e100'+ct+'025_190903');\n",
    "        \n",
    "        print('')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.891232Z",
     "start_time": "2019-09-04T18:23:08.269Z"
    }
   },
   "outputs": [],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.891946Z",
     "start_time": "2019-09-04T18:23:08.278Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train[(df_train['pg'] == 0) & (df_train['celltype'] == 'HEPG2')].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Classifcation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.892656Z",
     "start_time": "2019-09-04T18:23:08.290Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.load('resnet50/adacos_se_xresnet50c_val-split-v2_128e040-256e106CMe110_20190729');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.893364Z",
     "start_time": "2019-09-04T18:23:08.299Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get prediction of test dataset\n",
    "preds, _ = learn.get_preds(ds_type=DatasetType.Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.894076Z",
     "start_time": "2019-09-04T18:23:08.308Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# check length\n",
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.894790Z",
     "start_time": "2019-09-04T18:23:08.317Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get the categories\n",
    "preds_cat = preds.argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.895499Z",
     "start_time": "2019-09-04T18:23:08.325Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get the names\n",
    "preds_names = learn.data.test_ds.x.items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.896214Z",
     "start_time": "2019-09-04T18:23:08.334Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# without site\n",
    "#preds_names = [x.split('/')[1]+'_'+x.split('/')[2][-1]+'_'+x.split('/')[3][:3] for x in preds_names]\n",
    "\n",
    "# with site\n",
    "preds_names = [x.split('/')[1]+'_'+x.split('/')[2][-1]+'_'+x.split('/')[3] for x in preds_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.896924Z",
     "start_time": "2019-09-04T18:23:08.343Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_preds = pd.DataFrame({'id_code_site': preds_names, 'sirna': preds_cat})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.897636Z",
     "start_time": "2019-09-04T18:23:08.351Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get id_code without site\n",
    "df_preds['id_code'] = df_preds['id_code_site'].apply(lambda x: x[:-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.898349Z",
     "start_time": "2019-09-04T18:23:08.362Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get row indices with the same/not the same the prediction for both sites\n",
    "idx = [] # indices with the same prediction\n",
    "idx_notsame = [] # indices with not the same prediction\n",
    "for i, r in enumerate(df_preds.sort_values('id_code').iterrows()):\n",
    "    if i % 2:\n",
    "        # distance from row 2 is \n",
    "        if pred == r[1]['sirna']:\n",
    "            idx.append(r[0])\n",
    "        else:\n",
    "            #idx.append(r[0]) # always append idx until we come up with something better\n",
    "            idx.append(idx_row_before)\n",
    "            idx_notsame.append(idx_row_before) # get the first rows of the pairs that are not the same\n",
    "    else:\n",
    "        # save dist from row 1 for comparison in next iteration\n",
    "        pred = r[1]['sirna']\n",
    "        idx_row_before = r[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.899061Z",
     "start_time": "2019-09-04T18:23:08.372Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(idx), len(idx_notsame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.899770Z",
     "start_time": "2019-09-04T18:23:08.383Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "idx[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.900474Z",
     "start_time": "2019-09-04T18:23:08.393Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_preds.sort_values('id_code').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.901179Z",
     "start_time": "2019-09-04T18:23:08.404Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#df_preds.loc[idx,['id_code','sirna']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.901889Z",
     "start_time": "2019-09-04T18:23:08.423Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 'effnet/adacos_efficientnet_b3_e080CM112_190805'\n",
    "model = 'metriclearn_efficientnet_b3_e080CM112_190805'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.902600Z",
     "start_time": "2019-09-04T18:23:08.434Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_preds.loc[idx,['id_code','sirna']].to_csv('sub/'+model+'.csv.gz', index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.903311Z",
     "start_time": "2019-09-04T18:23:08.443Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c recursion-cellular-image-classification -f sub/{model}.csv.gz -m \"{model}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosinus similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full single features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.904019Z",
     "start_time": "2019-09-04T18:23:08.458Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://github.com/ducha-aiki/whale-identification-2018/blob/master/reproduce_problems.ipynb\n",
    "# And for test-time augmentation I used following random solution: switch train and val transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.904861Z",
     "start_time": "2019-09-04T18:23:08.468Z"
    }
   },
   "outputs": [],
   "source": [
    "# extended tfms\n",
    "tfms = get_transforms(do_flip=True, flip_vert=True, \n",
    "                      max_rotate=90.0, max_zoom=1.1, \n",
    "                      max_lighting=0.2, max_warp=0.2, \n",
    "                      p_affine=0.75, p_lighting=0.75, \n",
    "                      xtra_tfms=[color_augmentation()])\n",
    "\n",
    "# crop_pad: https://forums.fast.ai/t/misc-issues/35386/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.905576Z",
     "start_time": "2019-09-04T18:23:08.477Z"
    }
   },
   "outputs": [],
   "source": [
    "# extended tfms w/o color_augmentation !!!\n",
    "#tfms = get_transforms(do_flip=True, flip_vert=True, \n",
    "#                      max_rotate=90.0, max_zoom=1.1, \n",
    "#                      max_lighting=0.2, max_warp=0.2, \n",
    "#                      p_affine=0.75, p_lighting=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.906284Z",
     "start_time": "2019-09-04T18:23:08.485Z"
    }
   },
   "outputs": [],
   "source": [
    "# \"crop_pad\" to sz\n",
    "tfms[0][0] = crop_pad(size=sz, row_pct=[0.,1.], col_pct=[0.,1.])\n",
    "tfms[1][0] = crop_pad(size=sz, row_pct=[0.,1.], col_pct=[0.,1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.906998Z",
     "start_time": "2019-09-04T18:23:08.493Z"
    }
   },
   "outputs": [],
   "source": [
    "#sz, bs = 300, 8*2*2 # 3436MiB /  7952MiB\n",
    "#sz, bs = 300, 8*8 # 6884MiB /  7952MiB\n",
    "sz, bs = 300, 8*11 # 7938MiB /  7952MiB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.907706Z",
     "start_time": "2019-09-04T18:23:08.501Z"
    }
   },
   "outputs": [],
   "source": [
    "#pg = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.908417Z",
     "start_time": "2019-09-04T18:23:08.509Z"
    }
   },
   "outputs": [],
   "source": [
    "# VALID SPLIT (incl. tfms)\n",
    "data = (ImageList6Dct.from_df(df_train[df_train['pg'] == pg], path='train')\n",
    "        .split_from_df(col=-3) # FULL: .split_none() # !!!\n",
    "        .label_from_df(cols=-5)\n",
    "        .add_test(ImageList6Dct.from_df(df_test[df_test['pg'] == pg], path='test'))\n",
    "        .transform(tfms, size=sz)\n",
    "        .databunch(bs=bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.909124Z",
     "start_time": "2019-09-04T18:23:08.518Z"
    }
   },
   "outputs": [],
   "source": [
    "data.normalize([stats_mean, stats_var]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.909829Z",
     "start_time": "2019-09-04T18:23:08.526Z"
    }
   },
   "outputs": [],
   "source": [
    "#ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.910539Z",
     "start_time": "2019-09-04T18:23:08.535Z"
    }
   },
   "outputs": [],
   "source": [
    "pg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.911251Z",
     "start_time": "2019-09-04T18:23:08.543Z"
    }
   },
   "outputs": [],
   "source": [
    "#data.train_dl.dl.batch_sampler.sampler = torch.utils.data.SequentialSampler(data.train_ds)\n",
    "#data.train_dl.dl.batch_sampler.drop_last = False\n",
    "#\n",
    "#data.valid_dl.dl.batch_sampler.sampler = torch.utils.data.SequentialSampler(data.valid_ds)\n",
    "#data.valid_dl.dl.batch_sampler.drop_last = False\n",
    "#\n",
    "## DOES WORK TOO FOR TEST DL ??? ??? (Or do we need to set the test dataset to the valid dataset?)\n",
    "#data.test_dl.dl.batch_sampler.sampler = torch.utils.data.SequentialSampler(data.test_ds)\n",
    "#data.test_dl.dl.batch_sampler.drop_last = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.911960Z",
     "start_time": "2019-09-04T18:23:08.556Z"
    }
   },
   "outputs": [],
   "source": [
    "learn = Learner(data, adacos_efficientnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.912665Z",
     "start_time": "2019-09-04T18:23:08.564Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.load('effnet/adacos_efficientnet_b3_ct_pg_exp_Pre060e050pg'+str(pg)+'e100_190901');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.913378Z",
     "start_time": "2019-09-04T18:23:08.572Z"
    }
   },
   "outputs": [],
   "source": [
    "#def get_feats(model, dataloader, cycles=1):\n",
    "#    feats = []\n",
    "#    targs = []\n",
    "#    model.eval()\n",
    "#    with torch.no_grad():\n",
    "#        for i in range(cycles): # for TTA\n",
    "#            for xb, yb in dataloader:\n",
    "#                body_out = model.body(xb)\n",
    "#                head_out = model.head(body_out)\n",
    "#                feats.append(head_out.cpu())\n",
    "#                targs.append(yb.cpu())\n",
    "#    return feats, targs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.914089Z",
     "start_time": "2019-09-04T18:23:08.580Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_feats(model, dataloader, cycles=1):\n",
    "    feats = []\n",
    "    targs = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(cycles): # for TTA\n",
    "            for xb, yb in dataloader:\n",
    "                xb_img, xb_ctint, xb_pgint, xb_expint = xb\n",
    "                img_features = model.body1(xb_img)\n",
    "                int_features = model.body2(xb_ctint, xb_pgint, xb_expint)\n",
    "                features = torch.cat((img_features, int_features), dim=-1)\n",
    "                out = model.head(features)\n",
    "                feats.append(out.cpu())\n",
    "                targs.append(yb.cpu())\n",
    "    return feats, targs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.914809Z",
     "start_time": "2019-09-04T18:23:08.589Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_img_exp_feats(model, dataloader, cycles=1):\n",
    "    feats = []\n",
    "    targs = []\n",
    "    img_feats = []\n",
    "    exp_input = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(cycles): # for TTA\n",
    "            for xb, yb in dataloader:\n",
    "                xb_img, xb_ctint, xb_pgint, xb_expint = xb\n",
    "                img_features = model.body1(xb_img)\n",
    "                int_features = model.body2(xb_ctint, xb_pgint, xb_expint)\n",
    "                features = torch.cat((img_features, int_features), dim=-1)\n",
    "                out = model.head(features)\n",
    "                feats.append(out.cpu())\n",
    "                targs.append(yb.cpu())\n",
    "                img_feats.append(img_features)\n",
    "                exp_input.append(xb_expint.cpu())\n",
    "    return feats, targs, img_feats, exp_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.915522Z",
     "start_time": "2019-09-04T18:23:08.600Z"
    }
   },
   "outputs": [],
   "source": [
    "feats, targs = get_feats(learn.model, learn.data.train_dl, cycles=3)\n",
    "#feats, targs, img_feats, exp_input = get_img_exp_feats(learn.model, learn.data.train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.916233Z",
     "start_time": "2019-09-04T18:23:08.608Z"
    }
   },
   "outputs": [],
   "source": [
    "feats = torch.cat(feats, dim=0)\n",
    "targs = torch.cat(targs, dim=0)\n",
    "#img_feats = torch.cat(img_feats, dim=0)\n",
    "#exp_input = torch.cat(exp_input, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.916943Z",
     "start_time": "2019-09-04T18:23:08.617Z"
    }
   },
   "outputs": [],
   "source": [
    "# get class from data classes index\n",
    "targs_cl = torch.tensor([learn.data.classes[t] for t in targs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.917649Z",
     "start_time": "2019-09-04T18:23:08.627Z"
    }
   },
   "outputs": [],
   "source": [
    "feats.shape, targs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.918360Z",
     "start_time": "2019-09-04T18:23:08.636Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save('pred/feats_train_pg'+str(pg)+'.npy', feats)\n",
    "np.save('pred/targs_train_pg'+str(pg)+'.npy', targs)\n",
    "np.save('pred/targs_cl_train_pg'+str(pg)+'.npy', targs_cl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.919080Z",
     "start_time": "2019-09-04T18:23:08.646Z"
    }
   },
   "outputs": [],
   "source": [
    "feats, targs = get_feats(learn.model, learn.data.valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.919792Z",
     "start_time": "2019-09-04T18:23:08.655Z"
    }
   },
   "outputs": [],
   "source": [
    "feats = torch.cat(feats, dim=0)\n",
    "targs = torch.cat(targs, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.920503Z",
     "start_time": "2019-09-04T18:23:08.665Z"
    }
   },
   "outputs": [],
   "source": [
    "# get class from data classes index\n",
    "targs_cl = torch.tensor([learn.data.classes[t] for t in targs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.921214Z",
     "start_time": "2019-09-04T18:23:08.675Z"
    }
   },
   "outputs": [],
   "source": [
    "feats.shape, feats.shape, targs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.921925Z",
     "start_time": "2019-09-04T18:23:08.690Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save('pred/feats_valid_pg'+str(pg)+'.npy', feats)\n",
    "np.save('pred/targs_valid_pg'+str(pg)+'.npy', targs)\n",
    "np.save('pred/targs_cl_valid_pg'+str(pg)+'.npy', targs_cl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.922640Z",
     "start_time": "2019-09-04T18:23:08.710Z"
    }
   },
   "outputs": [],
   "source": [
    "feats, targs = get_feats(learn.model, learn.data.test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.923352Z",
     "start_time": "2019-09-04T18:23:08.723Z"
    }
   },
   "outputs": [],
   "source": [
    "del targs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.924064Z",
     "start_time": "2019-09-04T18:23:08.740Z"
    }
   },
   "outputs": [],
   "source": [
    "feats = torch.cat(feats, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.924772Z",
     "start_time": "2019-09-04T18:23:08.748Z"
    }
   },
   "outputs": [],
   "source": [
    "feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.925482Z",
     "start_time": "2019-09-04T18:23:08.758Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save('pred/feats_test_pg'+str(pg)+'.npy', feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.926193Z",
     "start_time": "2019-09-04T18:23:08.767Z"
    }
   },
   "outputs": [],
   "source": [
    "len(learn.data.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Multi-crop features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.926907Z",
     "start_time": "2019-09-04T18:23:08.778Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# https://github.com/ducha-aiki/whale-identification-2018/blob/master/reproduce_problems.ipynb\n",
    "# And for test-time augmentation I used following random solution: switch train and val transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.927621Z",
     "start_time": "2019-09-04T18:23:08.787Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_train['test'] = 0\n",
    "df_train['path'] = 'train/'+df_train['path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.928330Z",
     "start_time": "2019-09-04T18:23:08.797Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.929041Z",
     "start_time": "2019-09-04T18:23:08.806Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# add dummy columns for test dataset\n",
    "df_test['path'] = 'test/'+df_test['path']\n",
    "df_test['test'] = 1\n",
    "df_test['sirna'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.929751Z",
     "start_time": "2019-09-04T18:23:08.816Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.930469Z",
     "start_time": "2019-09-04T18:23:08.825Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_train_test = pd.concat((df_train, df_test), axis=0, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.931185Z",
     "start_time": "2019-09-04T18:23:08.834Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_train_test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.931896Z",
     "start_time": "2019-09-04T18:23:08.843Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# reload for train and valid ds\n",
    "df_train = pd.read_csv('full_train_dataset_valid-split-ex_v2_20190727.csv', index_col=0)\n",
    "df_test = pd.read_csv('full_test_dataset_v2_20190727.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T17:44:39.974069Z",
     "start_time": "2019-08-05T17:44:39.962352Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.932608Z",
     "start_time": "2019-09-04T18:23:08.857Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# test tfms switching for test ds\n",
    "#tfms_switched = (tfms[1], tfms[0])\n",
    "#\n",
    "#data = (ImageList6D.from_df(df_train_test, path='.')\n",
    "#                .split_from_df(col=-1)\n",
    "#                .label_from_df(cols=-4)\n",
    "#                .transform(tfms_switched)#, size=sz) # remove size so we get the crop size!\n",
    "#                .databunch(bs=bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.933320Z",
     "start_time": "2019-09-04T18:23:08.866Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#data.train_ds[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.934026Z",
     "start_time": "2019-09-04T18:23:08.875Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#data.valid_ds[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.934754Z",
     "start_time": "2019-09-04T18:23:08.892Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_dataset(row_pct, col_pct, is_test=False):\n",
    "    # extended tfms\n",
    "    tfms = get_transforms(do_flip=True, flip_vert=True, \n",
    "                          max_rotate=90.0, max_zoom=1.1, \n",
    "                          max_lighting=0.2, max_warp=0.2, \n",
    "                          p_affine=0.75, p_lighting=0.75, \n",
    "                          xtra_tfms=[color_augmentation()])\n",
    "    \n",
    "    # change \"crop_pad\" from get_transforms to \"crop\"\n",
    "    tfms[0][0] = crop(size=sz, row_pct=row_pct, col_pct=col_pct)\n",
    "    tfms[1][0] = crop(size=sz, row_pct=row_pct, col_pct=col_pct)\n",
    "    \n",
    "    # VALID SPLIT (incl. tfms)\n",
    "    if is_test:\n",
    "        #switch train with valid (= test) tfms!\n",
    "        tfms_switched = (tfms[1], tfms[0])\n",
    "        \n",
    "        data = (ImageList6D.from_df(df_train_test, path='.')\n",
    "                .split_from_df(col=-1)\n",
    "                .label_from_df(cols=-4)\n",
    "                .transform(tfms_switched)#, size=sz) # remove size so we get the crop size!\n",
    "                .databunch(bs=bs))\n",
    "    else:\n",
    "        data = (ImageList6D.from_df(df_train, path='train')\n",
    "                .split_from_df(col=-1) # split_by_rand_pct()\n",
    "                .label_from_df(cols=-3)\n",
    "                #.add_test(ImageList6D.from_df(df_test, path='test'))\n",
    "                .transform(tfms)#, size=sz) # remove size so we get the crop size!\n",
    "                .databunch(bs=bs))\n",
    "    \n",
    "    data.normalize([tensor([0.0456, 0.0702, 0.0447, 0.0468, 0.0407, 0.0399]),\n",
    "                    tensor([0.0644, 0.0733, 0.0536, 0.0633, 0.0555, 0.0392])]);\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.935466Z",
     "start_time": "2019-09-04T18:23:08.904Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_feats(model, dataloader, cycles=1):\n",
    "    feats = []\n",
    "    targs = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(cycles): # for TTA\n",
    "            for xb, yb in dataloader:\n",
    "                body_out = model.body(xb)\n",
    "                head_out = model.head(body_out)\n",
    "                feats.append(head_out.cpu())\n",
    "                targs.append(yb.cpu())\n",
    "                \n",
    "    feats = torch.cat(feats, dim=0)\n",
    "    targs = torch.cat(targs, dim=0)\n",
    "    \n",
    "    return feats, targs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.936177Z",
     "start_time": "2019-09-04T18:23:08.913Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def save_feats(feats, targs, crop, ds='train'):\n",
    "    np.save(f'pred/feats_{ds}_crop{crop}.npy', feats)\n",
    "    np.save(f'pred/targs_{ds}_crop{crop}.npy', targs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.936888Z",
     "start_time": "2019-09-04T18:23:08.922Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#https://docs.fast.ai/vision.transform.html#_crop\n",
    "crop_pos = [[0.,0.], [0.,1.],[0.5,0.5],[1.,0.], [1.,1.]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.937599Z",
     "start_time": "2019-09-04T18:23:08.931Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get random crop pos\n",
    "i = 2\n",
    "crop_pos = [[uniform(0,1), uniform(0,1)] for i in range(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.938309Z",
     "start_time": "2019-09-04T18:23:08.941Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "crop_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.939026Z",
     "start_time": "2019-09-04T18:23:08.950Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get the last three crop positions:\n",
    "crop_pos = [[0.5,0.5],[1.,0.], [1.,1.]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.939744Z",
     "start_time": "2019-09-04T18:23:08.959Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_crop_feats(model=learn.model, cycles=1, crop_pos=crop_pos):\n",
    "    \n",
    "    for i, (row_pct, col_pct) in enumerate(crop_pos):\n",
    "        \n",
    "        print('== crop#:', i,' of', len(crop_pos), '==')\n",
    "        print('row_pct:', row_pct,', col_pct:', col_pct)\n",
    "    \n",
    "        data = get_dataset(row_pct, col_pct)\n",
    "        \n",
    "        # train\n",
    "        print('= Start train dataset =')\n",
    "        feats, targs = get_feats(model, data.train_dl)\n",
    "        save_feats(feats, targs, i, ds='train')\n",
    "        print('feats:', feats.shape,' targs:', targs.shape)\n",
    "        print('- Finish train dataset -')\n",
    "        \n",
    "        # valid\n",
    "        print('= Start valid dataset =')\n",
    "        feats, targs = get_feats(model, data.valid_dl)\n",
    "        save_feats(feats, targs, i, ds='valid')\n",
    "        print('feats:', feats.shape,' targs:', targs.shape)\n",
    "        print('- Finish valid dataset -')\n",
    "        \n",
    "        # get test ds as valid ds for TTA\n",
    "        data = get_dataset(row_pct, col_pct, is_test=True)\n",
    "        \n",
    "        # test\n",
    "        print('= Start test dataset =')\n",
    "        feats, targs = get_feats(model, data.valid_dl)\n",
    "        save_feats(feats, targs, i, ds='test')\n",
    "        print('feats:', feats.shape,' targs:', targs.shape)\n",
    "        print('- Finish test dataset -')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.940453Z",
     "start_time": "2019-09-04T18:23:08.969Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn = Learner(data, adacos_efficientnet_b3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.941163Z",
     "start_time": "2019-09-04T18:23:08.982Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.load('effnet/adacos_efficientnet_b3_e080CM112_190805');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.941875Z",
     "start_time": "2019-09-04T18:23:08.991Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "get_crop_feats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.942590Z",
     "start_time": "2019-09-04T18:23:09.018Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#data = (ImageList6D.from_df(df_train_test, path='.')\n",
    "#        .split_from_df(col=-1)\n",
    "#        .label_from_df(cols=-4)\n",
    "#        .transform(tfms_switched)#, size=sz) # remove size so we get the crop size!\n",
    "#        .databunch(bs=bs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.943301Z",
     "start_time": "2019-09-04T18:23:09.033Z"
    }
   },
   "outputs": [],
   "source": [
    "# get the names\n",
    "preds_names = learn.data.test_ds.x.items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.944013Z",
     "start_time": "2019-09-04T18:23:09.044Z"
    }
   },
   "outputs": [],
   "source": [
    "# without site\n",
    "#preds_names = [x.split('/')[1]+'_'+x.split('/')[2][-1]+'_'+x.split('/')[3][:3] for x in preds_names]\n",
    "\n",
    "# with site\n",
    "preds_names = [x.split('/')[1]+'_'+x.split('/')[2][-1]+'_'+x.split('/')[3] for x in preds_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.944723Z",
     "start_time": "2019-09-04T18:23:09.053Z"
    }
   },
   "outputs": [],
   "source": [
    "preds_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.945442Z",
     "start_time": "2019-09-04T18:23:09.062Z"
    }
   },
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/27745500/how-to-save-a-list-to-a-file-and-read-it-as-a-list-type\n",
    "with open('pred/preds_test_pg'+str(pg)+'_names.txt', 'wb') as fp:   #Pickling\n",
    "    pickle.dump(preds_names, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.946155Z",
     "start_time": "2019-09-04T18:23:09.071Z"
    }
   },
   "outputs": [],
   "source": [
    "#with open('pred/preds_test_pg'+str(pg)+'_names.txt', 'rb') as fp:   # Unpickling\n",
    "#    b = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.946870Z",
     "start_time": "2019-09-04T18:23:09.082Z"
    }
   },
   "outputs": [],
   "source": [
    "preds_test = np.load('pred/preds_test_pg'+str(pg)+'.npy')\n",
    "dist_test = np.load('pred/dist_test_pg'+str(pg)+'.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.947581Z",
     "start_time": "2019-09-04T18:23:09.094Z"
    }
   },
   "outputs": [],
   "source": [
    "len(preds_names), len(preds_test), len(dist_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.948293Z",
     "start_time": "2019-09-04T18:23:09.103Z"
    }
   },
   "outputs": [],
   "source": [
    "#preds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.949001Z",
     "start_time": "2019-09-04T18:23:09.112Z"
    }
   },
   "outputs": [],
   "source": [
    "#dist_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.949712Z",
     "start_time": "2019-09-04T18:23:09.121Z"
    }
   },
   "outputs": [],
   "source": [
    "df_preds = pd.DataFrame({'id_code_site': preds_names, 'sirna': preds_test, 'cossim': dist_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.950422Z",
     "start_time": "2019-09-04T18:23:09.130Z"
    }
   },
   "outputs": [],
   "source": [
    "# get id_code without site\n",
    "df_preds['id_code'] = df_preds['id_code_site'].apply(lambda x: x[:-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.951143Z",
     "start_time": "2019-09-04T18:23:09.139Z"
    }
   },
   "outputs": [],
   "source": [
    "# get row indices with highest cosine similiarity\n",
    "idx = []\n",
    "for i, r in enumerate(df_preds.sort_values('id_code').iterrows()):\n",
    "    #print(r)\n",
    "    #print('i: ',i)\n",
    "    #print('idx: ',r[0])\n",
    "    #print(r[1]['cossim'])\n",
    "    if i % 2:\n",
    "        # distance from row 2 is \n",
    "        if dist < r[1]['cossim']:\n",
    "            idx.append(r[0])\n",
    "        else:\n",
    "            idx.append(idx_row_before)\n",
    "    else:\n",
    "        # save dist from row 1 for comparison in next iteration\n",
    "        dist = r[1]['cossim']\n",
    "        idx_row_before = r[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.951850Z",
     "start_time": "2019-09-04T18:23:09.149Z"
    }
   },
   "outputs": [],
   "source": [
    "idx[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.952556Z",
     "start_time": "2019-09-04T18:23:09.157Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_preds.sort_values('id_code').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.953266Z",
     "start_time": "2019-09-04T18:23:09.165Z"
    }
   },
   "outputs": [],
   "source": [
    "#df_preds.loc[idx,['id_code','sirna']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.953981Z",
     "start_time": "2019-09-04T18:23:09.179Z"
    }
   },
   "outputs": [],
   "source": [
    "# 'effnet/adacos_efficientnet_b3_ct_pg_exp_Pre060e050pg'+str(pg)+'e100_190901'\n",
    "model = 'adacos_efficientnet_b3_ct_pg_exp_Pre060e050pg'+str(pg)+'e100_190901_3xTTA-cossim'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.954697Z",
     "start_time": "2019-09-04T18:23:09.188Z"
    }
   },
   "outputs": [],
   "source": [
    "df_preds.loc[idx,['id_code','sirna']].to_csv('sub/'+model+'.csv.gz', index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.955409Z",
     "start_time": "2019-09-04T18:23:09.197Z"
    }
   },
   "outputs": [],
   "source": [
    "#!kaggle competitions submit -c recursion-cellular-image-classification -f sub/{model}.csv.gz -m \"{model}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.956126Z",
     "start_time": "2019-09-04T18:23:09.208Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('pred/preds_test_pg'+str(pg)+'_names.txt', 'rb') as fp:   # Unpickling\n",
    "    preds_names = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.956835Z",
     "start_time": "2019-09-04T18:23:09.217Z"
    }
   },
   "outputs": [],
   "source": [
    "preds_test_full = np.load('pred/preds_test_pg'+str(pg)+'_full.npy')\n",
    "dist_test_full = np.load('pred/dist_test_pg'+str(pg)+'_full.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.957552Z",
     "start_time": "2019-09-04T18:23:09.227Z"
    }
   },
   "outputs": [],
   "source": [
    "preds_test_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.958257Z",
     "start_time": "2019-09-04T18:23:09.237Z"
    }
   },
   "outputs": [],
   "source": [
    "dist_test_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.958975Z",
     "start_time": "2019-09-04T18:23:09.246Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    df_preds_full = pd.DataFrame({'id_code_site': preds_names,\n",
    "                                  'sirna': preds_test_full[:,i],\n",
    "                                  'cossim': dist_test_full[:,i]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.960050Z",
     "start_time": "2019-09-04T18:23:09.255Z"
    }
   },
   "outputs": [],
   "source": [
    "type(preds_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.960772Z",
     "start_time": "2019-09-04T18:23:09.271Z"
    }
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "df_preds_full = pd.DataFrame({'id_code_site': preds_names,\n",
    "                                  'sirna': preds_test_full[:,i],\n",
    "                                  'cossim': dist_test_full[:,i]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.961493Z",
     "start_time": "2019-09-04T18:23:09.280Z"
    }
   },
   "outputs": [],
   "source": [
    "df_preds_full.sort_values(by='cossim', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.962221Z",
     "start_time": "2019-09-04T18:23:09.289Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "for i, d in df_preds_full.sort_values(by='cossim', ascending=False).iterrows():\n",
    "    print(i)\n",
    "    print(d)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.962942Z",
     "start_time": "2019-09-04T18:23:09.298Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test.head()#.experiment.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.963652Z",
     "start_time": "2019-09-04T18:23:09.310Z"
    }
   },
   "outputs": [],
   "source": [
    "df_preds_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.964375Z",
     "start_time": "2019-09-04T18:23:09.319Z"
    }
   },
   "outputs": [],
   "source": [
    "df_preds_full.groupby('sirna')['id_code_site'].nunique()#.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-04T18:23:10.965087Z",
     "start_time": "2019-09-04T18:23:09.330Z"
    }
   },
   "outputs": [],
   "source": [
    "# ERROR ANALYSIS !!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "488px",
    "width": "305px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "206px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
