{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:34.451816Z",
     "start_time": "2019-09-03T04:30:34.294032Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:35.093252Z",
     "start_time": "2019-09-03T04:30:34.453005Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from fastai.vision import *\n",
    "from fastai.vision.models.xresnet import *\n",
    "\n",
    "# for datablock API\n",
    "from fastai.vision.image import _resolve_tfms, _get_crop_target, _round_multiple, _get_resize_target, _affine_grid, _grid_sample, _affine_mult\n",
    "\n",
    "# for XResNet\n",
    "#from fastai.vision.models.xresnet import act_fn, init_cnn, conv, noop, conv_layer, ResBlock, filt_sz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:35.105496Z",
     "start_time": "2019-09-03T04:30:35.094759Z"
    }
   },
   "outputs": [],
   "source": [
    "from fastai.callbacks import CSVLogger, ReduceLROnPlateauCallback, SaveModelCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:35.117971Z",
     "start_time": "2019-09-03T04:30:35.106621Z"
    }
   },
   "outputs": [],
   "source": [
    "from efficientnet_pytorch import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:35.129876Z",
     "start_time": "2019-09-03T04:30:35.118854Z"
    }
   },
   "outputs": [],
   "source": [
    "from nb_new_data_augmentation_adacos_celltype_plategroup_exp import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:35.141009Z",
     "start_time": "2019-09-03T04:30:35.130902Z"
    }
   },
   "outputs": [],
   "source": [
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:35.153352Z",
     "start_time": "2019-09-03T04:30:35.141915Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.55'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6D image with celltype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:35.168980Z",
     "start_time": "2019-09-03T04:30:35.154907Z"
    }
   },
   "outputs": [],
   "source": [
    "class Image6Dct(Image):\n",
    "    \"Support applying transforms to image data in `px`.\"\n",
    "    def __init__(self, px:Tensor, ctint, pgint, expint): # ct\n",
    "        self._px = px\n",
    "        self._logit_px=None\n",
    "        #self.ct = ct\n",
    "        self.ctint = ctint\n",
    "        self.pgint = pgint\n",
    "        self.expint = expint\n",
    "        self._flow=None\n",
    "        self._affine_mat=None\n",
    "        self.sample_kwargs = {}\n",
    "    \n",
    "    def _repr_image_format(self, format_str):\n",
    "        with BytesIO() as str_buffer:\n",
    "            #plt.imsave(str_buffer, image2np(self.px[:3]), format=format_str)\n",
    "            plt.imsave(str_buffer, \n",
    "                       np.concatenate((image2np(self.px[:3]), \n",
    "                                       image2np(self.px[3:])), axis=1),\n",
    "                       format=format_str)\n",
    "            return str_buffer.getvalue()\n",
    "        \n",
    "    def clone(self):\n",
    "        \"Mimic the behavior of torch.clone for `Image` objects.\"\n",
    "        return self.__class__(self.px.clone(), self.ctint.clone(), self.pgint.clone(), self.expint.clone()) # self.ct.clone(), \n",
    "\n",
    "    @property\n",
    "    def data(self)->TensorImage:\n",
    "        \"Return this images pixels as a tensor.\"\n",
    "        return self.px, self.ctint, self.pgint, self.expint\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:35.186417Z",
     "start_time": "2019-09-03T04:30:35.170286Z"
    }
   },
   "outputs": [],
   "source": [
    "def open_image_6Dct(fn:PathOrStr, div:bool=True, convert_mode:str='L', cls:type=Image6Dct,\n",
    "        after_open:Callable=None)->Image:\n",
    "    \"Return `Image` object created from image in file `fn`.\"\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", UserWarning) # EXIF warning from TiffPlugin\n",
    "        \n",
    "        x = []\n",
    "        for i in range(6):\n",
    "            c = PIL.Image.open(fn+'_w'+str(i+1)+'.png').convert(convert_mode)\n",
    "            if after_open: c = after_open(c)\n",
    "            c = np.asarray(c)\n",
    "            c = torch.from_numpy(c.astype(np.float32, copy=False))\n",
    "            x.append(c)\n",
    "    ct = fn.split('/')[1].split('-')[0] # get cell type\n",
    "    ctint = torch.tensor(ct2int[ct])\n",
    "    pgint = torch.tensor(fn2pgint[fn])\n",
    "    exp = fn.split('/')[1] # get experiment\n",
    "    expint = torch.tensor(exp2int[exp])\n",
    "    x = torch.stack(x)\n",
    "    if div: x.div_(255)\n",
    "    return cls(x, ctint, pgint, expint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:35.203334Z",
     "start_time": "2019-09-03T04:30:35.187911Z"
    }
   },
   "outputs": [],
   "source": [
    "# number experiments so that cell types do not overlap\n",
    "# and the valid and test dataset do have a embedding they can use!\n",
    "exp2int = {'HEPG2-01': 0,\n",
    "           'HEPG2-02': 1,\n",
    "           'HEPG2-03': 2,\n",
    "           'HEPG2-04': 3,\n",
    "           'HEPG2-05': 4,\n",
    "           # valid\n",
    "           'HEPG2-06': 0,\n",
    "           'HEPG2-07': 1,\n",
    "           # test\n",
    "           'HEPG2-08': 0,\n",
    "           'HEPG2-09': 1,\n",
    "           'HEPG2-10': 2,\n",
    "           'HEPG2-11': 3,           \n",
    "             \n",
    "           # train\n",
    "           'HUVEC-01': 5,\n",
    "           'HUVEC-02': 6,\n",
    "           'HUVEC-03': 7,\n",
    "           'HUVEC-04': 8,\n",
    "           'HUVEC-05': 9,\n",
    "           'HUVEC-06': 10,\n",
    "           'HUVEC-07': 11, \n",
    "           'HUVEC-08': 12,\n",
    "           'HUVEC-09': 13,\n",
    "           'HUVEC-10': 14,\n",
    "           'HUVEC-11': 15,\n",
    "           'HUVEC-12': 16,\n",
    "           'HUVEC-13': 17,\n",
    "           'HUVEC-14': 18, \n",
    "           # valid\n",
    "           'HUVEC-15': 5,\n",
    "           'HUVEC-16': 6, \n",
    "           # test\n",
    "           'HUVEC-17': 5,\n",
    "           'HUVEC-18': 6,\n",
    "           'HUVEC-19': 7,\n",
    "           'HUVEC-20': 8,\n",
    "           'HUVEC-21': 9,\n",
    "           'HUVEC-22': 10,\n",
    "           'HUVEC-23': 11,\n",
    "           'HUVEC-24': 12,\n",
    "             \n",
    "           # train\n",
    "           'RPE-01': 19,\n",
    "           'RPE-02': 20,\n",
    "           'RPE-03': 21,\n",
    "           'RPE-04': 22,\n",
    "           'RPE-05': 23,\n",
    "           # valid\n",
    "           'RPE-06': 19,\n",
    "           'RPE-07': 20,\n",
    "           # test\n",
    "           'RPE-08': 19,\n",
    "           'RPE-09': 20,\n",
    "           'RPE-10': 21,\n",
    "           'RPE-11': 22,\n",
    "             \n",
    "           # train\n",
    "           'U2OS-01': 24,\n",
    "           'U2OS-02': 25,\n",
    "           # valid\n",
    "           'U2OS-03': 24,\n",
    "           # test\n",
    "           'U2OS-04': 24,\n",
    "           'U2OS-05': 25\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:35.219412Z",
     "start_time": "2019-09-03T04:30:35.204527Z"
    }
   },
   "outputs": [],
   "source": [
    "#exp2int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:35.298460Z",
     "start_time": "2019-09-03T04:30:35.220535Z"
    }
   },
   "outputs": [],
   "source": [
    "df_full_plate_pattern = pd.read_csv('full_dataset_v2_path_plate_groups_only_20190812.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:35.315273Z",
     "start_time": "2019-09-03T04:30:35.299551Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>plate_pattern</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train/HEPG2-01/Plate1/B03_s1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train/HEPG2-01/Plate1/B04_s1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train/HEPG2-01/Plate1/B05_s1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train/HEPG2-01/Plate1/B06_s1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train/HEPG2-01/Plate1/B07_s1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           path  plate_pattern\n",
       "0  train/HEPG2-01/Plate1/B03_s1              0\n",
       "1  train/HEPG2-01/Plate1/B04_s1              0\n",
       "2  train/HEPG2-01/Plate1/B05_s1              0\n",
       "3  train/HEPG2-01/Plate1/B06_s1              0\n",
       "4  train/HEPG2-01/Plate1/B07_s1              0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full_plate_pattern.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:35.343026Z",
     "start_time": "2019-09-03T04:30:35.316205Z"
    }
   },
   "outputs": [],
   "source": [
    "fn2pgint = dict(zip(df_full_plate_pattern.path.values, \n",
    "                              df_full_plate_pattern.plate_pattern.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:35.355656Z",
     "start_time": "2019-09-03T04:30:35.344090Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn2pgint['train/HEPG2-01/Plate1/B03_s1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:35.368060Z",
     "start_time": "2019-09-03T04:30:35.356678Z"
    }
   },
   "outputs": [],
   "source": [
    "# cell types from rcic_v10_inspect_image_data.ipynb \"pixel stats\"\n",
    "cts = ['HEPG2', 'HUVEC', 'RPE', 'U2OS']\n",
    "int2ct = {i: ct for i, ct in enumerate(cts)}\n",
    "ct2int = {ct: i for i, ct in int2ct.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:35.381226Z",
     "start_time": "2019-09-03T04:30:35.369145Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'HEPG2', 1: 'HUVEC', 2: 'RPE', 3: 'U2OS'}\n",
      "{'HEPG2': 0, 'HUVEC': 1, 'RPE': 2, 'U2OS': 3}\n"
     ]
    }
   ],
   "source": [
    "print(int2ct)\n",
    "print(ct2int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:35.394745Z",
     "start_time": "2019-09-03T04:30:35.382826Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HEPG2'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct = 'train/HEPG2-01/Plate1/B03_s1'.split('/')[1].split('-')[0]; ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:35.410884Z",
     "start_time": "2019-09-03T04:30:35.395905Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct2int[ct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:35.423891Z",
     "start_time": "2019-09-03T04:30:35.412020Z"
    }
   },
   "outputs": [],
   "source": [
    "PATH_trunc = 'train/HEPG2-01/Plate1/B03_s1' # path is missing suffix \"_w1.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:35.507998Z",
     "start_time": "2019-09-03T04:30:35.424887Z"
    }
   },
   "outputs": [],
   "source": [
    "img = open_image_6Dct(PATH_trunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:35.521154Z",
     "start_time": "2019-09-03T04:30:35.509038Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 512, 512])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.px.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:35.540281Z",
     "start_time": "2019-09-03T04:30:35.525606Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(0), tensor(0))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.ctint, img.pgint, img.expint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:35.557776Z",
     "start_time": "2019-09-03T04:30:35.543660Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Tensor, torch.Tensor, torch.Tensor)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(img.ctint), type(img.pgint), type(img.expint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:35.576531Z",
     "start_time": "2019-09-03T04:30:35.560614Z"
    }
   },
   "outputs": [],
   "source": [
    "class ImageList6Dct(ImageList): #ImageList\n",
    "    def __init__(self, *args, convert_mode='L', after_open:Callable=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.convert_mode,self.after_open = convert_mode,after_open\n",
    "        self.copy_new.append('convert_mode')\n",
    "        self.c,self.sizes = 6,{}\n",
    "        \n",
    "    def open(self, fn):\n",
    "        \"Open image in `fn`, subclass and overwrite for custom behavior.\"\n",
    "        return open_image_6Dct(fn, convert_mode=self.convert_mode, after_open=self.after_open)\n",
    "\n",
    "#    def show(self, img):\n",
    "#        #return torch.cat((img[i][:3], img[i][3:]), dim=1)\n",
    "#        show_image(img)\n",
    "    \n",
    "    # https://docs.fast.ai/tutorial.itemlist.html#Advanced-show-methods\n",
    "    def show_xys(self, xs, ys, figsize:Tuple[int,int]=(15,10), **kwargs):\n",
    "        \"Show the `xs` and `ys` on a figure of `figsize`. `kwargs` are passed to the show method.\"\n",
    "        rows = int(math.sqrt(len(xs)))\n",
    "        fig, axs = plt.subplots(rows,rows,figsize=figsize)\n",
    "        for i, ax in enumerate(axs.flatten() if rows > 1 else [axs]):\n",
    "            #xs[i].show(ax=ax, y=ys[i], **kwargs)\n",
    "            img = Image6D(torch.cat((xs[i].data[:3], xs[i].data[3:]), dim=2)) # works but not elegant?\n",
    "            #img = Image6D(xs[i]) # does not work?\n",
    "            img.show(ax=ax, y=ys[i], **kwargs)\n",
    "        plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:35.592143Z",
     "start_time": "2019-09-03T04:30:35.579991Z"
    }
   },
   "outputs": [],
   "source": [
    "#def show_image(img:Image, ax:plt.Axes=None, figsize:tuple=(3,3), hide_axis:bool=True, cmap:str='binary',\n",
    "#                alpha:float=None, **kwargs)->plt.Axes:\n",
    "#    \"Display `Image` in notebook.\"\n",
    "#    if ax is None: fig,ax = plt.subplots(figsize=figsize)\n",
    "#    pdb.set_trace()\n",
    "#    #ax.imshow(image2np(img.data), cmap=cmap, alpha=alpha, **kwargs)\n",
    "#    ax.imshow(np.concatenate((image2np(self.px[:3]),\n",
    "#                              image2np(self.px[3:])), axis=1),\n",
    "#              cmap=cmap, alpha=alpha, **kwargs)\n",
    "#    if hide_axis: ax.axis('off')\n",
    "#    return ax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset raw files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:35.812726Z",
     "start_time": "2019-09-03T04:30:35.595691Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('full_train_dataset_valid-split-ex_v2_ct_20190824.csv', index_col=0)\n",
    "df_test = pd.read_csv('full_test_dataset_v2_ct_20190824.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:35.830758Z",
     "start_time": "2019-09-03T04:30:35.814182Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73030, 6)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:35.858663Z",
     "start_time": "2019-09-03T04:30:35.832617Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>experiment</th>\n",
       "      <th>sirna</th>\n",
       "      <th>multi</th>\n",
       "      <th>valid</th>\n",
       "      <th>celltype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36510</th>\n",
       "      <td>U2OS-03/Plate4/O19_s2</td>\n",
       "      <td>U2OS-03</td>\n",
       "      <td>103</td>\n",
       "      <td>U2OS-03 103</td>\n",
       "      <td>1</td>\n",
       "      <td>U2OS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36511</th>\n",
       "      <td>U2OS-03/Plate4/O20_s2</td>\n",
       "      <td>U2OS-03</td>\n",
       "      <td>202</td>\n",
       "      <td>U2OS-03 202</td>\n",
       "      <td>1</td>\n",
       "      <td>U2OS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36512</th>\n",
       "      <td>U2OS-03/Plate4/O21_s2</td>\n",
       "      <td>U2OS-03</td>\n",
       "      <td>824</td>\n",
       "      <td>U2OS-03 824</td>\n",
       "      <td>1</td>\n",
       "      <td>U2OS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36513</th>\n",
       "      <td>U2OS-03/Plate4/O22_s2</td>\n",
       "      <td>U2OS-03</td>\n",
       "      <td>328</td>\n",
       "      <td>U2OS-03 328</td>\n",
       "      <td>1</td>\n",
       "      <td>U2OS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36514</th>\n",
       "      <td>U2OS-03/Plate4/O23_s2</td>\n",
       "      <td>U2OS-03</td>\n",
       "      <td>509</td>\n",
       "      <td>U2OS-03 509</td>\n",
       "      <td>1</td>\n",
       "      <td>U2OS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        path experiment  sirna        multi  valid celltype\n",
       "36510  U2OS-03/Plate4/O19_s2    U2OS-03    103  U2OS-03 103      1     U2OS\n",
       "36511  U2OS-03/Plate4/O20_s2    U2OS-03    202  U2OS-03 202      1     U2OS\n",
       "36512  U2OS-03/Plate4/O21_s2    U2OS-03    824  U2OS-03 824      1     U2OS\n",
       "36513  U2OS-03/Plate4/O22_s2    U2OS-03    328  U2OS-03 328      1     U2OS\n",
       "36514  U2OS-03/Plate4/O23_s2    U2OS-03    509  U2OS-03 509      1     U2OS"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:35.885577Z",
     "start_time": "2019-09-03T04:30:35.861113Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>experiment</th>\n",
       "      <th>celltype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19892</th>\n",
       "      <td>U2OS-05/Plate4/O19_s2</td>\n",
       "      <td>U2OS-05</td>\n",
       "      <td>U2OS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19893</th>\n",
       "      <td>U2OS-05/Plate4/O20_s2</td>\n",
       "      <td>U2OS-05</td>\n",
       "      <td>U2OS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19894</th>\n",
       "      <td>U2OS-05/Plate4/O21_s2</td>\n",
       "      <td>U2OS-05</td>\n",
       "      <td>U2OS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19895</th>\n",
       "      <td>U2OS-05/Plate4/O22_s2</td>\n",
       "      <td>U2OS-05</td>\n",
       "      <td>U2OS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19896</th>\n",
       "      <td>U2OS-05/Plate4/O23_s2</td>\n",
       "      <td>U2OS-05</td>\n",
       "      <td>U2OS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        path experiment celltype\n",
       "19892  U2OS-05/Plate4/O19_s2    U2OS-05     U2OS\n",
       "19893  U2OS-05/Plate4/O20_s2    U2OS-05     U2OS\n",
       "19894  U2OS-05/Plate4/O21_s2    U2OS-05     U2OS\n",
       "19895  U2OS-05/Plate4/O22_s2    U2OS-05     U2OS\n",
       "19896  U2OS-05/Plate4/O23_s2    U2OS-05     U2OS"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:35.905451Z",
     "start_time": "2019-09-03T04:30:35.886615Z"
    }
   },
   "outputs": [],
   "source": [
    "cts = ['HEPG2', 'HUVEC', 'RPE', 'U2OS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:35.923387Z",
     "start_time": "2019-09-03T04:30:35.906623Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pick the celltype for the celltype-specific training\n",
    "#ct = cts[3]; ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:35.942814Z",
     "start_time": "2019-09-03T04:30:35.924683Z"
    }
   },
   "outputs": [],
   "source": [
    "#df_train[df_train['celltype'] == ct].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:35.955777Z",
     "start_time": "2019-09-03T04:30:35.943796Z"
    }
   },
   "outputs": [],
   "source": [
    "#df_train[df_train['celltype'] == ct].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:35.970238Z",
     "start_time": "2019-09-03T04:30:35.957387Z"
    }
   },
   "outputs": [],
   "source": [
    "#df_test[df_test['celltype'] == ct].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:36.016793Z",
     "start_time": "2019-09-03T04:30:35.971311Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train['pg'] = df_train['path'].apply(lambda x: fn2pgint['train/'+x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:36.046682Z",
     "start_time": "2019-09-03T04:30:36.017976Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test['pg'] = df_test['path'].apply(lambda x: fn2pgint['test/'+x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:36.058945Z",
     "start_time": "2019-09-03T04:30:36.047775Z"
    }
   },
   "outputs": [],
   "source": [
    "pg = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:36.078146Z",
     "start_time": "2019-09-03T04:30:36.059919Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((18252, 7), (9946, 4))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train['pg'] == pg].shape, df_test[df_test['pg'] == pg].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:36.097967Z",
     "start_time": "2019-09-03T04:30:36.079123Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>experiment</th>\n",
       "      <th>sirna</th>\n",
       "      <th>multi</th>\n",
       "      <th>valid</th>\n",
       "      <th>celltype</th>\n",
       "      <th>pg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36510</th>\n",
       "      <td>U2OS-03/Plate4/O19_s2</td>\n",
       "      <td>U2OS-03</td>\n",
       "      <td>103</td>\n",
       "      <td>U2OS-03 103</td>\n",
       "      <td>1</td>\n",
       "      <td>U2OS</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36511</th>\n",
       "      <td>U2OS-03/Plate4/O20_s2</td>\n",
       "      <td>U2OS-03</td>\n",
       "      <td>202</td>\n",
       "      <td>U2OS-03 202</td>\n",
       "      <td>1</td>\n",
       "      <td>U2OS</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36512</th>\n",
       "      <td>U2OS-03/Plate4/O21_s2</td>\n",
       "      <td>U2OS-03</td>\n",
       "      <td>824</td>\n",
       "      <td>U2OS-03 824</td>\n",
       "      <td>1</td>\n",
       "      <td>U2OS</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36513</th>\n",
       "      <td>U2OS-03/Plate4/O22_s2</td>\n",
       "      <td>U2OS-03</td>\n",
       "      <td>328</td>\n",
       "      <td>U2OS-03 328</td>\n",
       "      <td>1</td>\n",
       "      <td>U2OS</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36514</th>\n",
       "      <td>U2OS-03/Plate4/O23_s2</td>\n",
       "      <td>U2OS-03</td>\n",
       "      <td>509</td>\n",
       "      <td>U2OS-03 509</td>\n",
       "      <td>1</td>\n",
       "      <td>U2OS</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        path experiment  sirna        multi  valid celltype  \\\n",
       "36510  U2OS-03/Plate4/O19_s2    U2OS-03    103  U2OS-03 103      1     U2OS   \n",
       "36511  U2OS-03/Plate4/O20_s2    U2OS-03    202  U2OS-03 202      1     U2OS   \n",
       "36512  U2OS-03/Plate4/O21_s2    U2OS-03    824  U2OS-03 824      1     U2OS   \n",
       "36513  U2OS-03/Plate4/O22_s2    U2OS-03    328  U2OS-03 328      1     U2OS   \n",
       "36514  U2OS-03/Plate4/O23_s2    U2OS-03    509  U2OS-03 509      1     U2OS   \n",
       "\n",
       "       pg  \n",
       "36510   3  \n",
       "36511   3  \n",
       "36512   3  \n",
       "36513   3  \n",
       "36514   3  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train['pg'] == pg].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:36.117894Z",
     "start_time": "2019-09-03T04:30:36.098965Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>experiment</th>\n",
       "      <th>celltype</th>\n",
       "      <th>pg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19069</th>\n",
       "      <td>U2OS-05/Plate1/O19_s2</td>\n",
       "      <td>U2OS-05</td>\n",
       "      <td>U2OS</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19070</th>\n",
       "      <td>U2OS-05/Plate1/O20_s2</td>\n",
       "      <td>U2OS-05</td>\n",
       "      <td>U2OS</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19071</th>\n",
       "      <td>U2OS-05/Plate1/O21_s2</td>\n",
       "      <td>U2OS-05</td>\n",
       "      <td>U2OS</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19072</th>\n",
       "      <td>U2OS-05/Plate1/O22_s2</td>\n",
       "      <td>U2OS-05</td>\n",
       "      <td>U2OS</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19073</th>\n",
       "      <td>U2OS-05/Plate1/O23_s2</td>\n",
       "      <td>U2OS-05</td>\n",
       "      <td>U2OS</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        path experiment celltype  pg\n",
       "19069  U2OS-05/Plate1/O19_s2    U2OS-05     U2OS   3\n",
       "19070  U2OS-05/Plate1/O20_s2    U2OS-05     U2OS   3\n",
       "19071  U2OS-05/Plate1/O21_s2    U2OS-05     U2OS   3\n",
       "19072  U2OS-05/Plate1/O22_s2    U2OS-05     U2OS   3\n",
       "19073  U2OS-05/Plate1/O23_s2    U2OS-05     U2OS   3"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[df_test['pg'] == pg].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color augmentation transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Color Augmentation: Color variability can be increased by applying random color transformations to original training samples. We perform color augmentation by transforming every color channels Ic ← ac · Ic + bc, where ac and bc are drawn from uniform distributions ac ∼ U [0.9, 1.1] and bc ∼ U [−10, +10].\" from Domain-adversarial neural networks to address the appearance variability of histopathology images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:36.130979Z",
     "start_time": "2019-09-03T04:30:36.119338Z"
    }
   },
   "outputs": [],
   "source": [
    "# from https://github.com/fastai/fastai/blob/master/fastai/vision/transform.py#L137\n",
    "#def _rgb_randomize(x, channel:int=None, thresh:float=0.3):\n",
    "#    \"Randomize one of the channels of the input image\"\n",
    "#    if channel is None: channel = np.random.randint(0, x.shape[0] - 1)\n",
    "#    x[channel] = torch.rand(x.shape[1:]) * np.random.uniform(0, thresh)\n",
    "#    return x\n",
    "#\n",
    "#rgb_randomize = TfmPixel(_rgb_randomize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:36.144158Z",
     "start_time": "2019-09-03T04:30:36.132136Z"
    }
   },
   "outputs": [],
   "source": [
    "# Scaling factor comes from byte tensor?\n",
    "#10/255 = 0.0392156862745098"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:36.157967Z",
     "start_time": "2019-09-03T04:30:36.145256Z"
    }
   },
   "outputs": [],
   "source": [
    "def _color_augmentation(x):\n",
    "    \"Randomize all channels of the input image\"\n",
    "    channel_count = x.shape[0] - 1\n",
    "    \n",
    "    # by transforming every color channels Ic ← ac · Ic + bc, \n",
    "    # where ac and bc are drawn from uniform distributions \n",
    "    # ac ∼ U [0.9, 1.1] and \n",
    "    # bc ∼ U [−10, +10].\n",
    "    \n",
    "    # x [0,1]\n",
    "    \n",
    "    for c in range(channel_count):\n",
    "        #pdb.set_trace()\n",
    "        #print(x.min(), x.max())\n",
    "        ac = np.random.uniform(0.9, 1.1) #np.random.uniform(0.9, 1.1)\n",
    "        bc = np.random.uniform(-0.1,0.1) #np.random.uniform(-10, 10)\n",
    "        x[c] = x[c] * ac + bc\n",
    "        \n",
    "        # clipping to min 0 and max 1\n",
    "        x[c] = torch.clamp(x[c], 0., 1.)\n",
    "    \n",
    "    return x\n",
    "\n",
    "color_augmentation = TfmPixel(_color_augmentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforms setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:36.169819Z",
     "start_time": "2019-09-03T04:30:36.158966Z"
    }
   },
   "outputs": [],
   "source": [
    "## EfficientNet-B3\n",
    "#sz, bs = 300, 8 # 4167MiB /  7952MiB\n",
    "sz, bs = 300, 8*2 # 7942MiB /  7952MiB // FP16: 4397MiB /  7952MiB\n",
    "#sz, bs = 300, 8*4 # FP16: 7805MiB /  7952MiB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:36.182105Z",
     "start_time": "2019-09-03T04:30:36.170799Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 16)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sz, bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:36.195185Z",
     "start_time": "2019-09-03T04:30:36.183042Z"
    }
   },
   "outputs": [],
   "source": [
    "# cutout params\n",
    "#int(sz*0.1), int(sz*0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:36.207377Z",
     "start_time": "2019-09-03T04:30:36.196258Z"
    }
   },
   "outputs": [],
   "source": [
    "# normal tfms\n",
    "#tfms = get_transforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:36.220195Z",
     "start_time": "2019-09-03T04:30:36.208363Z"
    }
   },
   "outputs": [],
   "source": [
    "# extended tfms\n",
    "tfms = get_transforms(do_flip=True, flip_vert=True, \n",
    "                      max_rotate=90.0, max_zoom=1.1, \n",
    "                      max_lighting=0.2, max_warp=0.2, \n",
    "                      p_affine=0.75, p_lighting=0.75, \n",
    "                      xtra_tfms=[color_augmentation()])\n",
    "\n",
    "# crop_pad: https://forums.fast.ai/t/misc-issues/35386/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:36.232443Z",
     "start_time": "2019-09-03T04:30:36.221238Z"
    }
   },
   "outputs": [],
   "source": [
    "# extended tfms\n",
    "#tfms = get_transforms(do_flip=True, flip_vert=True, \n",
    "#                      max_rotate=90.0, max_zoom=1.1, \n",
    "#                      max_lighting=0.2, max_warp=0.2, \n",
    "#                      p_affine=0.75, p_lighting=0.75, \n",
    "#                      xtra_tfms=[color_augmentation(), \n",
    "#                                 cutout(n_holes=(1,4), length=(int(sz*0.1), int(sz*0.5)), p=.5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:36.245516Z",
     "start_time": "2019-09-03T04:30:36.233421Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([RandTransform(tfm=TfmCrop (crop_pad), kwargs={'row_pct': (0, 1), 'col_pct': (0, 1), 'padding_mode': 'reflection'}, p=1.0, resolved={}, do_run=True, is_random=True, use_on_y=True),\n",
       "  RandTransform(tfm=TfmAffine (dihedral_affine), kwargs={}, p=1.0, resolved={}, do_run=True, is_random=True, use_on_y=True),\n",
       "  RandTransform(tfm=TfmCoord (symmetric_warp), kwargs={'magnitude': (-0.2, 0.2)}, p=0.75, resolved={}, do_run=True, is_random=True, use_on_y=True),\n",
       "  RandTransform(tfm=TfmAffine (rotate), kwargs={'degrees': (-90.0, 90.0)}, p=0.75, resolved={}, do_run=True, is_random=True, use_on_y=True),\n",
       "  RandTransform(tfm=TfmAffine (zoom), kwargs={'scale': (1.0, 1.1), 'row_pct': (0, 1), 'col_pct': (0, 1)}, p=0.75, resolved={}, do_run=True, is_random=True, use_on_y=True),\n",
       "  RandTransform(tfm=TfmLighting (brightness), kwargs={'change': (0.4, 0.6)}, p=0.75, resolved={}, do_run=True, is_random=True, use_on_y=True),\n",
       "  RandTransform(tfm=TfmLighting (contrast), kwargs={'scale': (0.8, 1.25)}, p=0.75, resolved={}, do_run=True, is_random=True, use_on_y=True),\n",
       "  RandTransform(tfm=TfmPixel (color_augmentation), kwargs={}, p=1.0, resolved={}, do_run=True, is_random=True, use_on_y=True)],\n",
       " [RandTransform(tfm=TfmCrop (crop_pad), kwargs={}, p=1.0, resolved={}, do_run=True, is_random=True, use_on_y=True)])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:36.259275Z",
     "start_time": "2019-09-03T04:30:36.246490Z"
    }
   },
   "outputs": [],
   "source": [
    "# \"crop_pad\" to sz\n",
    "tfms[0][0] = crop_pad(size=sz, row_pct=[0.,1.], col_pct=[0.,1.])\n",
    "tfms[1][0] = crop_pad(size=sz, row_pct=[0.,1.], col_pct=[0.,1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:36.272455Z",
     "start_time": "2019-09-03T04:30:36.260257Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([RandTransform(tfm=TfmCrop (crop_pad), kwargs={'size': 300, 'row_pct': [0.0, 1.0], 'col_pct': [0.0, 1.0]}, p=1.0, resolved={}, do_run=True, is_random=True, use_on_y=True),\n",
       "  RandTransform(tfm=TfmAffine (dihedral_affine), kwargs={}, p=1.0, resolved={}, do_run=True, is_random=True, use_on_y=True),\n",
       "  RandTransform(tfm=TfmCoord (symmetric_warp), kwargs={'magnitude': (-0.2, 0.2)}, p=0.75, resolved={}, do_run=True, is_random=True, use_on_y=True),\n",
       "  RandTransform(tfm=TfmAffine (rotate), kwargs={'degrees': (-90.0, 90.0)}, p=0.75, resolved={}, do_run=True, is_random=True, use_on_y=True),\n",
       "  RandTransform(tfm=TfmAffine (zoom), kwargs={'scale': (1.0, 1.1), 'row_pct': (0, 1), 'col_pct': (0, 1)}, p=0.75, resolved={}, do_run=True, is_random=True, use_on_y=True),\n",
       "  RandTransform(tfm=TfmLighting (brightness), kwargs={'change': (0.4, 0.6)}, p=0.75, resolved={}, do_run=True, is_random=True, use_on_y=True),\n",
       "  RandTransform(tfm=TfmLighting (contrast), kwargs={'scale': (0.8, 1.25)}, p=0.75, resolved={}, do_run=True, is_random=True, use_on_y=True),\n",
       "  RandTransform(tfm=TfmPixel (color_augmentation), kwargs={}, p=1.0, resolved={}, do_run=True, is_random=True, use_on_y=True)],\n",
       " [RandTransform(tfm=TfmCrop (crop_pad), kwargs={'size': 300, 'row_pct': [0.0, 1.0], 'col_pct': [0.0, 1.0]}, p=1.0, resolved={}, do_run=True, is_random=True, use_on_y=True)])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:36.284457Z",
     "start_time": "2019-09-03T04:30:36.273488Z"
    }
   },
   "outputs": [],
   "source": [
    "### CHANGED LINE 65 to:\n",
    "# nano ~/anaconda3/envs/fastai/lib/python3.6/site-packages/fastai/vision/data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-10T10:36:41.864055Z",
     "start_time": "2019-08-10T10:36:41.846780Z"
    }
   },
   "source": [
    "```\n",
    "~/anaconda3/envs/fastai/lib/python3.6/site-packages/fastai/vision/data.py in _normalize_batch(b, mean, std, do_x, do_y)\n",
    "     64     \"`b` = `x`,`y` - normalize `x` array of imgs and `do_y` optionally `y`.\"\n",
    "     65     x,y = b\n",
    "---> 66     mean,std = mean.to(x.device),std.to(x.device)\n",
    "     67     if do_x: x = normalize(x,mean,std)\n",
    "     68     if do_y and len(y.shape) == 4: y = normalize(y,mean,std)\n",
    "\n",
    "AttributeError: 'list' object has no attribute 'device'\n",
    "```\n",
    "CHANGED TO:\n",
    "```\n",
    "def _normalize_batch(b:Tuple[Tensor,Tensor], mean:FloatTensor, std:FloatTensor, do_x:bool$\n",
    "    \"`b` = `x`,`y` - normalize `x` array of imgs and `do_y` optionally `y`.\"\n",
    "    (x,cint,pgint,expint),y = b\n",
    "    mean,std = mean.to(x.device),std.to(x.device)\n",
    "    if do_x: x = normalize(x,mean,std)\n",
    "    if do_y and len(y.shape) == 4: y = normalize(y,mean,std)\n",
    "    return (x,cint,pgint,expint),y\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:36.296555Z",
     "start_time": "2019-09-03T04:30:36.285456Z"
    }
   },
   "outputs": [],
   "source": [
    "#data.batch_stats() # DOES NOT WORK?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:36.312437Z",
     "start_time": "2019-09-03T04:30:36.297546Z"
    }
   },
   "outputs": [],
   "source": [
    "# From https://github.com/recursionpharma/rxrx1-utils/blob/master/rxrx/main.py\n",
    "# The mean and stds for each of the channels\n",
    "GLOBAL_PIXEL_STATS = (np.array([6.74696984, 14.74640167, 10.51260864,\n",
    "                                10.45369445,  5.49959796, 9.81545561]),\n",
    "                       np.array([7.95876312, 12.17305868, 5.86172946,\n",
    "                                 7.83451711, 4.701167, 5.43130431]))\n",
    "\n",
    "stats_mean = torch.tensor(GLOBAL_PIXEL_STATS[0]/255).float()\n",
    "stats_var = torch.tensor(GLOBAL_PIXEL_STATS[1]/255).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:36.324118Z",
     "start_time": "2019-09-03T04:30:36.313496Z"
    }
   },
   "outputs": [],
   "source": [
    "#stats_mean, stats_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:36.339407Z",
     "start_time": "2019-09-03T04:30:36.325114Z"
    }
   },
   "outputs": [],
   "source": [
    "# 3d to 6d from old/rcic_multicat_v9_resnet50-pretrained_colaug.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:36.353747Z",
     "start_time": "2019-09-03T04:30:36.340391Z"
    }
   },
   "outputs": [],
   "source": [
    "from efficientnet_pytorch.utils import get_same_padding_conv2d, round_filters, round_repeats, relu_fn\n",
    "from efficientnet_pytorch.model import MBConvBlock, load_pretrained_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:36.379363Z",
     "start_time": "2019-09-03T04:30:36.354946Z"
    }
   },
   "outputs": [],
   "source": [
    "# put feature extractor into forward method\n",
    "class EfficientNet(nn.Module):\n",
    "    \"\"\"\n",
    "    An EfficientNet model. Most easily loaded with the .from_name or .from_pretrained methods\n",
    "    Args:\n",
    "        blocks_args (list): A list of BlockArgs to construct blocks\n",
    "        global_params (namedtuple): A set of GlobalParams shared between blocks\n",
    "    Example:\n",
    "        model = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, blocks_args=None, global_params=None):\n",
    "        super().__init__()\n",
    "        assert isinstance(blocks_args, list), 'blocks_args should be a list'\n",
    "        assert len(blocks_args) > 0, 'block args must be greater than 0'\n",
    "        self._global_params = global_params\n",
    "        self._blocks_args = blocks_args\n",
    "\n",
    "        # Get static or dynamic convolution depending on image size\n",
    "        Conv2d = get_same_padding_conv2d(image_size=global_params.image_size)\n",
    "\n",
    "        # Batch norm parameters\n",
    "        bn_mom = 1 - self._global_params.batch_norm_momentum\n",
    "        bn_eps = self._global_params.batch_norm_epsilon\n",
    "\n",
    "        # Stem\n",
    "        in_channels = 3  # rgb\n",
    "        out_channels = round_filters(32, self._global_params)  # number of output channels\n",
    "        self._conv_stem = Conv2d(in_channels, out_channels, kernel_size=3, stride=2, bias=False)\n",
    "        self._bn0 = nn.BatchNorm2d(num_features=out_channels, momentum=bn_mom, eps=bn_eps)\n",
    "\n",
    "        # Build blocks\n",
    "        self._blocks = nn.ModuleList([])\n",
    "        for block_args in self._blocks_args:\n",
    "\n",
    "            # Update block input and output filters based on depth multiplier.\n",
    "            block_args = block_args._replace(\n",
    "                input_filters=round_filters(block_args.input_filters, self._global_params),\n",
    "                output_filters=round_filters(block_args.output_filters, self._global_params),\n",
    "                num_repeat=round_repeats(block_args.num_repeat, self._global_params)\n",
    "            )\n",
    "\n",
    "            # The first block needs to take care of stride and filter size increase.\n",
    "            self._blocks.append(MBConvBlock(block_args, self._global_params))\n",
    "            if block_args.num_repeat > 1:\n",
    "                block_args = block_args._replace(input_filters=block_args.output_filters, stride=1)\n",
    "            for _ in range(block_args.num_repeat - 1):\n",
    "                self._blocks.append(MBConvBlock(block_args, self._global_params))\n",
    "\n",
    "        # Head\n",
    "        in_channels = block_args.output_filters  # output of final block\n",
    "        out_channels = round_filters(1280, self._global_params)\n",
    "        self._conv_head = Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self._bn1 = nn.BatchNorm2d(num_features=out_channels, momentum=bn_mom, eps=bn_eps)\n",
    "\n",
    "        # Final linear layer\n",
    "        #self._dropout = self._global_params.dropout_rate\n",
    "        #self._fc = nn.Linear(out_channels, self._global_params.num_classes)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\" Returns output of the final convolution layer \"\"\"\n",
    "\n",
    "        # Stem\n",
    "        x = relu_fn(self._bn0(self._conv_stem(inputs)))\n",
    "\n",
    "        # Blocks\n",
    "        for idx, block in enumerate(self._blocks):\n",
    "            drop_connect_rate = self._global_params.drop_connect_rate\n",
    "            if drop_connect_rate:\n",
    "                drop_connect_rate *= float(idx) / len(self._blocks)\n",
    "            x = block(x, drop_connect_rate=drop_connect_rate)\n",
    "\n",
    "        # Head\n",
    "        x = relu_fn(self._bn1(self._conv_head(x)))\n",
    "\n",
    "        return x\n",
    "\n",
    "    #def forward(self, inputs):\n",
    "    #    \"\"\" Calls extract_features to extract features, applies final linear layer, and returns logits. \"\"\"\n",
    "    #\n",
    "    #    # Convolution layers\n",
    "    #    x = self.extract_features(inputs)\n",
    "    #\n",
    "    #    # Pooling and final linear layer\n",
    "    #    x = F.adaptive_avg_pool2d(x, 1).squeeze(-1).squeeze(-1)\n",
    "    #    if self._dropout:\n",
    "    #        x = F.dropout(x, p=self._dropout, training=self.training)\n",
    "    #    x = self._fc(x)\n",
    "    #    return x\n",
    "\n",
    "    @classmethod\n",
    "    def from_name(cls, model_name, override_params=None):\n",
    "        cls._check_model_name_is_valid(model_name)\n",
    "        blocks_args, global_params = get_model_params(model_name, override_params)\n",
    "        return EfficientNet(blocks_args, global_params)\n",
    "\n",
    "    @classmethod\n",
    "    def from_pretrained(cls, model_name, num_classes=1000):\n",
    "        model = EfficientNet.from_name(model_name, override_params={'num_classes': num_classes})\n",
    "        load_pretrained_weights(model, model_name, load_fc=(num_classes == 1000))\n",
    "        return model\n",
    "\n",
    "    @classmethod\n",
    "    def get_image_size(cls, model_name):\n",
    "        cls._check_model_name_is_valid(model_name)\n",
    "        _, _, res, _ = efficientnet_params(model_name)\n",
    "        return res\n",
    "\n",
    "    @classmethod\n",
    "    def _check_model_name_is_valid(cls, model_name, also_need_pretrained_weights=False):\n",
    "        \"\"\" Validates model name. None that pretrained weights are only available for\n",
    "        the first four models (efficientnet-b{i} for i in 0,1,2,3) at the moment. \"\"\"\n",
    "        num_models = 4 if also_need_pretrained_weights else 8\n",
    "        valid_models = ['efficientnet_b'+str(i) for i in range(num_models)]\n",
    "        if model_name.replace('-','_') not in valid_models:\n",
    "            raise ValueError('model_name should be one of: ' + ', '.join(valid_models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:36.395389Z",
     "start_time": "2019-09-03T04:30:36.380367Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils import model_zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:36.411362Z",
     "start_time": "2019-09-03T04:30:36.396527Z"
    }
   },
   "outputs": [],
   "source": [
    "url_map = {\n",
    "    'efficientnet-b0': 'http://storage.googleapis.com/public-models/efficientnet/efficientnet-b0-355c32eb.pth',\n",
    "    'efficientnet-b1': 'http://storage.googleapis.com/public-models/efficientnet/efficientnet-b1-f1951068.pth',\n",
    "    'efficientnet-b2': 'http://storage.googleapis.com/public-models/efficientnet/efficientnet-b2-8bb594d6.pth',\n",
    "    'efficientnet-b3': 'http://storage.googleapis.com/public-models/efficientnet/efficientnet-b3-5fb5a3c3.pth',\n",
    "    'efficientnet-b4': 'http://storage.googleapis.com/public-models/efficientnet/efficientnet-b4-6ed6700e.pth',\n",
    "    'efficientnet-b5': 'http://storage.googleapis.com/public-models/efficientnet/efficientnet-b5-b6417697.pth',\n",
    "    'efficientnet-b6': 'http://storage.googleapis.com/public-models/efficientnet/efficientnet-b6-c76e70fd.pth',\n",
    "    'efficientnet-b7': 'http://storage.googleapis.com/public-models/efficientnet/efficientnet-b7-dcc49843.pth',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:36.427353Z",
     "start_time": "2019-09-03T04:30:36.412402Z"
    }
   },
   "outputs": [],
   "source": [
    "# adapt load function to only load weights for feature extractor stage\n",
    "def load_pretrained_weights(model, model_name, load_fc=True):\n",
    "    \"\"\" Loads pretrained weights, and downloads if loading for the first time. \"\"\"\n",
    "    state_dict = model_zoo.load_url(url_map[model_name])\n",
    "    #if load_fc:\n",
    "    #    model.load_state_dict(state_dict)\n",
    "    #else:\n",
    "    state_dict.pop('_fc.weight')\n",
    "    state_dict.pop('_fc.bias')\n",
    "    res = model.load_state_dict(state_dict, strict=False)\n",
    "        #assert str(res.missing_keys) == str(['_fc.weight', '_fc.bias']), 'issue loading pretrained weights'\n",
    "    print('Loaded pretrained weights for {}'.format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:36.639413Z",
     "start_time": "2019-09-03T04:30:36.428359Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b3\n"
     ]
    }
   ],
   "source": [
    "# b3: input size = 300\n",
    "#efficientnet_b3 = EfficientNet.from_name('efficientnet-b3')\n",
    "efficientnet_f = EfficientNet.from_pretrained('efficientnet-b3')\n",
    "#efficientnet_b4f = EfficientNet.from_pretrained('efficientnet-b4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:36.659690Z",
     "start_time": "2019-09-03T04:30:36.647300Z"
    }
   },
   "outputs": [],
   "source": [
    "#efficientnet_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:36.684149Z",
     "start_time": "2019-09-03T04:30:36.662588Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Conv2dStaticSamePadding(\n",
       "   3, 40, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "   (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       " ), efficientnet_pytorch.utils.Conv2dStaticSamePadding)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficientnet_f._conv_stem, type(efficientnet_f._conv_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:36.710392Z",
     "start_time": "2019-09-03T04:30:36.691295Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2dStaticSamePadding(\n",
       "  6, 40, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "  (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       ")"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.Conv2dStaticSamePadding(6, 40, kernel_size=(3, 3), stride=(2, 2), bias=False, image_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:36.743118Z",
     "start_time": "2019-09-03T04:30:36.721180Z"
    }
   },
   "outputs": [],
   "source": [
    "p_dict = {pn: p for pn, p in efficientnet_f._conv_stem.named_parameters()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:36.773218Z",
     "start_time": "2019-09-03T04:30:36.749565Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['weight'])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:36.798406Z",
     "start_time": "2019-09-03T04:30:36.780214Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([40, 3, 3, 3]), True)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_dict['weight'].shape, p_dict['weight'].requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:36.817423Z",
     "start_time": "2019-09-03T04:30:36.800231Z"
    }
   },
   "outputs": [],
   "source": [
    "old_weight = p_dict['weight'].detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:36.838628Z",
     "start_time": "2019-09-03T04:30:36.824209Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([40, 3, 3, 3]), False)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_weight.shape, old_weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:36.860005Z",
     "start_time": "2019-09-03T04:30:36.839672Z"
    }
   },
   "outputs": [],
   "source": [
    "new_weight = torch.cat((old_weight, old_weight), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:36.896964Z",
     "start_time": "2019-09-03T04:30:36.861149Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([40, 6, 3, 3]), False)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_weight.shape, new_weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:36.930598Z",
     "start_time": "2019-09-03T04:30:36.898448Z"
    }
   },
   "outputs": [],
   "source": [
    "def show_input_stage_weights(weight=None, nrows=2, ncols=3):\n",
    "    fig, ax = plt.subplots(nrows=nrows, ncols=ncols)\n",
    "    k = 0\n",
    "    for i in range(nrows):\n",
    "        for j in range(ncols):\n",
    "            if nrows > 1:\n",
    "                ax[i,j].set_title(k)\n",
    "                ax[i,j].imshow(weight[0][k])\n",
    "                ax[i,j].axis(\"off\")\n",
    "            else:\n",
    "                ax[j].set_title(k)\n",
    "                ax[j].imshow(weight[0][k])\n",
    "                ax[j].axis(\"off\")\n",
    "            k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:36.946618Z",
     "start_time": "2019-09-03T04:30:36.932180Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot old_weight\n",
    "#show_input_stage_weights(old_weight, nrows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:36.970561Z",
     "start_time": "2019-09-03T04:30:36.947813Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot new_weight\n",
    "#show_input_stage_weights(new_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:36.995528Z",
     "start_time": "2019-09-03T04:30:36.971699Z"
    }
   },
   "outputs": [],
   "source": [
    "# replace first conv layer with a 6-channel version\n",
    "efficientnet_f._conv_stem = utils.Conv2dStaticSamePadding(6, 40, kernel_size=(3, 3),\n",
    "                                                          stride=(2, 2), bias=False, image_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:37.042631Z",
     "start_time": "2019-09-03T04:30:36.996527Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2dStaticSamePadding(\n",
       "  6, 40, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "  (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       ")"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficientnet_f._conv_stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:37.079842Z",
     "start_time": "2019-09-03T04:30:37.055272Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 6, 3, 3])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficientnet_f._conv_stem.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:37.110385Z",
     "start_time": "2019-09-03T04:30:37.095153Z"
    }
   },
   "outputs": [],
   "source": [
    "# set new_weights to nn.Parameter and overwrite it in the conv layer\n",
    "efficientnet_f._conv_stem.weight = nn.Parameter(new_weight) # hand over requires_grad False?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:37.124220Z",
     "start_time": "2019-09-03T04:30:37.111531Z"
    }
   },
   "outputs": [],
   "source": [
    "# check if weight was loaded properly\n",
    "assert torch.allclose(new_weight, efficientnet_f._conv_stem.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:37.140571Z",
     "start_time": "2019-09-03T04:30:37.125254Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([40, 6, 3, 3]), True)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficientnet_f._conv_stem.weight.shape, efficientnet_f._conv_stem.weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:37.155352Z",
     "start_time": "2019-09-03T04:30:37.141643Z"
    }
   },
   "outputs": [],
   "source": [
    "# network is in full train mode!\n",
    "#[p.requires_grad for p in efficientnet_b3f.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:37.171373Z",
     "start_time": "2019-09-03T04:30:37.156391Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_rg(model=efficientnet_f, option=False):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:37.187544Z",
     "start_time": "2019-09-03T04:30:37.172529Z"
    }
   },
   "outputs": [],
   "source": [
    "# set requires grad for the efficientnet to false (to later only set it true for the input)\n",
    "# WE WILL NOT DO THIS, because it should be not necessary!\n",
    "set_rg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:37.203435Z",
     "start_time": "2019-09-03T04:30:37.188694Z"
    }
   },
   "outputs": [],
   "source": [
    "# network is frozen\n",
    "#[p.requires_grad for p in efficientnet_b4f.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:37.220347Z",
     "start_time": "2019-09-03T04:30:37.204475Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficientnet_f._conv_stem.weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:37.235356Z",
     "start_time": "2019-09-03T04:30:37.221320Z"
    }
   },
   "outputs": [],
   "source": [
    "# set input stage to trainable\n",
    "#efficientnet_f._conv_stem.weight.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:37.251386Z",
     "start_time": "2019-09-03T04:30:37.236340Z"
    }
   },
   "outputs": [],
   "source": [
    "#efficientnet_f._conv_stem.weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:37.799432Z",
     "start_time": "2019-09-03T04:30:37.252384Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1536, 9, 9])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficientnet_f(torch.randn(1,6,sz,sz)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EfficientNet Pre-Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:37.819447Z",
     "start_time": "2019-09-03T04:30:37.800438Z"
    }
   },
   "outputs": [],
   "source": [
    "def resnet_pre_head(concat_pool:bool=True):\n",
    "    pool = AdaptiveConcatPool2d() if concat_pool else nn.AdaptiveAvgPool2d(1)\n",
    "    layers = [pool, Flatten()]\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:37.839800Z",
     "start_time": "2019-09-03T04:30:37.820426Z"
    }
   },
   "outputs": [],
   "source": [
    "efficientnet_f_prehead = resnet_pre_head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:37.862780Z",
     "start_time": "2019-09-03T04:30:37.841512Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): AdaptiveConcatPool2d(\n",
       "    (ap): AdaptiveAvgPool2d(output_size=1)\n",
       "    (mp): AdaptiveMaxPool2d(output_size=1)\n",
       "  )\n",
       "  (1): Flatten()\n",
       ")"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficientnet_f_prehead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:37.900547Z",
     "start_time": "2019-09-03T04:30:37.864956Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3072])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficientnet_f_prehead(torch.randn(2, 1536, 9, 9)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:37.927254Z",
     "start_time": "2019-09-03T04:30:37.907298Z"
    }
   },
   "outputs": [],
   "source": [
    "efficientnet_fph = nn.Sequential(efficientnet_f, efficientnet_f_prehead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:38.399919Z",
     "start_time": "2019-09-03T04:30:37.935309Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3072])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficientnet_fph(torch.randn(1,6,sz,sz)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CellType & Plate Group Feature Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:38.423315Z",
     "start_time": "2019-09-03T04:30:38.401158Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exps = len(set([exp2int[i] for i in exp2int])); exps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:38.453997Z",
     "start_time": "2019-09-03T04:30:38.424662Z"
    }
   },
   "outputs": [],
   "source": [
    "class CellTypePlateGroupFeatures(nn.Module):\n",
    "    '''CellType Feature Extractor.'''\n",
    "    def __init__(self, cell_types=4, plate_groups=4, exps=exps, emb_sz=128):\n",
    "        super(CellTypePlateGroupFeatures, self).__init__()\n",
    "        self.emb_ctint = nn.Embedding(cell_types, emb_sz)\n",
    "        self.emb_pgint = nn.Embedding(plate_groups, emb_sz)\n",
    "        self.emb_expint = nn.Embedding(exps, emb_sz)\n",
    "        \n",
    "    def forward(self, xb_ctint, xb_pgint, xb_expint, yb=None): # yb=None for training in non-AdaCos mode!\n",
    "        \n",
    "        ### CTINT\n",
    "        # check if we are in CutMix mode:\n",
    "        if isinstance(xb_ctint, tuple):\n",
    "            x1, x2, λ = xb_ctint\n",
    "            out1 = self.emb_ctint(x1)\n",
    "            out2 = self.emb_ctint(x2)\n",
    "            out_ctint = out1 * λ + out2 * (1-λ)\n",
    "        else: # if not CutMix, then normal mode\n",
    "            out_ctint = self.emb_ctint(xb_ctint)\n",
    "        \n",
    "        ## PGINT\n",
    "        # check if we are in CutMix mode:\n",
    "        if isinstance(xb_pgint, tuple):\n",
    "            x1, x2, λ = xb_pgint\n",
    "            out1 = self.emb_pgint(x1)\n",
    "            out2 = self.emb_pgint(x2)\n",
    "            out_pgint = out1 * λ + out2 * (1-λ)\n",
    "        else: # if not CutMix, then normal mode\n",
    "            out_pgint = self.emb_pgint(xb_pgint)\n",
    "            \n",
    "        ## EXPINT\n",
    "        # check if we are in CutMix mode:\n",
    "        if isinstance(xb_expint, tuple):\n",
    "            x1, x2, λ = xb_expint\n",
    "            out1 = self.emb_expint(x1)\n",
    "            out2 = self.emb_expint(x2)\n",
    "            out_expint = out1 * λ + out2 * (1-λ)\n",
    "        else: # if not CutMix, then normal mode\n",
    "            out_expint = self.emb_expint(xb_expint)\n",
    "        \n",
    "        out = torch.cat((out_ctint, out_pgint,  out_expint), dim=-1)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:38.478656Z",
     "start_time": "2019-09-03T04:30:38.455954Z"
    }
   },
   "outputs": [],
   "source": [
    "ctf = CellTypePlateGroupFeatures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:38.502088Z",
     "start_time": "2019-09-03T04:30:38.480222Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CellTypePlateGroupFeatures(\n",
       "  (emb_ctint): Embedding(4, 128)\n",
       "  (emb_pgint): Embedding(4, 128)\n",
       "  (emb_expint): Embedding(26, 128)\n",
       ")"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:38.525227Z",
     "start_time": "2019-09-03T04:30:38.503408Z"
    }
   },
   "outputs": [],
   "source": [
    "xb = (torch.tensor(ct2int['HEPG2']),\n",
    "      torch.tensor(fn2pgint['train/HEPG2-01/Plate1/B03_s1']),\n",
    "      torch.tensor(exp2int['train/HEPG2-01/Plate1/B03_s1'.split('/')[1]])\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:38.549651Z",
     "start_time": "2019-09-03T04:30:38.526598Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(0), tensor(0))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:38.574167Z",
     "start_time": "2019-09-03T04:30:38.551103Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([384])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctf(xb[0], xb[1], xb[2]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:38.598980Z",
     "start_time": "2019-09-03T04:30:38.576144Z"
    }
   },
   "outputs": [],
   "source": [
    "xb = (torch.tensor((1,3)), torch.tensor((1,3)), torch.tensor((1,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:38.617184Z",
     "start_time": "2019-09-03T04:30:38.600153Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 3]), tensor([1, 3]), tensor([1, 3]))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:38.634675Z",
     "start_time": "2019-09-03T04:30:38.618131Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 384])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctf(xb[0], xb[1], xb[2]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:38.668569Z",
     "start_time": "2019-09-03T04:30:38.635705Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 2)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct2int['HEPG2'], ct2int['RPE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:38.704583Z",
     "start_time": "2019-09-03T04:30:38.669645Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn2pgint['train/HEPG2-01/Plate1/B03_s1'], fn2pgint['train/RPE-01/Plate1/B03_s1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:38.740823Z",
     "start_time": "2019-09-03T04:30:38.705710Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 19)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp2int['HEPG2-01'], exp2int['RPE-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:38.776075Z",
     "start_time": "2019-09-03T04:30:38.742185Z"
    }
   },
   "outputs": [],
   "source": [
    "xb = ((torch.tensor(ct2int['HEPG2']), torch.tensor(ct2int['RPE']), 0.9),\n",
    "      (torch.tensor(fn2pgint['train/HEPG2-01/Plate1/B03_s1']),\n",
    "       torch.tensor(fn2pgint['train/RPE-01/Plate1/B03_s1']), 0.9),\n",
    "      (torch.tensor(exp2int['HEPG2-01']),\n",
    "       torch.tensor(exp2int['RPE-01']), 0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:38.821053Z",
     "start_time": "2019-09-03T04:30:38.777197Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([384])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctf(xb[0], xb[1], xb[2]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:38.839438Z",
     "start_time": "2019-09-03T04:30:38.822269Z"
    }
   },
   "outputs": [],
   "source": [
    "#class CellTypeFeatures(nn.Module):\n",
    "#    '''CellType Feature Extractor.'''\n",
    "#    def __init__(self, cell_types=4, emb_sz=128, lin_ftrs:Optional[Collection[int]]=None, nc=128):\n",
    "#        super(AdaCosNet, self).__init__()\n",
    "#        self.emb = nn.Embedding(cell_types, emb_sz)\n",
    "#        \n",
    "#        self.lin_ftrs = [emb_sz, 512, 512] if lin_ftrs is None else [emb_sz] + lin_ftrs + [nc]\n",
    "#\n",
    "#        \n",
    "#    def forward(self, xb, yb=None): # yb=None for training in non-AdaCos mode!\n",
    "#\n",
    "#        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaCos-Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:38.856702Z",
     "start_time": "2019-09-03T04:30:38.840662Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_adacos_head(nf:int, lin_ftrs:Optional[Collection[int]]=None, ps:Floats=0.5,\n",
    "                bn_final:bool=False): # concat_pool:bool=True, nc:int,\n",
    "    \"Model head that takes `nf` features, runs through `lin_ftrs`, and about `nc` classes.\"\n",
    "    \n",
    "    # ADDED TWO MORE 512 LAYERS !!!\n",
    "    lin_ftrs = [nf, 512, 512, 512, 512] if lin_ftrs is None else [nf] + lin_ftrs + [nc]\n",
    "    # remove last 512 fc layer to reduce MODEL SIZE ??? ???\n",
    "    \n",
    "    ps = listify(ps)\n",
    "    if len(ps) == 1: ps = [ps[0]/2] * (len(lin_ftrs)-2) + ps\n",
    "    actns = [nn.ReLU(inplace=True)] * (len(lin_ftrs)-2) + [None]\n",
    "    #pool = AdaptiveConcatPool2d() if concat_pool else nn.AdaptiveAvgPool2d(1)\n",
    "    #layers = [pool, Flatten()]\n",
    "    layers = []\n",
    "    for ni,no,p,actn in zip(lin_ftrs[:-1], lin_ftrs[1:], ps, actns):\n",
    "        layers += bn_drop_lin(ni, no, True, p, actn)\n",
    "    if bn_final: layers.append(nn.BatchNorm1d(lin_ftrs[-1], momentum=0.01))\n",
    "    #layers.append(AdaCos(lin_ftrs[-1], nc))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:38.891334Z",
     "start_time": "2019-09-03T04:30:38.857805Z"
    }
   },
   "outputs": [],
   "source": [
    "#adacos_head = create_adacos_head(nf=2048+1) \n",
    "adacos_head = create_adacos_head(nf=1536*2+128*3)\n",
    "# se_xresnet50f: 2048*2=4096, ctf: 128*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:38.905694Z",
     "start_time": "2019-09-03T04:30:38.892504Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): BatchNorm1d(3456, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (1): Dropout(p=0.25)\n",
       "  (2): Linear(in_features=3456, out_features=512, bias=True)\n",
       "  (3): ReLU(inplace)\n",
       "  (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (5): Dropout(p=0.25)\n",
       "  (6): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (7): ReLU(inplace)\n",
       "  (8): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (9): Dropout(p=0.25)\n",
       "  (10): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (11): ReLU(inplace)\n",
       "  (12): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (13): Dropout(p=0.5)\n",
       "  (14): Linear(in_features=512, out_features=512, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adacos_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:38.918700Z",
     "start_time": "2019-09-03T04:30:38.906707Z"
    }
   },
   "outputs": [],
   "source": [
    "#adacos_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:38.954280Z",
     "start_time": "2019-09-03T04:30:38.919792Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 512])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adacos_head(torch.randn(2, 1536*2+128*3)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:39.000542Z",
     "start_time": "2019-09-03T04:30:38.955224Z"
    }
   },
   "outputs": [],
   "source": [
    "# from https://github.com/4uiiurz1/pytorch-adacos/blob/master/metrics.py\n",
    "class AdaCos(nn.Module):\n",
    "    def __init__(self, num_features, num_classes, m=0.50):\n",
    "        super(AdaCos, self).__init__()\n",
    "        self.num_features = num_features\n",
    "        self.n_classes = num_classes\n",
    "        self.s = math.sqrt(2) * math.log(num_classes - 1)\n",
    "        self.m = m\n",
    "        self.We = nn.Parameter(torch.FloatTensor(num_classes, num_features))\n",
    "        nn.init.xavier_uniform_(self.We)\n",
    "\n",
    "    def forward(self, xb, yb):\n",
    "        \n",
    "        #print(yb.shape)\n",
    "        #pdb.set_trace()\n",
    "        \n",
    "        # normalize features\n",
    "        x = F.normalize(xb)\n",
    "        # normalize weights\n",
    "        W = F.normalize(self.We)\n",
    "        # dot product\n",
    "        logits = F.linear(x, W)\n",
    "        \n",
    "        # for training in non-AdaCos mode (= no yb date in the forward pass):\n",
    "        if yb is None:\n",
    "            print('yb = None')\n",
    "            return logits\n",
    "        \n",
    "        # feature re-scale\n",
    "        theta = torch.acos(torch.clamp(logits, -1.0 + 1e-7, 1.0 - 1e-7))\n",
    "        one_hot = torch.zeros_like(logits)\n",
    "        \n",
    "        # ORIGINAL\n",
    "        #one_hot.scatter_(1, yb.view(-1, 1).long(), 1)\n",
    "        #with torch.no_grad():\n",
    "        #    B_avg = torch.where(one_hot < 1, torch.exp(self.s * logits), torch.zeros_like(logits))\n",
    "        #    B_avg = torch.sum(B_avg) / xb.size(0)\n",
    "        #    #print(B_avg)\n",
    "        #    theta_med = torch.median(theta[one_hot == 1])\n",
    "        #    self.s = torch.log(B_avg) / torch.cos(torch.min(math.pi/4 * torch.ones_like(theta_med), theta_med))\n",
    "        #    #print(self.s)\n",
    "            \n",
    "        # ADAPTED FOR CUTMIX TO GET MIXED SCALE PARAMETER\n",
    "        with torch.no_grad():\n",
    "            # FROM nb_new_data_augmentation_adacos2.py LINE 888\n",
    "            # AND https://github.com/fastai/fastai/blob/master/fastai/callbacks/mixup.py#L40\n",
    "            if yb.ndim == 2:# and target.shape[-1] >1:\n",
    "                n_mod_patches = (yb.shape[-1] - 1) // 2\n",
    "                #c_ = yb[:, 1:n_mod_patches + 1]\n",
    "                c_ = yb[:, 0:n_mod_patches + 1]\n",
    "                W_ = yb[:, n_mod_patches + 1:]\n",
    "                self.s_scaled = []\n",
    "                \n",
    "                # this loop is only realdy needed when we have different probabilities inside a batch\n",
    "                # which we do not have (right now)! So this could be cleaned up, but we leave until\n",
    "                # we know we will not need the case with different probabilities in a batch.\n",
    "                for k in range(n_mod_patches+1):\n",
    "                    yb_new = c_[:, k].long()\n",
    "                    #pdb.set_trace()\n",
    "                    \n",
    "                    one_hot.scatter_(1, yb_new.view(-1,1).long(), 1)\n",
    "                    \n",
    "                    B_avg = torch.where(one_hot < 1, torch.exp(self.s * logits), torch.zeros_like(logits))\n",
    "                    B_avg = torch.sum(B_avg) / xb.size(0)\n",
    "                    theta_med = torch.median(theta[one_hot == 1])\n",
    "                    self.s = torch.log(B_avg) / torch.cos(torch.min(math.pi/4 * torch.ones_like(theta_med), theta_med))\n",
    "                    \n",
    "                    if k+1 == len(range(n_mod_patches+1)):\n",
    "                        #self.s_scaled.append((1-W_[:, k-1]) * self.s)\n",
    "                        self.s_scaled.append((1-W_[0, k-1]) * self.s)\n",
    "                        # For more than two the sum of W_[:, :k] has to be used!!!\n",
    "                    else:\n",
    "                        #self.s_scaled.append(W_[:, k] * self.s)\n",
    "                        self.s_scaled.append(W_[0, k] * self.s)\n",
    "                    # Mixed B_avg & self.s and single are not really far off, but now we have it coded\n",
    "                    # se we keep it (until it breaks something later).\n",
    "                self.s = torch.add(*self.s_scaled)\n",
    "                # Clean up, self.s_scaled is just a vector with the same entry multiple times\n",
    "                # when it is not indexed above with W_[0,... !\n",
    "            else:\n",
    "                one_hot.scatter_(1, yb.view(-1,1).long(), 1)\n",
    "                B_avg = torch.where(one_hot < 1, torch.exp(self.s * logits), torch.zeros_like(logits))\n",
    "                B_avg = torch.sum(B_avg) / xb.size(0)\n",
    "                theta_med = torch.median(theta[one_hot == 1])\n",
    "                self.s = torch.log(B_avg) / torch.cos(torch.min(math.pi/4 * torch.ones_like(theta_med), theta_med))\n",
    "        \n",
    "        output = self.s * logits\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:39.032633Z",
     "start_time": "2019-09-03T04:30:39.001486Z"
    }
   },
   "outputs": [],
   "source": [
    "class AdaCosNet(nn.Module):\n",
    "    '''Simple AdaCosNet connecter to run xb through the feature extractor head\n",
    "    and then feed xb and yb into the AdaCos layer.'''\n",
    "    def __init__(self, body1, body2, head):\n",
    "        super(AdaCosNet, self).__init__()\n",
    "        self.body1 = body1\n",
    "        self.body2 = body2\n",
    "        self.head = head\n",
    "        self.adacos = AdaCos(512, 277) # was 1108 !!!\n",
    "        \n",
    "    def forward(self, xb, yb=None): # yb=None for training in non-AdaCos mode!\n",
    "        xb_img, xb_ctint, xb_pgint, xb_expint = xb\n",
    "        resnet_features = self.body1(xb_img)\n",
    "        int_features = self.body2(xb_ctint, xb_pgint, xb_expint)\n",
    "        features = torch.cat((resnet_features, int_features), dim=-1)\n",
    "        out = self.head(features)\n",
    "        #print('xb.shape: ', xb.shape,', yb.shape: ', yb.shape)\n",
    "        out = self.adacos(out, yb)\n",
    "        #print('out: ',out.shape)\n",
    "        #pdb.set_trace()\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:39.062020Z",
     "start_time": "2019-09-03T04:30:39.033593Z"
    }
   },
   "outputs": [],
   "source": [
    "adacos_efficientnet = AdaCosNet(efficientnet_fph, ctf, adacos_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:39.098611Z",
     "start_time": "2019-09-03T04:30:39.063545Z"
    }
   },
   "outputs": [],
   "source": [
    "xb = (torch.randn(2,6,sz,sz),\n",
    "      #(torch.randint(4, (2,1)),  torch.randint(4, (2,1)))\n",
    "      torch.tensor((1,3)), torch.tensor((1,3)), torch.tensor((1,3))\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:39.847306Z",
     "start_time": "2019-09-03T04:30:39.100165Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yb = None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 277])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adacos_efficientnet(xb).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:40.941703Z",
     "start_time": "2019-09-03T04:30:39.850600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 277])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adacos_efficientnet(xb, torch.tensor([276, 1])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:40.965255Z",
     "start_time": "2019-09-03T04:30:40.943132Z"
    }
   },
   "outputs": [],
   "source": [
    "test_target = torch.tensor(\n",
    "    [[2.4700e+02, 2.3900e+02, 7.8362e-01],\n",
    "     [2.3300e+02, 1.7400e+02, 7.8362e-01],\n",
    "     [1.7400e+02, 1.3400e+02, 7.8362e-01],\n",
    "     [1.9800e+02, 1.4700e+02, 7.8362e-01]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:42.773441Z",
     "start_time": "2019-09-03T04:30:40.966505Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 277])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adacos_efficientnet((torch.randn(4,6,sz,sz), \n",
    "                     torch.tensor((1,3,0,2)), torch.tensor((1,3,0,2)), torch.tensor((1,3,0,2))),\n",
    "                    test_target).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:42.800943Z",
     "start_time": "2019-09-03T04:30:42.777128Z"
    }
   },
   "outputs": [],
   "source": [
    "# Based on https://forums.fast.ai/t/teacher-forcing/29415/4\n",
    "# https://forums.fast.ai/t/on-batch-begin-callback/35201/3\n",
    "@dataclass\n",
    "class AppendBatchTargs(Callback):\n",
    "    learn:Learner\n",
    "    def __init__(self, learn):\n",
    "        super().__init__()\n",
    "    def on_batch_begin(self, last_input, last_target, **kwargs):\n",
    "        return {'last_input':(last_input, last_target), 'last_target':last_target}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:42.824420Z",
     "start_time": "2019-09-03T04:30:42.804276Z"
    }
   },
   "outputs": [],
   "source": [
    "#def check_rg(model=learn.model):\n",
    "#    layer_rg = [(n, p.requires_grad) for n,p in model.named_parameters()]\n",
    "#    for i in range(len(layer_rg)):\n",
    "#        print(f'{layer_rg[i][0]}\\t{layer_rg[i][1]}'.expandtabs(45))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.034607Z",
     "start_time": "2019-09-03T04:30:42.828164Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ===  0  ===  HEPG2  === \n",
      "train:  (3874, 7)\n",
      "valid:  (1108, 7)\n",
      " ===  0  ===  HUVEC  === \n",
      "train:  (8844, 7)\n",
      "valid:  (1102, 7)\n",
      " ===  0  ===  RPE  === \n",
      "train:  (3878, 7)\n",
      "valid:  (1108, 7)\n",
      " ===  0  ===  U2OS  === \n",
      "train:  (1662, 7)\n",
      "valid:  (554, 7)\n",
      " ===  1  ===  HEPG2  === \n",
      "train:  (3876, 7)\n",
      "valid:  (1106, 7)\n",
      " ===  1  ===  HUVEC  === \n",
      "train:  (8842, 7)\n",
      "valid:  (1100, 7)\n",
      " ===  1  ===  RPE  === \n",
      "train:  (3876, 7)\n",
      "valid:  (1106, 7)\n",
      " ===  1  ===  U2OS  === \n",
      "train:  (1662, 7)\n",
      "valid:  (554, 7)\n",
      " ===  2  ===  HEPG2  === \n",
      "train:  (3878, 7)\n",
      "valid:  (1108, 7)\n",
      " ===  2  ===  HUVEC  === \n",
      "train:  (8848, 7)\n",
      "valid:  (1102, 7)\n",
      " ===  2  ===  RPE  === \n",
      "train:  (3876, 7)\n",
      "valid:  (1108, 7)\n",
      " ===  2  ===  U2OS  === \n",
      "train:  (1662, 7)\n",
      "valid:  (554, 7)\n",
      " ===  3  ===  HEPG2  === \n",
      "train:  (3872, 7)\n",
      "valid:  (1106, 7)\n",
      " ===  3  ===  HUVEC  === \n",
      "train:  (8842, 7)\n",
      "valid:  (1100, 7)\n",
      " ===  3  ===  RPE  === \n",
      "train:  (3876, 7)\n",
      "valid:  (1106, 7)\n",
      " ===  3  ===  U2OS  === \n",
      "train:  (1662, 7)\n",
      "valid:  (554, 7)\n"
     ]
    }
   ],
   "source": [
    "for pg in range(4):\n",
    "    for ct in cts:\n",
    "        print(' === ', pg ,' === ', ct , ' === ')\n",
    "        print('train: ', df_train[(df_train['pg'] == pg) & (df_train['celltype'] == ct)].shape)\n",
    "        print('valid: ', df_train[(df_train['pg'] == pg) & (df_train['celltype'] == ct) & (df_train['valid'] == 1)].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.188965Z",
     "start_time": "2019-09-03T04:30:43.047098Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-130-ce3af7760f12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'xx' is not defined"
     ]
    }
   ],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.199371Z",
     "start_time": "2019-09-03T04:30:35.608Z"
    }
   },
   "outputs": [],
   "source": [
    "lrs = [1e-5, 1e-5, 1e-5, 1e-5, 1e-3, 1e-4, 1e-4, 1e-3, 1e-3, 1e-6, 1e-4, 1e-4, 1e-4, 1e-6, 1e-4, 1e-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.199917Z",
     "start_time": "2019-09-03T04:30:35.618Z"
    }
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for pg in range(4):\n",
    "    for ct in cts:\n",
    "        \n",
    "        print(' === ', pg ,' === ', ct , ' === ')\n",
    "\n",
    "        # VALID SPLIT (incl. tfms)\n",
    "        data = (ImageList6Dct.from_df(df_train[(df_train['pg'] == pg) & (df_train['celltype'] == ct)], path='train')\n",
    "        .split_from_df(col=-3) # FULL: .split_none() # !!!\n",
    "        .label_from_df(cols=-5)\n",
    "        #.add_test(ImageList6Dct.from_df(df_test[(df_test['pg'] == pg) & (df_test['celltype'] == ct)], path='test'))\n",
    "        .transform(tfms, size=sz)\n",
    "        .databunch(bs=bs))\n",
    "        \n",
    "        data.normalize([stats_mean, stats_var]);\n",
    "        \n",
    "        learn = Learner(data, adacos_efficientnet, metrics=[accuracy], callback_fns=[CSVLogger, AppendBatchTargs])\n",
    "        learn.load('effnet/adacos_efficientnet_b3_ct_pg_exp_Pre060e050pg'+str(pg)+'e100_190901');\n",
    "        learn.unfreeze()\n",
    "        learn.fit(25, lr=lrs[i])\n",
    "        learn.save('effnet/adacos_efficientnet_b3_ct_pg_exp_Pre060e050pg'+str(pg)+'e100'+ct+'025_190903');\n",
    "        i += 1\n",
    "        print('')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.200433Z",
     "start_time": "2019-09-03T04:30:35.627Z"
    }
   },
   "outputs": [],
   "source": [
    "xxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lrs pg & ct #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.200956Z",
     "start_time": "2019-09-03T04:30:35.644Z"
    }
   },
   "outputs": [],
   "source": [
    "for pg in range(4):\n",
    "    for ct in cts:\n",
    "        print(' === ', pg ,' === ', ct , ' === ')\n",
    "\n",
    "        # VALID SPLIT (incl. tfms)\n",
    "        data = (ImageList6Dct.from_df(df_train[(df_train['pg'] == pg) & (df_train['celltype'] == ct)], path='train')\n",
    "        .split_from_df(col=-3) # FULL: .split_none() # !!!\n",
    "        .label_from_df(cols=-5)\n",
    "        #.add_test(ImageList6Dct.from_df(df_test[(df_test['pg'] == pg) & (df_test['celltype'] == ct)], path='test'))\n",
    "        .transform(tfms, size=sz)\n",
    "        .databunch(bs=bs))\n",
    "        \n",
    "        data.normalize([stats_mean, stats_var]);\n",
    "        \n",
    "        learn = Learner(data, adacos_efficientnet, metrics=[accuracy], callback_fns=[CSVLogger, AppendBatchTargs])\n",
    "        learn.load('effnet/adacos_efficientnet_b3_ct_pg_exp_Pre060e050pg'+str(pg)+'e100_190901');\n",
    "        learn.unfreeze()\n",
    "        \n",
    "        #learn.fit_one_cycle(25, max_lr=1e-4)\n",
    "        #learn.save('effnet/adacos_efficientnet_b3_ct_pg_exp_Pre060e050pg'+str(pg)+'e100'+ct+'025_190902');\n",
    "        \n",
    "        learn.lr_find()\n",
    "        learn.recorder.plot(suggestion=True)\n",
    "        \n",
    "        print('')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.201475Z",
     "start_time": "2019-09-03T04:30:35.652Z"
    }
   },
   "outputs": [],
   "source": [
    "lrs = [1e-5, 1e-5, 1e-5, 1e-5, 1e-3, 1e-4, 1e-4, 1e-3, 1e-3, 1e-6, 1e-4, 1e-4, 1e-4, 1e-6, 1e-4, 1e-4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train pg & ct #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.207078Z",
     "start_time": "2019-09-03T04:30:35.661Z"
    }
   },
   "outputs": [],
   "source": [
    "for pg in range(4):\n",
    "    for ct in cts:\n",
    "        print(' === ', pg ,' === ', ct , ' === ')\n",
    "\n",
    "        # VALID SPLIT (incl. tfms)\n",
    "        data = (ImageList6Dct.from_df(df_train[(df_train['pg'] == pg) & (df_train['celltype'] == ct)], path='train')\n",
    "        .split_from_df(col=-3) # FULL: .split_none() # !!!\n",
    "        .label_from_df(cols=-5)\n",
    "        #.add_test(ImageList6Dct.from_df(df_test[(df_test['pg'] == pg) & (df_test['celltype'] == ct)], path='test'))\n",
    "        .transform(tfms, size=sz)\n",
    "        .databunch(bs=bs))\n",
    "        \n",
    "        data.normalize([stats_mean, stats_var]);\n",
    "        \n",
    "        learn = Learner(data, adacos_efficientnet, metrics=[accuracy], callback_fns=[CSVLogger, AppendBatchTargs])\n",
    "        learn.load('effnet/adacos_efficientnet_b3_ct_pg_exp_Pre060e050pg'+str(pg)+'e100_190901');\n",
    "        learn.unfreeze()\n",
    "        learn.fit_one_cycle(25, max_lr=1e-4)\n",
    "        learn.save('effnet/adacos_efficientnet_b3_ct_pg_exp_Pre060e050pg'+str(pg)+'e100'+ct+'025_190903');\n",
    "        \n",
    "        print('')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.207778Z",
     "start_time": "2019-09-03T04:30:35.668Z"
    }
   },
   "outputs": [],
   "source": [
    "xxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.208320Z",
     "start_time": "2019-09-03T04:30:35.675Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train[(df_train['pg'] == 0) & (df_train['celltype'] == 'HEPG2')].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Classifcation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.208863Z",
     "start_time": "2019-09-03T04:30:35.685Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.load('resnet50/adacos_se_xresnet50c_val-split-v2_128e040-256e106CMe110_20190729');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.209404Z",
     "start_time": "2019-09-03T04:30:35.694Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get prediction of test dataset\n",
    "preds, _ = learn.get_preds(ds_type=DatasetType.Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.209944Z",
     "start_time": "2019-09-03T04:30:35.702Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# check length\n",
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.210483Z",
     "start_time": "2019-09-03T04:30:35.709Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get the categories\n",
    "preds_cat = preds.argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.211026Z",
     "start_time": "2019-09-03T04:30:35.717Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get the names\n",
    "preds_names = learn.data.test_ds.x.items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.215037Z",
     "start_time": "2019-09-03T04:30:35.724Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# without site\n",
    "#preds_names = [x.split('/')[1]+'_'+x.split('/')[2][-1]+'_'+x.split('/')[3][:3] for x in preds_names]\n",
    "\n",
    "# with site\n",
    "preds_names = [x.split('/')[1]+'_'+x.split('/')[2][-1]+'_'+x.split('/')[3] for x in preds_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.215599Z",
     "start_time": "2019-09-03T04:30:35.732Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_preds = pd.DataFrame({'id_code_site': preds_names, 'sirna': preds_cat})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.216155Z",
     "start_time": "2019-09-03T04:30:35.744Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get id_code without site\n",
    "df_preds['id_code'] = df_preds['id_code_site'].apply(lambda x: x[:-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.216705Z",
     "start_time": "2019-09-03T04:30:35.753Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get row indices with the same/not the same the prediction for both sites\n",
    "idx = [] # indices with the same prediction\n",
    "idx_notsame = [] # indices with not the same prediction\n",
    "for i, r in enumerate(df_preds.sort_values('id_code').iterrows()):\n",
    "    if i % 2:\n",
    "        # distance from row 2 is \n",
    "        if pred == r[1]['sirna']:\n",
    "            idx.append(r[0])\n",
    "        else:\n",
    "            #idx.append(r[0]) # always append idx until we come up with something better\n",
    "            idx.append(idx_row_before)\n",
    "            idx_notsame.append(idx_row_before) # get the first rows of the pairs that are not the same\n",
    "    else:\n",
    "        # save dist from row 1 for comparison in next iteration\n",
    "        pred = r[1]['sirna']\n",
    "        idx_row_before = r[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.217245Z",
     "start_time": "2019-09-03T04:30:35.762Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len(idx), len(idx_notsame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.217784Z",
     "start_time": "2019-09-03T04:30:35.770Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "idx[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.218326Z",
     "start_time": "2019-09-03T04:30:35.781Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_preds.sort_values('id_code').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.218867Z",
     "start_time": "2019-09-03T04:30:35.798Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#df_preds.loc[idx,['id_code','sirna']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.219407Z",
     "start_time": "2019-09-03T04:30:35.814Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 'effnet/adacos_efficientnet_b3_e080CM112_190805'\n",
    "model = 'metriclearn_efficientnet_b3_e080CM112_190805'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.219960Z",
     "start_time": "2019-09-03T04:30:35.822Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_preds.loc[idx,['id_code','sirna']].to_csv('sub/'+model+'.csv.gz', index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.220909Z",
     "start_time": "2019-09-03T04:30:35.831Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c recursion-cellular-image-classification -f sub/{model}.csv.gz -m \"{model}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosinus similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full single features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.221490Z",
     "start_time": "2019-09-03T04:30:35.843Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://github.com/ducha-aiki/whale-identification-2018/blob/master/reproduce_problems.ipynb\n",
    "# And for test-time augmentation I used following random solution: switch train and val transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.222042Z",
     "start_time": "2019-09-03T04:30:35.852Z"
    }
   },
   "outputs": [],
   "source": [
    "# extended tfms\n",
    "tfms = get_transforms(do_flip=True, flip_vert=True, \n",
    "                      max_rotate=90.0, max_zoom=1.1, \n",
    "                      max_lighting=0.2, max_warp=0.2, \n",
    "                      p_affine=0.75, p_lighting=0.75, \n",
    "                      xtra_tfms=[color_augmentation()])\n",
    "\n",
    "# crop_pad: https://forums.fast.ai/t/misc-issues/35386/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.222696Z",
     "start_time": "2019-09-03T04:30:35.860Z"
    }
   },
   "outputs": [],
   "source": [
    "# extended tfms w/o color_augmentation !!!\n",
    "#tfms = get_transforms(do_flip=True, flip_vert=True, \n",
    "#                      max_rotate=90.0, max_zoom=1.1, \n",
    "#                      max_lighting=0.2, max_warp=0.2, \n",
    "#                      p_affine=0.75, p_lighting=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.223419Z",
     "start_time": "2019-09-03T04:30:35.870Z"
    }
   },
   "outputs": [],
   "source": [
    "# \"crop_pad\" to sz\n",
    "tfms[0][0] = crop_pad(size=sz, row_pct=[0.,1.], col_pct=[0.,1.])\n",
    "tfms[1][0] = crop_pad(size=sz, row_pct=[0.,1.], col_pct=[0.,1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.224048Z",
     "start_time": "2019-09-03T04:30:35.879Z"
    }
   },
   "outputs": [],
   "source": [
    "#sz, bs = 300, 8*2*2 # 3436MiB /  7952MiB\n",
    "#sz, bs = 300, 8*8 # 6884MiB /  7952MiB\n",
    "sz, bs = 300, 8*11 # 7938MiB /  7952MiB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.224662Z",
     "start_time": "2019-09-03T04:30:35.887Z"
    }
   },
   "outputs": [],
   "source": [
    "#pg = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.225306Z",
     "start_time": "2019-09-03T04:30:35.896Z"
    }
   },
   "outputs": [],
   "source": [
    "# VALID SPLIT (incl. tfms)\n",
    "data = (ImageList6Dct.from_df(df_train[df_train['pg'] == pg], path='train')\n",
    "        .split_from_df(col=-3) # FULL: .split_none() # !!!\n",
    "        .label_from_df(cols=-5)\n",
    "        .add_test(ImageList6Dct.from_df(df_test[df_test['pg'] == pg], path='test'))\n",
    "        .transform(tfms, size=sz)\n",
    "        .databunch(bs=bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.225931Z",
     "start_time": "2019-09-03T04:30:35.904Z"
    }
   },
   "outputs": [],
   "source": [
    "data.normalize([stats_mean, stats_var]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.226556Z",
     "start_time": "2019-09-03T04:30:35.911Z"
    }
   },
   "outputs": [],
   "source": [
    "#ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.231270Z",
     "start_time": "2019-09-03T04:30:35.919Z"
    }
   },
   "outputs": [],
   "source": [
    "pg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.232007Z",
     "start_time": "2019-09-03T04:30:35.926Z"
    }
   },
   "outputs": [],
   "source": [
    "#data.train_dl.dl.batch_sampler.sampler = torch.utils.data.SequentialSampler(data.train_ds)\n",
    "#data.train_dl.dl.batch_sampler.drop_last = False\n",
    "#\n",
    "#data.valid_dl.dl.batch_sampler.sampler = torch.utils.data.SequentialSampler(data.valid_ds)\n",
    "#data.valid_dl.dl.batch_sampler.drop_last = False\n",
    "#\n",
    "## DOES WORK TOO FOR TEST DL ??? ??? (Or do we need to set the test dataset to the valid dataset?)\n",
    "#data.test_dl.dl.batch_sampler.sampler = torch.utils.data.SequentialSampler(data.test_ds)\n",
    "#data.test_dl.dl.batch_sampler.drop_last = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.232730Z",
     "start_time": "2019-09-03T04:30:35.937Z"
    }
   },
   "outputs": [],
   "source": [
    "learn = Learner(data, adacos_efficientnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.233448Z",
     "start_time": "2019-09-03T04:30:35.944Z"
    }
   },
   "outputs": [],
   "source": [
    "learn.load('effnet/adacos_efficientnet_b3_ct_pg_exp_Pre060e050pg'+str(pg)+'e100_190901');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.234138Z",
     "start_time": "2019-09-03T04:30:35.951Z"
    }
   },
   "outputs": [],
   "source": [
    "#def get_feats(model, dataloader, cycles=1):\n",
    "#    feats = []\n",
    "#    targs = []\n",
    "#    model.eval()\n",
    "#    with torch.no_grad():\n",
    "#        for i in range(cycles): # for TTA\n",
    "#            for xb, yb in dataloader:\n",
    "#                body_out = model.body(xb)\n",
    "#                head_out = model.head(body_out)\n",
    "#                feats.append(head_out.cpu())\n",
    "#                targs.append(yb.cpu())\n",
    "#    return feats, targs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.234839Z",
     "start_time": "2019-09-03T04:30:35.961Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_feats(model, dataloader, cycles=1):\n",
    "    feats = []\n",
    "    targs = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(cycles): # for TTA\n",
    "            for xb, yb in dataloader:\n",
    "                xb_img, xb_ctint, xb_pgint, xb_expint = xb\n",
    "                img_features = model.body1(xb_img)\n",
    "                int_features = model.body2(xb_ctint, xb_pgint, xb_expint)\n",
    "                features = torch.cat((img_features, int_features), dim=-1)\n",
    "                out = model.head(features)\n",
    "                feats.append(out.cpu())\n",
    "                targs.append(yb.cpu())\n",
    "    return feats, targs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.235527Z",
     "start_time": "2019-09-03T04:30:35.970Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_img_exp_feats(model, dataloader, cycles=1):\n",
    "    feats = []\n",
    "    targs = []\n",
    "    img_feats = []\n",
    "    exp_input = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(cycles): # for TTA\n",
    "            for xb, yb in dataloader:\n",
    "                xb_img, xb_ctint, xb_pgint, xb_expint = xb\n",
    "                img_features = model.body1(xb_img)\n",
    "                int_features = model.body2(xb_ctint, xb_pgint, xb_expint)\n",
    "                features = torch.cat((img_features, int_features), dim=-1)\n",
    "                out = model.head(features)\n",
    "                feats.append(out.cpu())\n",
    "                targs.append(yb.cpu())\n",
    "                img_feats.append(img_features)\n",
    "                exp_input.append(xb_expint.cpu())\n",
    "    return feats, targs, img_feats, exp_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.236193Z",
     "start_time": "2019-09-03T04:30:35.980Z"
    }
   },
   "outputs": [],
   "source": [
    "feats, targs = get_feats(learn.model, learn.data.train_dl, cycles=3)\n",
    "#feats, targs, img_feats, exp_input = get_img_exp_feats(learn.model, learn.data.train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.236940Z",
     "start_time": "2019-09-03T04:30:35.989Z"
    }
   },
   "outputs": [],
   "source": [
    "feats = torch.cat(feats, dim=0)\n",
    "targs = torch.cat(targs, dim=0)\n",
    "#img_feats = torch.cat(img_feats, dim=0)\n",
    "#exp_input = torch.cat(exp_input, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.237677Z",
     "start_time": "2019-09-03T04:30:35.999Z"
    }
   },
   "outputs": [],
   "source": [
    "# get class from data classes index\n",
    "targs_cl = torch.tensor([learn.data.classes[t] for t in targs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.238410Z",
     "start_time": "2019-09-03T04:30:36.011Z"
    }
   },
   "outputs": [],
   "source": [
    "feats.shape, targs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.239107Z",
     "start_time": "2019-09-03T04:30:36.021Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save('pred/feats_train_pg'+str(pg)+'.npy', feats)\n",
    "np.save('pred/targs_train_pg'+str(pg)+'.npy', targs)\n",
    "np.save('pred/targs_cl_train_pg'+str(pg)+'.npy', targs_cl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.239834Z",
     "start_time": "2019-09-03T04:30:36.032Z"
    }
   },
   "outputs": [],
   "source": [
    "feats, targs = get_feats(learn.model, learn.data.valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.240551Z",
     "start_time": "2019-09-03T04:30:36.041Z"
    }
   },
   "outputs": [],
   "source": [
    "feats = torch.cat(feats, dim=0)\n",
    "targs = torch.cat(targs, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.241260Z",
     "start_time": "2019-09-03T04:30:36.050Z"
    }
   },
   "outputs": [],
   "source": [
    "# get class from data classes index\n",
    "targs_cl = torch.tensor([learn.data.classes[t] for t in targs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.241958Z",
     "start_time": "2019-09-03T04:30:36.060Z"
    }
   },
   "outputs": [],
   "source": [
    "feats.shape, feats.shape, targs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.242671Z",
     "start_time": "2019-09-03T04:30:36.069Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save('pred/feats_valid_pg'+str(pg)+'.npy', feats)\n",
    "np.save('pred/targs_valid_pg'+str(pg)+'.npy', targs)\n",
    "np.save('pred/targs_cl_valid_pg'+str(pg)+'.npy', targs_cl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.243345Z",
     "start_time": "2019-09-03T04:30:36.079Z"
    }
   },
   "outputs": [],
   "source": [
    "feats, targs = get_feats(learn.model, learn.data.test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.244040Z",
     "start_time": "2019-09-03T04:30:36.089Z"
    }
   },
   "outputs": [],
   "source": [
    "del targs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.244708Z",
     "start_time": "2019-09-03T04:30:36.099Z"
    }
   },
   "outputs": [],
   "source": [
    "feats = torch.cat(feats, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.245376Z",
     "start_time": "2019-09-03T04:30:36.109Z"
    }
   },
   "outputs": [],
   "source": [
    "feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.246065Z",
     "start_time": "2019-09-03T04:30:36.118Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save('pred/feats_test_pg'+str(pg)+'.npy', feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.246748Z",
     "start_time": "2019-09-03T04:30:36.127Z"
    }
   },
   "outputs": [],
   "source": [
    "len(learn.data.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Multi-crop features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.247445Z",
     "start_time": "2019-09-03T04:30:36.135Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# https://github.com/ducha-aiki/whale-identification-2018/blob/master/reproduce_problems.ipynb\n",
    "# And for test-time augmentation I used following random solution: switch train and val transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.248143Z",
     "start_time": "2019-09-03T04:30:36.142Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_train['test'] = 0\n",
    "df_train['path'] = 'train/'+df_train['path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.248807Z",
     "start_time": "2019-09-03T04:30:36.152Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.249533Z",
     "start_time": "2019-09-03T04:30:36.159Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# add dummy columns for test dataset\n",
    "df_test['path'] = 'test/'+df_test['path']\n",
    "df_test['test'] = 1\n",
    "df_test['sirna'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.250211Z",
     "start_time": "2019-09-03T04:30:36.167Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.250896Z",
     "start_time": "2019-09-03T04:30:36.175Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_train_test = pd.concat((df_train, df_test), axis=0, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.251567Z",
     "start_time": "2019-09-03T04:30:36.182Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_train_test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.252252Z",
     "start_time": "2019-09-03T04:30:36.189Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# reload for train and valid ds\n",
    "df_train = pd.read_csv('full_train_dataset_valid-split-ex_v2_20190727.csv', index_col=0)\n",
    "df_test = pd.read_csv('full_test_dataset_v2_20190727.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-05T17:44:39.974069Z",
     "start_time": "2019-08-05T17:44:39.962352Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.258559Z",
     "start_time": "2019-09-03T04:30:36.201Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# test tfms switching for test ds\n",
    "#tfms_switched = (tfms[1], tfms[0])\n",
    "#\n",
    "#data = (ImageList6D.from_df(df_train_test, path='.')\n",
    "#                .split_from_df(col=-1)\n",
    "#                .label_from_df(cols=-4)\n",
    "#                .transform(tfms_switched)#, size=sz) # remove size so we get the crop size!\n",
    "#                .databunch(bs=bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.259434Z",
     "start_time": "2019-09-03T04:30:36.208Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#data.train_ds[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.260129Z",
     "start_time": "2019-09-03T04:30:36.214Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#data.valid_ds[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.260803Z",
     "start_time": "2019-09-03T04:30:36.226Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_dataset(row_pct, col_pct, is_test=False):\n",
    "    # extended tfms\n",
    "    tfms = get_transforms(do_flip=True, flip_vert=True, \n",
    "                          max_rotate=90.0, max_zoom=1.1, \n",
    "                          max_lighting=0.2, max_warp=0.2, \n",
    "                          p_affine=0.75, p_lighting=0.75, \n",
    "                          xtra_tfms=[color_augmentation()])\n",
    "    \n",
    "    # change \"crop_pad\" from get_transforms to \"crop\"\n",
    "    tfms[0][0] = crop(size=sz, row_pct=row_pct, col_pct=col_pct)\n",
    "    tfms[1][0] = crop(size=sz, row_pct=row_pct, col_pct=col_pct)\n",
    "    \n",
    "    # VALID SPLIT (incl. tfms)\n",
    "    if is_test:\n",
    "        #switch train with valid (= test) tfms!\n",
    "        tfms_switched = (tfms[1], tfms[0])\n",
    "        \n",
    "        data = (ImageList6D.from_df(df_train_test, path='.')\n",
    "                .split_from_df(col=-1)\n",
    "                .label_from_df(cols=-4)\n",
    "                .transform(tfms_switched)#, size=sz) # remove size so we get the crop size!\n",
    "                .databunch(bs=bs))\n",
    "    else:\n",
    "        data = (ImageList6D.from_df(df_train, path='train')\n",
    "                .split_from_df(col=-1) # split_by_rand_pct()\n",
    "                .label_from_df(cols=-3)\n",
    "                #.add_test(ImageList6D.from_df(df_test, path='test'))\n",
    "                .transform(tfms)#, size=sz) # remove size so we get the crop size!\n",
    "                .databunch(bs=bs))\n",
    "    \n",
    "    data.normalize([tensor([0.0456, 0.0702, 0.0447, 0.0468, 0.0407, 0.0399]),\n",
    "                    tensor([0.0644, 0.0733, 0.0536, 0.0633, 0.0555, 0.0392])]);\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.261472Z",
     "start_time": "2019-09-03T04:30:36.233Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_feats(model, dataloader, cycles=1):\n",
    "    feats = []\n",
    "    targs = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(cycles): # for TTA\n",
    "            for xb, yb in dataloader:\n",
    "                body_out = model.body(xb)\n",
    "                head_out = model.head(body_out)\n",
    "                feats.append(head_out.cpu())\n",
    "                targs.append(yb.cpu())\n",
    "                \n",
    "    feats = torch.cat(feats, dim=0)\n",
    "    targs = torch.cat(targs, dim=0)\n",
    "    \n",
    "    return feats, targs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.262127Z",
     "start_time": "2019-09-03T04:30:36.241Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def save_feats(feats, targs, crop, ds='train'):\n",
    "    np.save(f'pred/feats_{ds}_crop{crop}.npy', feats)\n",
    "    np.save(f'pred/targs_{ds}_crop{crop}.npy', targs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.262791Z",
     "start_time": "2019-09-03T04:30:36.248Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#https://docs.fast.ai/vision.transform.html#_crop\n",
    "crop_pos = [[0.,0.], [0.,1.],[0.5,0.5],[1.,0.], [1.,1.]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.263471Z",
     "start_time": "2019-09-03T04:30:36.256Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get random crop pos\n",
    "i = 2\n",
    "crop_pos = [[uniform(0,1), uniform(0,1)] for i in range(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.264154Z",
     "start_time": "2019-09-03T04:30:36.264Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "crop_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.264819Z",
     "start_time": "2019-09-03T04:30:36.271Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# get the last three crop positions:\n",
    "crop_pos = [[0.5,0.5],[1.,0.], [1.,1.]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.265513Z",
     "start_time": "2019-09-03T04:30:36.277Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_crop_feats(model=learn.model, cycles=1, crop_pos=crop_pos):\n",
    "    \n",
    "    for i, (row_pct, col_pct) in enumerate(crop_pos):\n",
    "        \n",
    "        print('== crop#:', i,' of', len(crop_pos), '==')\n",
    "        print('row_pct:', row_pct,', col_pct:', col_pct)\n",
    "    \n",
    "        data = get_dataset(row_pct, col_pct)\n",
    "        \n",
    "        # train\n",
    "        print('= Start train dataset =')\n",
    "        feats, targs = get_feats(model, data.train_dl)\n",
    "        save_feats(feats, targs, i, ds='train')\n",
    "        print('feats:', feats.shape,' targs:', targs.shape)\n",
    "        print('- Finish train dataset -')\n",
    "        \n",
    "        # valid\n",
    "        print('= Start valid dataset =')\n",
    "        feats, targs = get_feats(model, data.valid_dl)\n",
    "        save_feats(feats, targs, i, ds='valid')\n",
    "        print('feats:', feats.shape,' targs:', targs.shape)\n",
    "        print('- Finish valid dataset -')\n",
    "        \n",
    "        # get test ds as valid ds for TTA\n",
    "        data = get_dataset(row_pct, col_pct, is_test=True)\n",
    "        \n",
    "        # test\n",
    "        print('= Start test dataset =')\n",
    "        feats, targs = get_feats(model, data.valid_dl)\n",
    "        save_feats(feats, targs, i, ds='test')\n",
    "        print('feats:', feats.shape,' targs:', targs.shape)\n",
    "        print('- Finish test dataset -')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.266206Z",
     "start_time": "2019-09-03T04:30:36.285Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn = Learner(data, adacos_efficientnet_b3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.266889Z",
     "start_time": "2019-09-03T04:30:36.293Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learn.load('effnet/adacos_efficientnet_b3_e080CM112_190805');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.267579Z",
     "start_time": "2019-09-03T04:30:36.300Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "get_crop_feats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.268283Z",
     "start_time": "2019-09-03T04:30:36.318Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#data = (ImageList6D.from_df(df_train_test, path='.')\n",
    "#        .split_from_df(col=-1)\n",
    "#        .label_from_df(cols=-4)\n",
    "#        .transform(tfms_switched)#, size=sz) # remove size so we get the crop size!\n",
    "#        .databunch(bs=bs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.268961Z",
     "start_time": "2019-09-03T04:30:36.326Z"
    }
   },
   "outputs": [],
   "source": [
    "# get the names\n",
    "preds_names = learn.data.test_ds.x.items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.269668Z",
     "start_time": "2019-09-03T04:30:36.334Z"
    }
   },
   "outputs": [],
   "source": [
    "# without site\n",
    "#preds_names = [x.split('/')[1]+'_'+x.split('/')[2][-1]+'_'+x.split('/')[3][:3] for x in preds_names]\n",
    "\n",
    "# with site\n",
    "preds_names = [x.split('/')[1]+'_'+x.split('/')[2][-1]+'_'+x.split('/')[3] for x in preds_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.270309Z",
     "start_time": "2019-09-03T04:30:36.340Z"
    }
   },
   "outputs": [],
   "source": [
    "preds_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.271007Z",
     "start_time": "2019-09-03T04:30:36.348Z"
    }
   },
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/27745500/how-to-save-a-list-to-a-file-and-read-it-as-a-list-type\n",
    "with open('pred/preds_test_pg'+str(pg)+'_names.txt', 'wb') as fp:   #Pickling\n",
    "    pickle.dump(preds_names, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.271740Z",
     "start_time": "2019-09-03T04:30:36.355Z"
    }
   },
   "outputs": [],
   "source": [
    "#with open('pred/preds_test_pg'+str(pg)+'_names.txt', 'rb') as fp:   # Unpickling\n",
    "#    b = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.272435Z",
     "start_time": "2019-09-03T04:30:36.364Z"
    }
   },
   "outputs": [],
   "source": [
    "preds_test = np.load('pred/preds_test_pg'+str(pg)+'.npy')\n",
    "dist_test = np.load('pred/dist_test_pg'+str(pg)+'.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.273107Z",
     "start_time": "2019-09-03T04:30:36.371Z"
    }
   },
   "outputs": [],
   "source": [
    "len(preds_names), len(preds_test), len(dist_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.273813Z",
     "start_time": "2019-09-03T04:30:36.379Z"
    }
   },
   "outputs": [],
   "source": [
    "#preds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.274538Z",
     "start_time": "2019-09-03T04:30:36.386Z"
    }
   },
   "outputs": [],
   "source": [
    "#dist_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.275244Z",
     "start_time": "2019-09-03T04:30:36.395Z"
    }
   },
   "outputs": [],
   "source": [
    "df_preds = pd.DataFrame({'id_code_site': preds_names, 'sirna': preds_test, 'cossim': dist_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.275955Z",
     "start_time": "2019-09-03T04:30:36.404Z"
    }
   },
   "outputs": [],
   "source": [
    "# get id_code without site\n",
    "df_preds['id_code'] = df_preds['id_code_site'].apply(lambda x: x[:-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.276646Z",
     "start_time": "2019-09-03T04:30:36.411Z"
    }
   },
   "outputs": [],
   "source": [
    "# get row indices with highest cosine similiarity\n",
    "idx = []\n",
    "for i, r in enumerate(df_preds.sort_values('id_code').iterrows()):\n",
    "    #print(r)\n",
    "    #print('i: ',i)\n",
    "    #print('idx: ',r[0])\n",
    "    #print(r[1]['cossim'])\n",
    "    if i % 2:\n",
    "        # distance from row 2 is \n",
    "        if dist < r[1]['cossim']:\n",
    "            idx.append(r[0])\n",
    "        else:\n",
    "            idx.append(idx_row_before)\n",
    "    else:\n",
    "        # save dist from row 1 for comparison in next iteration\n",
    "        dist = r[1]['cossim']\n",
    "        idx_row_before = r[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.277333Z",
     "start_time": "2019-09-03T04:30:36.418Z"
    }
   },
   "outputs": [],
   "source": [
    "idx[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.278034Z",
     "start_time": "2019-09-03T04:30:36.425Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_preds.sort_values('id_code').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.278722Z",
     "start_time": "2019-09-03T04:30:36.435Z"
    }
   },
   "outputs": [],
   "source": [
    "#df_preds.loc[idx,['id_code','sirna']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.279404Z",
     "start_time": "2019-09-03T04:30:36.447Z"
    }
   },
   "outputs": [],
   "source": [
    "# 'effnet/adacos_efficientnet_b3_ct_pg_exp_Pre060e050pg'+str(pg)+'e100_190901'\n",
    "model = 'adacos_efficientnet_b3_ct_pg_exp_Pre060e050pg'+str(pg)+'e100_190901_3xTTA-cossim'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.280094Z",
     "start_time": "2019-09-03T04:30:36.454Z"
    }
   },
   "outputs": [],
   "source": [
    "df_preds.loc[idx,['id_code','sirna']].to_csv('sub/'+model+'.csv.gz', index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.280766Z",
     "start_time": "2019-09-03T04:30:36.461Z"
    }
   },
   "outputs": [],
   "source": [
    "#!kaggle competitions submit -c recursion-cellular-image-classification -f sub/{model}.csv.gz -m \"{model}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.281410Z",
     "start_time": "2019-09-03T04:30:36.469Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('pred/preds_test_pg'+str(pg)+'_names.txt', 'rb') as fp:   # Unpickling\n",
    "    preds_names = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.282084Z",
     "start_time": "2019-09-03T04:30:36.475Z"
    }
   },
   "outputs": [],
   "source": [
    "preds_test_full = np.load('pred/preds_test_pg'+str(pg)+'_full.npy')\n",
    "dist_test_full = np.load('pred/dist_test_pg'+str(pg)+'_full.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.282765Z",
     "start_time": "2019-09-03T04:30:36.482Z"
    }
   },
   "outputs": [],
   "source": [
    "preds_test_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.283438Z",
     "start_time": "2019-09-03T04:30:36.489Z"
    }
   },
   "outputs": [],
   "source": [
    "dist_test_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.284200Z",
     "start_time": "2019-09-03T04:30:36.496Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    df_preds_full = pd.DataFrame({'id_code_site': preds_names,\n",
    "                                  'sirna': preds_test_full[:,i],\n",
    "                                  'cossim': dist_test_full[:,i]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.284910Z",
     "start_time": "2019-09-03T04:30:36.503Z"
    }
   },
   "outputs": [],
   "source": [
    "type(preds_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.285614Z",
     "start_time": "2019-09-03T04:30:36.518Z"
    }
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "df_preds_full = pd.DataFrame({'id_code_site': preds_names,\n",
    "                                  'sirna': preds_test_full[:,i],\n",
    "                                  'cossim': dist_test_full[:,i]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.286305Z",
     "start_time": "2019-09-03T04:30:36.525Z"
    }
   },
   "outputs": [],
   "source": [
    "df_preds_full.sort_values(by='cossim', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.287005Z",
     "start_time": "2019-09-03T04:30:36.535Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "for i, d in df_preds_full.sort_values(by='cossim', ascending=False).iterrows():\n",
    "    print(i)\n",
    "    print(d)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.287700Z",
     "start_time": "2019-09-03T04:30:36.542Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test.head()#.experiment.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.288405Z",
     "start_time": "2019-09-03T04:30:36.549Z"
    }
   },
   "outputs": [],
   "source": [
    "df_preds_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.289101Z",
     "start_time": "2019-09-03T04:30:36.557Z"
    }
   },
   "outputs": [],
   "source": [
    "df_preds_full.groupby('sirna')['id_code_site'].nunique()#.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T04:30:43.289792Z",
     "start_time": "2019-09-03T04:30:36.565Z"
    }
   },
   "outputs": [],
   "source": [
    "# ERROR ANALYSIS !!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "488px",
    "width": "305px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "206px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
